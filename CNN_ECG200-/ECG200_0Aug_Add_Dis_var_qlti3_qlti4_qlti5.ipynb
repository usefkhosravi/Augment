{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab7fbdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from augment import *\n",
    "import glob\n",
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "import random\n",
    "import bisect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess import *                         #ماژول استخراج پنجره ها\n",
    "from data import *                               #ماژول محلی ورود داده ها\n",
    "from augment import *                            #ماژول های داده افزایی\n",
    "from GAN import *                  \n",
    "from lstm_cnn import *                           #ماژول های داده افزایی با lstm_cnn\n",
    "import augment\n",
    "import importlib\n",
    "importlib.reload(augment)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report,recall_score,precision_score\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D,Conv1D,Dropout,MaxPooling1D,MaxPooling2D,Flatten,Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "cwd = os.getcwd() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64bf2935",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wdth= 481\n",
      "shape(ecg)= (100, 481)\n",
      "shape wndws1= (31, 481)\n",
      "shape base_wn= (100, 481)\n",
      "shape furir_windws0= (100, 480)\n",
      "shape furir_windws= (100, 481)\n",
      "smpl_rte= 480\n",
      "mx_wndws= 69\n"
     ]
    }
   ],
   "source": [
    "def dstnc(dt2,dt1): #فاصله و واریانس بردار فاصله ی هر کدام از ردیف های دیتاست(آگمنت)1 از (کل)2\n",
    "    dist,vrnc,i,h,w=[],[],0,np.shape(dt1)[0],np.shape(dt1)[1]\n",
    "    end=min(len(dt2[0]),len(dt1[0]))\n",
    "    for i in range (h):\n",
    "        ds1 = dt2-dt1[i,:end] #.reshape(-1,1) #distance of every training instance\n",
    "        dist_array=(ds1*10)**3  #معیار فاصله با حساسیت به توان 3 (حفظ علامت و تاثیر بیشتر تفاوت زیاد در نقاط)\n",
    "        vr=np.var(ds1)\n",
    "        ds1=min(np.sum(np.absolute(dist_array),axis=1))\n",
    "        #print('dist2 = ', dist2)\n",
    "        vrnc.append(vr)\n",
    "        dist.append(ds1)\n",
    "    variance=np.reshape(vrnc,(-1,1))\n",
    "    distnc=np.reshape(dist,(-1,1))\n",
    "    return(distnc,variance)\n",
    "\n",
    "ecg=np.array([])\n",
    "for i in range (1,3):\n",
    "    vars()['ecg'+str(i)],vars()['ecg_tst'+str(i)]=Ecg200(i)         #فراخوانی داده های اصلی\n",
    "    ecg=np.append(ecg,vars()['ecg'+str(i)])\n",
    "wdth=int(len(ecg1[0]))\n",
    "print('wdth=',wdth)\n",
    "ecg=np.reshape(ecg,(int(len(ecg)/wdth),wdth))  #base data windows\n",
    "print('shape(ecg)=',np.shape(ecg))\n",
    "os.chdir(cwd)\n",
    "base_wn=np.array([])\n",
    "windws=np.array([])\n",
    "\n",
    "for cls in range (1,3):                   #ساخت پنجره های داده های آموزش اصلی\n",
    "    vars()['wndws'+str(cls)]=np.array(vars()['ecg'+str(cls)])\n",
    "    base_wn=np.append(base_wn,vars()['wndws'+str(cls)])\n",
    "base_wn=np.reshape(base_wn,(int(len(base_wn)/wdth),wdth))  #base data windows\n",
    "print(\"shape wndws1=\", np.shape(wndws1))\n",
    "print(\"shape base_wn=\", np.shape(base_wn))\n",
    "\n",
    "furir_windws0=np.fft.fft(np.array(base_wn[:,:-1]))\n",
    "print(\"shape furir_windws0=\", np.shape(furir_windws0))\n",
    "furir_windws=np.concatenate((np.array(furir_windws0),np.transpose([base_wn[:,-1]])),axis=1)   \n",
    "print(\"shape furir_windws=\", np.shape(furir_windws))\n",
    "\n",
    "smpl_rte=len(base_wn[0])-1                 #len(ecg1[0])  # در ماژول ها نیز همین مقدار ثبت شده\n",
    "print(\"smpl_rte=\",smpl_rte)\n",
    "mx_wndws=np.max(np.bincount(np.int16(base_wn[:,-1])))\n",
    "print(\"mx_wndws=\",mx_wndws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "095bd5cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path=('{}\\AugEvl'.format(cwd)) #create folder \n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "def addqlty(base_wn_dt,data,mthd,i):               \n",
    "    cls=int(i)\n",
    "    c,alpha,PL=0,1,1\n",
    "    #from glob import glob\n",
    "    cwd = os.getcwd() #\n",
    "    adrs=cwd+'/Aug/aug'+str(i)+str(mthd)+'.csv'\n",
    "    #alldata = np.array([])                    # List for storing all the data\n",
    "    train_labels=np.array(base_wn_dt[:,-1])\n",
    "    tr=np.array(base_wn_dt[:,:-1])\n",
    "    indx_pstv=np.where(base_wn_dt[:,-1] == i)\n",
    "    P=np.array(base_wn_dt[indx_pstv])\n",
    "    indx_ngtv=np.where(base_wn_dt[:,-1] != i)\n",
    "    N=np.array(base_wn_dt[indx_ngtv])\n",
    "\n",
    "    #data = np.array(data)\n",
    "    aug=np.array(data)\n",
    "    pnts=int(np.shape(data)[1])\n",
    "    \n",
    "    #aug=data[data[:,-2].argsort()]        # Positive data Sorted Base Distance\n",
    "    trl=np.array(train_labels)\n",
    "    for j in range (len(trl)):\n",
    "        if train_labels[j]==i :           # !!!!! == (Paper GDO)\n",
    "            trl[j]=1\n",
    "        else :\n",
    "            trl[j]=0\n",
    "    trlt=np.array([trl]).T\n",
    "    #mn_ds_pstv=np.reshape(aug[:,-2],(-1,1)) #min dis to positive class (submited in -2 column)\n",
    "    print('shape and aug[0]=',np.shape(aug[0]),aug[0])\n",
    "    print('shape P and P[0]=',np.shape(P),P[0])    \n",
    "    qlty1,qlty2=mn_ds_pstv,vr_P=dstnc(P[:,1:-1],aug[:,1:-1])  #min distance to negative class\n",
    "    new1=np.append(aug,qlty1,axis=1)\n",
    "    new2=np.append(new1,qlty2,axis=1)\n",
    "    mn_ds_ngtv,vr_N=dstnc(N[:,1:-1],aug[:,1:-1])              #min distance to negative class\n",
    "    qlty3=mn_ds_pstv/mn_ds_ngtv                               #Smaller is Better\n",
    "    qlty4=np.reshape(valuation(aug[:,:-1],tr,trlt),(-1,1))   #line 272\n",
    "    new3=np.append(new2,qlty3,axis=1)\n",
    "    new4=np.append(new3,qlty4,axis=1)\n",
    "    for j in range (len(trl)):\n",
    "        if train_labels[j]!=i :                          # !!!!! == (!= Inverse Paper GDO)\n",
    "            trl[j]=1\n",
    "        else :\n",
    "            trl[j]=0\n",
    "    trlt=np.array([trl]).T\n",
    "    qlty5=np.reshape(valuation(aug[:,:-1],tr,trlt),(-1,1))   #line 272\n",
    "    new5=np.append(new4,qlty5,axis=1)\n",
    "    print('class=',i,'shape(new5)=',np.shape(new5),end='\\t')\n",
    "    print('mx=',np.max(new5[:,1:-7]),end='\\t')\n",
    "    print('mn=',np.min(new5[:,1:-7]))\n",
    "    pd.DataFrame(new5[:,:]).to_csv('{}/AugEvl/AugEvl{}{}.csv'.format(cwd,cls,mthd))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "785419e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range (1,3):                           #تعریف آرایه ی پنجره های کلاس ها\\n    vlum_sig=6*mx_wndws-len(vars()['wndws'+str(i)])\\n  \\n    vars()['ecg_aug'+str(i)+'10']=np.append(vars()['ecg_aug'+str(i)+'10'],sclRaw(ecg,i,int(vlum_sig),mag=.1),axis=0)#0.1\\n    addqlty(base_wn,vars()['ecg_aug'+str(i)+'10'],10,i)\\n    print(str(i)+'10 =',len(vars()['ecg_aug'+str(i)+'10']))\\n    vars()['ecg_aug'+str(i)+'11']=np.append(vars()['ecg_aug'+str(i)+'11'],sclRaw(ecg,i,int(vlum_sig),mag=.2),axis=0)\\n    addqlty(base_wn,vars()['ecg_aug'+str(i)+'11'],11,i)\\n    print(str(i)+'11 =',len(vars()['ecg_aug'+str(i)+'11']))\\n    #xtrain=np.append(xtrain,vars()['ecg_aug10'+str(i)],axis=0)\\n    \\n    vars()['ecg_aug'+str(i)+'20']=np.append(vars()['ecg_aug'+str(i)+'20'],MgWrpRaw(ecg,i,int(vlum_sig),mag=.05),axis=0)\\n    addqlty(base_wn,vars()['ecg_aug'+str(i)+'20'],20,i)\\n    print(str(i)+'20 =',len(vars()['ecg_aug'+str(i)+'20']))\\n    vars()['ecg_aug'+str(i)+'21']=np.append(vars()['ecg_aug'+str(i)+'21'],MgWrpRaw(ecg,i,int(vlum_sig),mag=.1),axis=0) \\n    addqlty(base_wn,vars()['ecg_aug'+str(i)+'21'],21,i)\\n    print(str(i)+'21 =',len(vars()['ecg_aug'+str(i)+'21']))\\n    #xtrain=np.append(xtrain,vars()['ecg_aug21'+str(i)],axis=0)\\n    \\n    vars()['ecg_aug'+str(i)+'30']=np.append(vars()['ecg_aug'+str(i)+'30'],TimWrpRaw(ecg,i,int(vlum_sig),mag=.1),axis=0)#.1\\n    addqlty(base_wn,vars()['ecg_aug'+str(i)+'30'],30,i)\\n    print(str(i)+'30 =',len(vars()['ecg_aug'+str(i)+'30']))\\n    vars()['ecg_aug'+str(i)+'31']=np.append(vars()['ecg_aug'+str(i)+'31'],TimWrpRaw(ecg,i,int(vlum_sig),mag=.2),axis=0)\\n    addqlty(base_wn,vars()['ecg_aug'+str(i)+'31'],31,i)\\n    print(str(i)+'31 =',len(vars()['ecg_aug'+str(i)+'31']))\\n    #xtrain=np.append(xtrain,vars()['ecg_aug30'+str(i)],axis=0)\\n    \\n    vars()['ecg_aug'+str(i)+'40']=np.append(vars()['ecg_aug'+str(i)+'40'],GDORaw(ecg,i,int(vlum_sig),mag=.1),axis=0)\\n    addqlty(base_wn,vars()['ecg_aug'+str(i)+'40'],40,i)\\n    print(str(i)+'40 =',len(vars()['ecg_aug'+str(i)+'40']))\\n    vars()['ecg_aug'+str(i)+'41']=np.append(vars()['ecg_aug'+str(i)+'41'],GDORaw(ecg,i,int(vlum_sig),mag=.2),axis=0)\\n    addqlty(base_wn,vars()['ecg_aug'+str(i)+'41'],41,i)\\n    print(str(i)+'41 =',len(vars()['ecg_aug'+str(i)+'41']))\\n    #xtrain=np.append(xtrain,vars()['ecg_aug40'+str(i)],axis=0)\\n    \\n    vars()['ecg_aug'+str(i)+'50']=np.append(vars()['ecg_aug'+str(i)+'50'],frqncRaw(furir_windws,i,int(vlum_sig),mag=.1),axis=0)\\n    addqlty(base_wn,vars()['ecg_aug'+str(i)+'50'],50,i)\\n    print(str(i)+'50 =',len(vars()['ecg_aug'+str(i)+'50']))\\n    vars()['ecg_aug'+str(i)+'51']=np.append(vars()['ecg_aug'+str(i)+'51'],frqncRaw(furir_windws,i,int(vlum_sig),mag=.2),axis=0)   \\n    addqlty(base_wn,vars()['ecg_aug'+str(i)+'51'],51,i)\\n    print(str(i)+'51 =',len(vars()['ecg_aug'+str(i)+'51']))\\n    #xtrain=np.append(xtrain,vars()['ecg_aug51'+str(i)],axis=0)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain=np.empty((0,smpl_rte+1), float) \n",
    "\n",
    "for i in range (1,3):                           #تعریف آرایه ی پنجره های کلاس ها\n",
    "    vars()['ecg_aug'+str(i)+'00']=np.empty((0,smpl_rte+1), float) #Scale    \n",
    "    vars()['ecg_aug'+str(i)+'10']=np.empty((0,smpl_rte+1), float) #Scale\n",
    "    vars()['ecg_aug'+str(i)+'11']=np.empty((0,smpl_rte+1), float) \n",
    "    vars()['ecg_aug'+str(i)+'20']=np.empty((0,smpl_rte+1), float) #Mag Warp\n",
    "    vars()['ecg_aug'+str(i)+'21']=np.empty((0,smpl_rte+1), float) \n",
    "    vars()['ecg_aug'+str(i)+'30']=np.empty((0,smpl_rte+1), float) #TimWarp\n",
    "    vars()['ecg_aug'+str(i)+'31']=np.empty((0,smpl_rte+1), float)\n",
    "    vars()['ecg_aug'+str(i)+'40']=np.empty((0,smpl_rte+1), float) #GDO\n",
    "    vars()['ecg_aug'+str(i)+'41']=np.empty((0,smpl_rte+1), float) \n",
    "    vars()['ecg_aug'+str(i)+'50']=np.empty((0,smpl_rte+1), float) #frequence\n",
    "    vars()['ecg_aug'+str(i)+'51']=np.empty((0,smpl_rte+1), float)     \n",
    "    vars()['ecg_aug'+str(i)+'60']=np.empty((0,smpl_rte+1), float) #GAN\n",
    "    vars()['ecg_aug'+str(i)+'61']=np.empty((0,smpl_rte+1), float)\n",
    "    vars()['ecg_aug'+str(i)+'70']=np.empty((0,smpl_rte+1), float) #LSTM\n",
    "    vars()['ecg_aug'+str(i)+'71']=np.empty((0,smpl_rte+1), float)\n",
    "\n",
    "'''f_scr=np.array([54,83,88,82,70,58,54,70])      #UnAg,Scl.2,Mag.05,Tm.2,Gs1,frqnc2,GAN,LSTMexpgdo\n",
    "f_scr_difrnc=f_scr-f_scr[0]\n",
    "f_scr_rtio=f_scr_difrnc/(sum(f_scr_difrnc))\n",
    "aug_amnt=np.array(f_scr_rtio)                 #aug_amnt[0] is UnAg so in follow start from 1 for scale,..\n",
    "'''\n",
    "vlum_wndw=6*mx_wndws  #5000\n",
    "\n",
    "for i in range (1,3):                           #تعریف آرایه ی پنجره های کلاس ها\n",
    "    vlum_sig=6*mx_wndws-len(vars()['wndws'+str(i)])\n",
    "  \n",
    "    vars()['ecg_aug'+str(i)+'10']=np.append(vars()['ecg_aug'+str(i)+'10'],sclRaw(ecg,i,int(vlum_sig),mag=.1),axis=0)#0.1\n",
    "    addqlty(base_wn,vars()['ecg_aug'+str(i)+'10'],10,i)\n",
    "    print(str(i)+'10 =',len(vars()['ecg_aug'+str(i)+'10']))\n",
    "    vars()['ecg_aug'+str(i)+'11']=np.append(vars()['ecg_aug'+str(i)+'11'],sclRaw(ecg,i,int(vlum_sig),mag=.2),axis=0)\n",
    "    addqlty(base_wn,vars()['ecg_aug'+str(i)+'11'],11,i)\n",
    "    print(str(i)+'11 =',len(vars()['ecg_aug'+str(i)+'11']))\n",
    "    #xtrain=np.append(xtrain,vars()['ecg_aug10'+str(i)],axis=0)\n",
    "    \n",
    "    vars()['ecg_aug'+str(i)+'20']=np.append(vars()['ecg_aug'+str(i)+'20'],MgWrpRaw(ecg,i,int(vlum_sig),mag=.05),axis=0)\n",
    "    addqlty(base_wn,vars()['ecg_aug'+str(i)+'20'],20,i)\n",
    "    print(str(i)+'20 =',len(vars()['ecg_aug'+str(i)+'20']))\n",
    "    vars()['ecg_aug'+str(i)+'21']=np.append(vars()['ecg_aug'+str(i)+'21'],MgWrpRaw(ecg,i,int(vlum_sig),mag=.1),axis=0) \n",
    "    addqlty(base_wn,vars()['ecg_aug'+str(i)+'21'],21,i)\n",
    "    print(str(i)+'21 =',len(vars()['ecg_aug'+str(i)+'21']))\n",
    "    #xtrain=np.append(xtrain,vars()['ecg_aug21'+str(i)],axis=0)\n",
    "    \n",
    "    vars()['ecg_aug'+str(i)+'30']=np.append(vars()['ecg_aug'+str(i)+'30'],TimWrpRaw(ecg,i,int(vlum_sig),mag=.1),axis=0)#.1\n",
    "    addqlty(base_wn,vars()['ecg_aug'+str(i)+'30'],30,i)\n",
    "    print(str(i)+'30 =',len(vars()['ecg_aug'+str(i)+'30']))\n",
    "    vars()['ecg_aug'+str(i)+'31']=np.append(vars()['ecg_aug'+str(i)+'31'],TimWrpRaw(ecg,i,int(vlum_sig),mag=.2),axis=0)\n",
    "    addqlty(base_wn,vars()['ecg_aug'+str(i)+'31'],31,i)\n",
    "    print(str(i)+'31 =',len(vars()['ecg_aug'+str(i)+'31']))\n",
    "    #xtrain=np.append(xtrain,vars()['ecg_aug30'+str(i)],axis=0)\n",
    "    \n",
    "    vars()['ecg_aug'+str(i)+'40']=np.append(vars()['ecg_aug'+str(i)+'40'],GDORaw(ecg,i,int(vlum_sig),mag=.1),axis=0)\n",
    "    addqlty(base_wn,vars()['ecg_aug'+str(i)+'40'],40,i)\n",
    "    print(str(i)+'40 =',len(vars()['ecg_aug'+str(i)+'40']))\n",
    "    vars()['ecg_aug'+str(i)+'41']=np.append(vars()['ecg_aug'+str(i)+'41'],GDORaw(ecg,i,int(vlum_sig),mag=.2),axis=0)\n",
    "    addqlty(base_wn,vars()['ecg_aug'+str(i)+'41'],41,i)\n",
    "    print(str(i)+'41 =',len(vars()['ecg_aug'+str(i)+'41']))\n",
    "    #xtrain=np.append(xtrain,vars()['ecg_aug40'+str(i)],axis=0)\n",
    "    \n",
    "    vars()['ecg_aug'+str(i)+'50']=np.append(vars()['ecg_aug'+str(i)+'50'],frqncRaw(furir_windws,i,int(vlum_sig),mag=.1),axis=0)\n",
    "    addqlty(base_wn,vars()['ecg_aug'+str(i)+'50'],50,i)\n",
    "    print(str(i)+'50 =',len(vars()['ecg_aug'+str(i)+'50']))\n",
    "    vars()['ecg_aug'+str(i)+'51']=np.append(vars()['ecg_aug'+str(i)+'51'],frqncRaw(furir_windws,i,int(vlum_sig),mag=.2),axis=0)   \n",
    "    addqlty(base_wn,vars()['ecg_aug'+str(i)+'51'],51,i)\n",
    "    print(str(i)+'51 =',len(vars()['ecg_aug'+str(i)+'51']))\n",
    "    #xtrain=np.append(xtrain,vars()['ecg_aug51'+str(i)],axis=0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75405e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Class  1  Shape =  (100, 481)\n",
      "for class  1 number of windows is =  (481,)\n",
      "GAN Train Data shape= (138, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:881: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:881: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal cluster number:  3\n",
      "class= 1 cluster= 0 epochs= 2172  >> shape generate =  (651600, 483)\n",
      "class= 1 cluster= 1 epochs= 2172  >> shape generate =  (651600, 483)\n",
      "class= 1 cluster= 2 epochs= 2172  >> shape generate =  (651600, 483)\n",
      "cls  1  final shape, Generated by GAN = (690, 483)\n",
      "shape and aug[0]= (481,) [2.4921875  2.48046875 2.50390625 2.53710938 2.55859375 2.59960938\n",
      " 2.63476562 2.68554688 2.71679688 2.75       2.77734375 2.81445312\n",
      " 2.84765625 2.87695312 2.91210938 2.94140625 2.96679688 2.98632812\n",
      " 3.00976562 3.03125    3.05859375 3.08203125 3.11523438 3.14257812\n",
      " 3.171875   3.19726562 3.23242188 3.25976562 3.28710938 3.31054688\n",
      " 3.34179688 3.37304688 3.40234375 3.43359375 3.46875    3.49414062\n",
      " 3.5234375  3.54296875 3.57226562 3.58398438 3.60546875 3.61523438\n",
      " 3.62304688 3.62695312 3.6171875  3.59960938 3.578125   3.55273438\n",
      " 3.50976562 3.45898438 3.40820312 3.359375   3.30664062 3.25585938\n",
      " 3.19921875 3.14453125 3.07421875 3.01367188 2.94921875 2.89257812\n",
      " 2.83203125 2.77148438 2.7109375  2.6484375  2.5859375  2.51757812\n",
      " 2.4375     2.3671875  2.2890625  2.234375   2.18164062 2.14257812\n",
      " 2.10742188 2.109375   2.1171875  2.12695312 2.13867188 2.15234375\n",
      " 2.15820312 2.15820312 2.15820312 2.14648438 2.13671875 2.12890625\n",
      " 2.15429688 2.16601562 2.20703125 2.2578125  2.29101562 2.3203125\n",
      " 2.30859375 2.3046875  2.26367188 2.1953125  2.11914062 2.01757812\n",
      " 1.92480469 1.87402344 1.81152344 1.79980469 1.78515625 1.79882812\n",
      " 1.82714844 1.82617188 1.79980469 1.80371094 1.74707031 1.73046875\n",
      " 1.70410156 1.68847656 1.69140625 1.69433594 1.69628906 1.7109375\n",
      " 1.69140625 1.66503906 1.64941406 1.62597656 1.59667969 1.5859375\n",
      " 1.56738281 1.5546875  1.52832031 1.51953125 1.51269531 1.50097656\n",
      " 1.50097656 1.48828125 1.50195312 1.48046875 1.45117188 1.44824219\n",
      " 1.421875   1.41699219 1.40332031 1.39355469 1.38867188 1.3671875\n",
      " 1.32519531 1.3046875  1.28222656 1.26464844 1.25292969 1.22753906\n",
      " 1.23144531 1.19824219 1.18359375 1.1640625  1.14160156 1.13867188\n",
      " 1.12890625 1.11230469 1.11816406 1.09375    1.07617188 1.07714844\n",
      " 1.06738281 1.06347656 1.08398438 1.08300781 1.10351562 1.09570312\n",
      " 1.10351562 1.09277344 1.09765625 1.12304688 1.12597656 1.15722656\n",
      " 1.16308594 1.18554688 1.18847656 1.19140625 1.20117188 1.2109375\n",
      " 1.21289062 1.21484375 1.22070312 1.22265625 1.19824219 1.1875\n",
      " 1.17285156 1.16015625 1.19042969 1.17285156 1.17089844 1.15625\n",
      " 1.13964844 1.10253906 1.09667969 1.09277344 1.09863281 1.09863281\n",
      " 1.09082031 1.09667969 1.10058594 1.09765625 1.10058594 1.10839844\n",
      " 1.12597656 1.1328125  1.15039062 1.16308594 1.15820312 1.16992188\n",
      " 1.18359375 1.18847656 1.21679688 1.22363281 1.23144531 1.23828125\n",
      " 1.24511719 1.22363281 1.23730469 1.23144531 1.23339844 1.22949219\n",
      " 1.23242188 1.23535156 1.22558594 1.23046875 1.23339844 1.22851562\n",
      " 1.24511719 1.23828125 1.26367188 1.26464844 1.26269531 1.28320312\n",
      " 1.29003906 1.3125     1.33496094 1.36035156 1.38964844 1.40234375\n",
      " 1.41601562 1.4375     1.45507812 1.4765625  1.48632812 1.53320312\n",
      " 1.53710938 1.56152344 1.56738281 1.59179688 1.60253906 1.60644531\n",
      " 1.61132812 1.62597656 1.63378906 1.62890625 1.62207031 1.62695312\n",
      " 1.63574219 1.6171875  1.61132812 1.62304688 1.61523438 1.61035156\n",
      " 1.62207031 1.62695312 1.62890625 1.62207031 1.62792969 1.64355469\n",
      " 1.63964844 1.65136719 1.66015625 1.67871094 1.68847656 1.70214844\n",
      " 1.71289062 1.7421875  1.75292969 1.78222656 1.79882812 1.8203125\n",
      " 1.82910156 1.85058594 1.87011719 1.89648438 1.89648438 1.92480469\n",
      " 1.93359375 1.95605469 1.95507812 1.97265625 1.97363281 1.99023438\n",
      " 1.98730469 2.00195312 1.99609375 2.00195312 2.00195312 2.00390625\n",
      " 2.00585938 2.015625   1.99804688 2.0078125  2.00195312 2.015625\n",
      " 2.00195312 2.00976562 2.0078125  2.015625   2.01367188 2.01757812\n",
      " 2.01367188 2.02929688 2.0234375  2.03710938 2.0390625  2.05859375\n",
      " 2.05859375 2.07421875 2.07617188 2.1015625  2.10742188 2.12890625\n",
      " 2.140625   2.16015625 2.16796875 2.19140625 2.203125   2.23046875\n",
      " 2.234375   2.25585938 2.27539062 2.29101562 2.30078125 2.31835938\n",
      " 2.328125   2.34960938 2.35742188 2.36523438 2.37304688 2.37890625\n",
      " 2.3828125  2.37695312 2.38085938 2.37890625 2.375      2.3671875\n",
      " 2.36132812 2.35742188 2.34960938 2.34570312 2.34375    2.34179688\n",
      " 2.33789062 2.33984375 2.34375    2.3515625  2.35742188 2.36328125\n",
      " 2.37304688 2.39453125 2.40429688 2.41992188 2.43554688 2.45703125\n",
      " 2.4765625  2.4921875  2.50976562 2.5234375  2.53515625 2.54101562\n",
      " 2.546875   2.55078125 2.54882812 2.55273438 2.55273438 2.55273438\n",
      " 2.55664062 2.5625     2.56640625 2.57421875 2.58203125 2.58789062\n",
      " 2.59960938 2.60351562 2.61328125 2.6171875  2.6171875  2.63085938\n",
      " 2.63867188 2.65039062 2.671875   2.6875     2.70507812 2.71875\n",
      " 2.73046875 2.7265625  2.7109375  2.68359375 2.66992188 2.66015625\n",
      " 2.65820312 2.68359375 2.68554688 2.70703125 2.79492188 2.73828125\n",
      " 2.72460938 2.58398438 2.80273438 2.84179688 2.796875   2.81640625\n",
      " 2.85351562 2.86132812 2.77929688 2.7421875  2.6796875  2.65039062\n",
      " 2.6484375  2.671875   2.6875     2.70898438 2.71484375 2.70898438\n",
      " 2.69140625 2.6640625  2.63476562 2.61328125 2.59570312 2.59570312\n",
      " 2.59570312 2.61132812 2.62695312 2.64648438 2.66601562 2.68359375\n",
      " 2.69335938 2.69921875 2.69921875 2.69140625 2.67578125 2.66015625\n",
      " 2.63476562 2.62304688 2.59765625 2.578125   2.56054688 2.54492188\n",
      " 2.53515625 2.52929688 2.52734375 2.53320312 2.54101562 2.55859375\n",
      " 2.57421875 2.59179688 2.61328125 2.63671875 2.65820312 2.68164062\n",
      " 2.70703125 2.72460938 2.74023438 2.75       2.75585938 2.75195312\n",
      " 2.74609375 2.73046875 2.7109375  2.69140625 2.66601562 2.63867188\n",
      " 2.609375   2.57617188 2.54882812 2.52539062 2.49804688 2.4765625\n",
      " 2.46289062 2.453125   2.4375     2.4296875  2.43164062 2.43945312\n",
      " 1.        ]\n",
      "shape P and P[0]= (31, 481) [ 0.50206     0.53193953  0.5502248   0.55541849  0.55051777  0.54216\n",
      "  0.53898992  0.54973595  0.58149978  0.63863594  0.72238     0.83115291\n",
      "  0.96129606  1.10792479  1.26563211  1.4289      1.59222605  1.75009346\n",
      "  1.89695971  2.02740652  2.1365      2.22029804  2.2763578   2.30407188\n",
      "  2.30470542  2.2811      2.23711756  2.17697753  2.10466584  2.02355624\n",
      "  1.9363      1.84494184  1.75114403  1.65637534  1.56195285  1.4689\n",
      "  1.37767286  1.2878751   1.19810412  1.10603833  1.0088      0.90353711\n",
      "  0.78809223  0.66159377  0.52482384  0.38028     0.23193253  0.08475499\n",
      " -0.05584905 -0.18459873 -0.29678    -0.38854936 -0.45711891 -0.50087365\n",
      " -0.51946951 -0.51393    -0.48671727 -0.44172037 -0.3840953  -0.31991554\n",
      " -0.25564    -0.19746239 -0.15064987 -0.11899398 -0.10447615 -0.1072\n",
      " -0.12557991 -0.15671923 -0.19688043 -0.24195007 -0.28783    -0.33072964\n",
      " -0.36737375 -0.39516216 -0.41231455 -0.41801    -0.41249849 -0.39713725\n",
      " -0.37430065 -0.34713374 -0.31916    -0.29380091 -0.27390025 -0.26135659\n",
      " -0.25694712 -0.26038    -0.27055399 -0.28595198 -0.30506405 -0.32673505\n",
      " -0.35036    -0.37589755 -0.40372159 -0.43437009 -0.4682673  -0.50549\n",
      " -0.54562581 -0.58774202 -0.63045763 -0.67209578 -0.71089    -0.74522051\n",
      " -0.77386102 -0.79621466 -0.81251038 -0.82392    -0.83255056 -0.84127234\n",
      " -0.8533666  -0.8720152  -0.8997     -0.93761917 -0.98524732 -1.04015675\n",
      " -1.09817637 -1.1539     -1.2014816  -1.23558894 -1.25234642 -1.25009158\n",
      " -1.2298     -1.19509221 -1.15181074 -1.10722911 -1.06901419 -1.0441\n",
      " -1.03764085 -1.05219758 -1.08727704 -1.13929776 -1.202      -1.26726023\n",
      " -1.32621412 -1.37054303 -1.3937452  -1.3922     -1.36585006 -1.31837252\n",
      " -1.25678464 -1.19051953 -1.1301     -1.08561264 -1.06522591 -1.07399289\n",
      " -1.11313255 -1.1799     -1.26805398 -1.36882883 -1.472238   -1.5684909\n",
      " -1.6493     -1.70888841 -1.74456938 -1.75684476 -1.7490452  -1.7266\n",
      " -1.69606963 -1.66409757 -1.63643856 -1.61720046 -1.6084     -1.60988356\n",
      " -1.6196077  -1.63421849 -1.64982114 -1.6628     -1.67054107 -1.67192747\n",
      " -1.66752054 -1.65939973 -1.6507     -1.64494431 -1.64530701 -1.65395489\n",
      " -1.67159327 -1.6973     -1.72867133 -1.76224229 -1.79409407 -1.8205305\n",
      " -1.8387     -1.84705606 -1.84558389 -1.83576459 -1.82029252 -1.8026\n",
      " -1.78627035 -1.77443399 -1.76924177 -1.77149661 -1.7805     -1.79413797\n",
      " -1.80919484 -1.82184727 -1.82826172 -1.8252     -1.8105349  -1.78359157\n",
      " -1.74525975 -1.69786128 -1.6448     -1.59005801 -1.53762671 -1.4909681\n",
      " -1.4525909  -1.4238     -1.40464323 -1.39404332 -1.39007247 -1.39030783\n",
      " -1.3922     -1.39339329 -1.39195322 -1.38647916 -1.37610354 -1.3604\n",
      " -1.33923761 -1.31262557 -1.28059102 -1.24312311 -1.2002     -1.15189495\n",
      " -1.09853729 -1.04088669 -0.98026985 -0.91863    -0.85845197 -0.8025484\n",
      " -0.75372126 -0.71434239 -0.68592    -0.66873077 -0.66159426 -0.66184897\n",
      " -0.66555873 -0.66794    -0.66396177 -0.64903669 -0.61970118 -0.57417711\n",
      " -0.51272    -0.43768685 -0.35329741 -0.26510965 -0.17927651 -0.10169\n",
      " -0.03714182  0.01136589  0.0430445   0.05940074  0.063954    0.06162693\n",
      "  0.05790454  0.05789941  0.06548031  0.082614    0.10903568  0.14230821\n",
      "  0.17826407  0.21175864  0.23761     0.2515693   0.2511596   0.23624232\n",
      "  0.20921354  0.17479     0.1394087   0.11032408  0.09453441  0.0976986\n",
      "  0.12321     0.17157505  0.24020272  0.32365051  0.41430297  0.50339\n",
      "  0.58219511  0.64327018  0.68146904  0.6946396   0.68387     0.65325717\n",
      "  0.60924465  0.55964425  0.51250259  0.47499     0.45247536  0.44791042\n",
      "  0.46159128  0.49130326  0.5328      0.5805255   0.62846322  0.67098978\n",
      "  0.7036198   0.72355     0.7299409   0.72391057  0.70825288  0.68692999\n",
      "  0.66442     0.64502168  0.63222407  0.6282369   0.6337489   0.64794\n",
      "  0.66872719  0.69318307  0.71803945  0.74018132  0.75705     0.7669035\n",
      "  0.76891897  0.76315532  0.7504174   0.73207     0.70984325  0.68565476\n",
      "  0.66145614  0.63909868  0.62021     0.60607827  0.59755077  0.59496242\n",
      "  0.5981123   0.6063      0.61842107  0.63310515  0.64886972  0.66425959\n",
      "  0.67795     0.68880624  0.6959092   0.69856783  0.6963408   0.68908\n",
      "  0.67699162  0.66069289  0.64123204  0.62004157  0.59881     0.57928209\n",
      "  0.56302232  0.55119328  0.54440174  0.54265     0.5454024   0.5517457\n",
      "  0.56059768  0.57090883  0.58181     0.59268106  0.60314321  0.6130011\n",
      "  0.62217143  0.63063     0.63839196  0.6455185   0.65212686  0.65837713\n",
      "  0.66442     0.67031108  0.6759196   0.680873    0.68457565  0.68632\n",
      "  0.68547632  0.68171525  0.675197    0.66666192  0.65738     0.6489569\n",
      "  0.64303687  0.64097562  0.64356672  0.65089     0.66231436  0.6766435\n",
      "  0.69235479  0.70786236  0.72174     0.73286396  0.74047012  0.74414951\n",
      "  0.74382042  0.73971     0.73235613  0.72261454  0.71163715  0.7007877\n",
      "  0.69148     0.68495778  0.68206814  0.6830991   0.687745    0.69523\n",
      "  0.70456944  0.71489846  0.72576535  0.73728826  0.75011     0.7651477\n",
      "  0.78320182  0.8045403   0.82858977  0.85384     0.87800819  0.89843395\n",
      "  0.91260969  0.91871401  0.91602     0.9050901   0.88773152  0.86674641\n",
      "  0.84555143  0.82775     0.81672143  0.81525666  0.82524036  0.84736908\n",
      "  0.88091     0.92353834  0.97132363  1.01894687  1.06020555  1.0888\n",
      "  1.09930935  1.0881829   1.05452705  1.00047973  0.93104     0.85334411\n",
      "  0.77551691  0.70533814  0.64901213  0.6103      0.59017431  0.58701736\n",
      "  0.59724981  0.61618575  0.63889     0.66086138  0.67846062  0.68910264\n",
      "  0.69130267  0.68468     0.66998052  0.64910423  0.62505395  0.60169356\n",
      "  0.58324     0.57350614  0.5750306   0.58832694  0.61151354  0.64052\n",
      "  0.66991522  0.69420647  0.70928223  0.7135794   0.70859     0.69848796\n",
      "  0.68891134  0.68520365  0.69061411  0.70501     0.72453774  0.74240769\n",
      "  0.75064558  0.74235019  0.71382     0.66591893  0.60425013  0.53803957\n",
      "  0.47800212  0.43376     0.41151724  0.41262417  0.43341425  0.46633777\n",
      "  1.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 1 shape(new5)= (690, 486)\tmx= 4.234375\tmn= 1.0\n",
      "\n",
      "161 = 690\n",
      "\n",
      "\n",
      "\n",
      " Class  2  Shape =  (100, 481)\n",
      "for class  2 number of windows is =  (481,)\n",
      "GAN Train Data shape= (138, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:881: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:881: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal cluster number:  4\n",
      "class= 2 cluster= 0 epochs= 4000  >> shape generate =  (640000, 483)\n",
      "class= 2 cluster= 1 epochs= 2630  >> shape generate =  (789000, 483)\n",
      "class= 2 cluster= 2 epochs= 1368  >> shape generate =  (410400, 483)\n",
      "class= 2 cluster= 3 epochs= 4000  >> shape generate =  (640000, 483)\n",
      "cls  2  final shape, Generated by GAN = (690, 483)\n",
      "shape and aug[0]= (481,) [3.16015625 3.34765625 3.53515625 3.78125    3.9609375  4.15625\n",
      " 4.3046875  4.44921875 4.52734375 4.56640625 4.546875   4.484375\n",
      " 4.359375   4.19140625 4.00390625 3.75976562 3.56640625 3.35742188\n",
      " 3.14648438 2.94335938 2.79296875 2.66796875 2.58203125 2.5390625\n",
      " 2.54296875 2.578125   2.65625    2.74414062 2.85546875 2.96875\n",
      " 3.07421875 3.15820312 3.20507812 3.23828125 3.22851562 3.20507812\n",
      " 3.17382812 3.15039062 3.13085938 3.1171875  3.11523438 3.12109375\n",
      " 3.125      3.13085938 3.12304688 3.1015625  3.06640625 3.03125\n",
      " 2.984375   2.93359375 2.87695312 2.8203125  2.76171875 2.71289062\n",
      " 2.640625   2.58007812 2.4921875  2.41992188 2.3515625  2.30664062\n",
      " 2.28320312 2.28320312 2.2890625  2.30078125 2.30859375 2.3203125\n",
      " 2.30078125 2.28710938 2.26367188 2.25195312 2.23242188 2.22851562\n",
      " 2.23632812 2.25976562 2.27929688 2.30273438 2.3203125  2.34375\n",
      " 2.34375    2.34570312 2.34375    2.34375    2.34179688 2.34179688\n",
      " 2.33789062 2.33789062 2.31835938 2.30273438 2.27539062 2.2578125\n",
      " 2.2265625  2.20117188 2.171875   2.15625    2.1328125  2.12109375\n",
      " 2.1015625  2.08984375 2.0625     2.04101562 2.01757812 1.99511719\n",
      " 1.97167969 1.95117188 1.92871094 1.9140625  1.89257812 1.87207031\n",
      " 1.84765625 1.83203125 1.80664062 1.79199219 1.78027344 1.78125\n",
      " 1.78125    1.78710938 1.796875   1.81054688 1.79980469 1.79296875\n",
      " 1.75585938 1.7265625  1.68164062 1.64160156 1.61035156 1.58105469\n",
      " 1.55859375 1.5546875  1.55078125 1.54785156 1.53515625 1.52148438\n",
      " 1.5        1.47558594 1.4375     1.38867188 1.38085938 1.35742188\n",
      " 1.37304688 1.36816406 1.40039062 1.41601562 1.45703125 1.45214844\n",
      " 1.47167969 1.44726562 1.45117188 1.39648438 1.38769531 1.34277344\n",
      " 1.35449219 1.31933594 1.33886719 1.32714844 1.37011719 1.35449219\n",
      " 1.38867188 1.37695312 1.4140625  1.38476562 1.4140625  1.40136719\n",
      " 1.44140625 1.42871094 1.46875    1.47363281 1.52929688 1.53320312\n",
      " 1.58886719 1.61621094 1.67578125 1.6875     1.734375   1.75195312\n",
      " 1.796875   1.8046875  1.83984375 1.86621094 1.91210938 1.93164062\n",
      " 1.97558594 2.02734375 2.08203125 2.12890625 2.1953125  2.27148438\n",
      " 2.33398438 2.38085938 2.4375     2.48046875 2.51171875 2.54101562\n",
      " 2.56640625 2.58984375 2.59960938 2.62695312 2.65429688 2.68554688\n",
      " 2.72265625 2.765625   2.80664062 2.84375    2.87304688 2.90234375\n",
      " 2.91992188 2.93359375 2.93945312 2.95117188 2.9609375  2.98242188\n",
      " 3.00585938 3.03125    3.05273438 3.07617188 3.08984375 3.09375\n",
      " 3.08789062 3.07617188 3.0546875  3.03515625 3.0234375  3.015625\n",
      " 3.01367188 3.01953125 3.01757812 3.02148438 3.015625   3.00976562\n",
      " 2.99609375 2.98046875 2.95507812 2.93554688 2.91601562 2.90429688\n",
      " 2.90429688 2.91210938 2.92382812 2.9375     2.95117188 2.96679688\n",
      " 2.97265625 2.9765625  2.97070312 2.96484375 2.953125   2.94335938\n",
      " 2.93554688 2.93164062 2.92382812 2.92382812 2.921875   2.92382812\n",
      " 2.92773438 2.9296875  2.92773438 2.9296875  2.9296875  2.92773438\n",
      " 2.92578125 2.92773438 2.92773438 2.9296875  2.93164062 2.93945312\n",
      " 2.9453125  2.953125   2.95898438 2.96679688 2.97460938 2.98046875\n",
      " 2.984375   2.98828125 2.99023438 2.99414062 2.99414062 2.99609375\n",
      " 3.         3.         2.99609375 2.99414062 2.98828125 2.98046875\n",
      " 2.96679688 2.953125   2.93554688 2.921875   2.90429688 2.89453125\n",
      " 2.88085938 2.87304688 2.87109375 2.87109375 2.875      2.88085938\n",
      " 2.88085938 2.88085938 2.87304688 2.86523438 2.8515625  2.84179688\n",
      " 2.82617188 2.80859375 2.79492188 2.78515625 2.77734375 2.77539062\n",
      " 2.77539062 2.77929688 2.78125    2.78320312 2.78320312 2.78125\n",
      " 2.77734375 2.7734375  2.76171875 2.75195312 2.73632812 2.7265625\n",
      " 2.71484375 2.70898438 2.703125   2.69921875 2.6953125  2.6953125\n",
      " 2.69140625 2.6953125  2.69335938 2.68945312 2.6875     2.6875\n",
      " 2.68359375 2.67773438 2.67382812 2.671875   2.671875   2.67578125\n",
      " 2.67773438 2.68164062 2.68164062 2.6796875  2.67578125 2.66601562\n",
      " 2.65625    2.6484375  2.64453125 2.64648438 2.65039062 2.65429688\n",
      " 2.65820312 2.6640625  2.66796875 2.67382812 2.67382812 2.66992188\n",
      " 2.66210938 2.6484375  2.640625   2.62695312 2.61523438 2.60546875\n",
      " 2.59765625 2.59765625 2.6015625  2.609375   2.62304688 2.64453125\n",
      " 2.66796875 2.69335938 2.71679688 2.7421875  2.76171875 2.77929688\n",
      " 2.7890625  2.79882812 2.8046875  2.81445312 2.83398438 2.85742188\n",
      " 2.88085938 2.90625    2.93164062 2.953125   2.95898438 2.96289062\n",
      " 2.953125   2.94140625 2.91210938 2.88867188 2.86132812 2.83984375\n",
      " 2.81835938 2.8125     2.80859375 2.8125     2.80859375 2.8046875\n",
      " 2.78710938 2.7734375  2.74609375 2.72070312 2.68945312 2.66796875\n",
      " 2.64453125 2.63085938 2.62695312 2.625      2.62109375 2.61132812\n",
      " 2.6015625  2.59375    2.57226562 2.546875   2.52734375 2.50976562\n",
      " 2.48632812 2.47265625 2.46875    2.47070312 2.47460938 2.48242188\n",
      " 2.49023438 2.50390625 2.51171875 2.51171875 2.515625   2.515625\n",
      " 2.50976562 2.50195312 2.49023438 2.48242188 2.46875    2.46289062\n",
      " 2.45507812 2.453125   2.45117188 2.45507812 2.46289062 2.4765625\n",
      " 2.48046875 2.48828125 2.48632812 2.48046875 2.45507812 2.44140625\n",
      " 2.4140625  2.39648438 2.375      2.36523438 2.36132812 2.37109375\n",
      " 2.37695312 2.3828125  2.39453125 2.41601562 2.42578125 2.43554688\n",
      " 2.44921875 2.46875    2.4765625  2.48046875 2.49023438 2.5\n",
      " 2.50585938 2.50976562 2.515625   2.52734375 2.5234375  2.515625\n",
      " 2.5078125  2.49804688 2.484375   2.47070312 2.47070312 2.47851562\n",
      " 2.50390625 2.54492188 2.61328125 2.703125   2.82617188 2.95898438\n",
      " 2.        ]\n",
      "shape P and P[0]= (69, 481) [ 0.14765     0.24620616  0.38609298  0.54770812  0.69877174  0.80467\n",
      "  0.83951841  0.79445918  0.68065645  0.52616575  0.36777     0.24038877\n",
      "  0.16732425  0.15423599  0.188496    0.24389     0.28903857  0.29689656\n",
      "  0.25252385  0.15700008  0.026614   -0.11212753 -0.22999219 -0.30279421\n",
      " -0.31737032 -0.2744     -0.18771331 -0.08068719  0.01902944  0.08503331\n",
      "  0.096731    0.04224923 -0.08046286 -0.26407821 -0.49343226 -0.74773\n",
      " -1.00312891 -1.2355386  -1.42351319 -1.55102961 -1.6098     -1.60065892\n",
      " -1.53359286 -1.42618454 -1.30059509 -1.1796     -1.08249414 -1.02177189\n",
      " -1.00132199 -1.01649281 -1.0559     -1.10441706 -1.14654373 -1.16935372\n",
      " -1.16445981 -1.1288     -1.06440542 -0.97753677 -0.87760832 -0.77617626\n",
      " -0.68604    -0.6203075  -0.59120894 -0.60854277 -0.67786552 -0.79879\n",
      " -0.96391581 -1.15889032 -1.36386816 -1.55626373 -1.7143     -1.82058585\n",
      " -1.86490891 -1.84563356 -1.76948026 -1.6499     -1.50459474 -1.35286057\n",
      " -1.21331431 -1.10227084 -1.0327     -1.01345863 -1.04846901 -1.13571589\n",
      " -1.26627402 -1.4239     -1.58585607 -1.72546887 -1.81646075 -1.83844857\n",
      " -1.7824     -1.65450716 -1.47705525 -1.28546892 -1.12168847 -1.0251\n",
      " -1.0230946  -1.12367436 -1.31220556 -1.55347867 -1.7989     -1.99727069\n",
      " -2.10658994 -2.10395248 -1.99101602 -1.7936     -1.55545831 -1.32775095\n",
      " -1.15682987 -1.07336804 -1.0855     -1.17761327 -1.31500994 -1.45321363\n",
      " -1.5495863  -1.5744     -1.51868375 -1.39696516 -1.24424155 -1.10785413\n",
      " -1.0361     -1.06615452 -1.21404708 -1.46901464 -1.79364449 -2.13\n",
      " -2.41064319 -2.57238331 -2.56991333 -2.38639868 -2.0386     -1.57517067\n",
      " -1.06817659 -0.59935987 -0.24388863 -0.055013   -0.05299191 -0.22083465\n",
      " -0.50795862 -0.84110723 -1.1402     -1.3356053  -1.38293948 -1.27202499\n",
      " -1.02798288 -0.70428    -0.36945523 -0.09074117  0.08149309  0.124805\n",
      "  0.048723   -0.10899876 -0.29277282 -0.44348113 -0.51306928 -0.47585\n",
      " -0.33385619 -0.11514056  0.13429922  0.362734    0.52587     0.59765741\n",
      "  0.57613024  0.48299244  0.35726539  0.24478     0.18627542  0.20712861\n",
      "  0.31124436  0.48052752  0.67993     0.86667394  1.00124201  1.05733641\n",
      "  1.0283223   0.9286      0.78965118  0.65185095  0.55419082  0.524558\n",
      "  0.57304     0.6899205   0.84880827  1.01401056  1.15016877  1.2316\n",
      "  1.24888373  1.21097507  1.14232014  1.07578172  1.0433      1.06681535\n",
      "  1.15190487  1.28584983  1.44065438  1.5802      1.66960764  1.68429405\n",
      "  1.6163083   1.47629091  1.2906      1.09446378  0.92308186  0.80311713\n",
      "  0.74685594  0.75052     0.79701838  0.86217469  0.92250711  0.96224808\n",
      "  0.97757     0.9768476   0.97698     0.99696947  1.05076576  1.1416\n",
      "  1.25958732  1.38340345  1.48562222  1.54019638  1.5299      1.45152564\n",
      "  1.3172587   1.15175398  0.98569749  0.84768     0.75672622  0.71765654\n",
      "  0.72064446  0.74510462  0.76676     0.76577243  0.73346984  0.67558208\n",
      "  0.61090668  0.56568     0.56523405  0.62538686  0.74617779  0.90995408\n",
      "  1.0846      1.23121752  1.31424447  1.31122092  1.21942417  1.0574\n",
      "  0.86080599  0.67356377  0.53664512  0.4775107   0.50308     0.5981685\n",
      "  0.72984426  0.85654244  0.93947996  0.95329     0.89301328  0.77557394\n",
      "  0.63535263  0.5150414   0.4542      0.47850943  0.59250029  0.77759862\n",
      "  0.99594738  1.199       1.33872027  1.3786436   1.30217545  1.11625956\n",
      "  0.84972     0.54685725  0.25794522  0.02889166 -0.10762452 -0.13771\n",
      " -0.06754445  0.07954777  0.26926509  0.46413194  0.63112     0.74748049\n",
      "  0.80373147  0.80348091  0.76050575  0.69408     0.62383412  0.56538886\n",
      "  0.52767663  0.51234477  0.51507     0.52814715  0.54346067  0.55495537\n",
      "  0.55997326  0.55923     0.55564142  0.55254798  0.55202679  0.55389265\n",
      "  0.55571     0.55376263  0.54458543  0.52646528  0.50033317  0.46969\n",
      "  0.43955965  0.4148226   0.39852558  0.39079845  0.38882     0.38791735\n",
      "  0.38347882  0.37304598  0.35784134  0.34313     0.33716966  0.34896271\n",
      "  0.38543591  0.4488997   0.5356      0.63587449  0.73595668  0.82097889\n",
      "  0.87836743  0.90071     0.8873403   0.8442691   0.78257001  0.7157477\n",
      "  0.65685     0.61607148  0.59935769  0.60815276  0.64007     0.69003\n",
      "  0.75137061  0.81658619  0.87762252  0.92592505  0.9526      0.94903159\n",
      "  0.90810807  0.82591207  0.70344246  0.54777     0.37206461  0.19417759\n",
      "  0.0338536  -0.09093128 -0.16769    -0.19227698 -0.1700889  -0.11519804\n",
      " -0.04750145  0.011532    0.04356807  0.03747811 -0.0081915  -0.08496257\n",
      " -0.17649    -0.26252366 -0.3238979  -0.34742026 -0.32951481 -0.27771\n",
      " -0.20950384 -0.14870788 -0.11995285 -0.14251094 -0.22484    -0.36120792\n",
      " -0.53138941 -0.70379378 -0.84160025 -0.91072    -0.88786028 -0.76679375\n",
      " -0.56121758 -0.30329183 -0.037932    0.18603618  0.32593701  0.35422519\n",
      "  0.26428393  0.071668   -0.18948889 -0.47400775 -0.73529694 -0.93477388\n",
      " -1.0489     -1.07234328 -1.01682946 -0.90635083 -0.77026596 -0.63622\n",
      " -0.52466182 -0.4461115  -0.40144979 -0.38463381 -0.38664    -0.39924827\n",
      " -0.41752788 -0.44044823 -0.46971576 -0.50751    -0.55409142 -0.60621216\n",
      " -0.65692282 -0.69686708 -0.71666    -0.70960934 -0.6739484  -0.6139104\n",
      " -0.53931645 -0.46376    -0.40182918 -0.3660295  -0.36411323 -0.39740049\n",
      " -0.46044    -0.54206575 -0.62762228 -0.70190121 -0.75218891 -0.77079\n",
      " -0.75647418 -0.71449277 -0.65510565 -0.59090018 -0.5335     -0.49046526\n",
      " -0.46320173 -0.44648675 -0.42981188 -0.40023    -0.34592501 -0.25945086\n",
      " -0.13962492  0.00856698  0.17608     0.3532816   0.5336171   0.71614552\n",
      "  0.90591156  1.1118      1.34238719  1.60107532  1.88218909  2.16955745\n",
      "  2.4384      2.66028359  2.80984554  2.87126356  2.84236608  2.7349\n",
      "  2.57064673  2.37444302  2.16626756  1.95500518  1.7361      1.49413662\n",
      "  1.20979023  0.86907197  0.47187672  0.036857   -0.39935482 -0.78884955\n",
      " -1.08345594 -1.24698872 -1.2651     -1.14967838 -0.93629394 -0.67525556\n",
      " -0.41878631 -0.20802    -0.06358937  0.01751703  0.05807012  0.09107033\n",
      "  2.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 2 shape(new5)= (690, 486)\tmx= 4.67578125\tmn= 1.013671875\n",
      "\n",
      "260 = 690\n",
      "\n",
      "\n",
      "\n",
      " Class  2  Shape =  (100, 481)\n",
      "for class  2 number of windows is =  (481,)\n",
      "GAN Train Data shape= (138, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:881: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:881: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal cluster number:  3\n",
      "class= 2 cluster= 0 epochs= 4000  >> shape generate =  (640000, 483)\n",
      "class= 2 cluster= 1 epochs= 1110  >> shape generate =  (333000, 483)\n",
      "class= 2 cluster= 2 epochs= 3030  >> shape generate =  (606000, 483)\n",
      "cls  2  final shape, Generated by GAN = (690, 483)\n",
      "shape and aug[0]= (481,) [3.2109375  3.69140625 3.60351562 3.50390625 3.43164062 3.22851562\n",
      " 2.94140625 2.65429688 2.46289062 2.41796875 2.56445312 2.74804688\n",
      " 2.90429688 3.04492188 3.14453125 3.13867188 3.09179688 3.04492188\n",
      " 3.0234375  2.99414062 3.00195312 3.0390625  3.08398438 3.125\n",
      " 3.15625    3.16015625 3.1484375  3.1171875  3.00976562 2.890625\n",
      " 2.77734375 2.65039062 2.52929688 2.41601562 2.31445312 2.21875\n",
      " 2.18164062 2.15625    2.15234375 2.1484375  2.16015625 2.15234375\n",
      " 2.1640625  2.16210938 2.16992188 2.15429688 2.140625   2.11132812\n",
      " 2.08789062 2.05859375 2.03320312 1.99804688 1.98632812 1.97070312\n",
      " 1.96582031 1.95019531 1.95703125 1.94238281 1.95703125 1.95410156\n",
      " 1.96972656 1.96484375 1.98144531 1.97265625 1.98242188 1.9609375\n",
      " 1.9609375  1.93945312 1.93164062 1.91113281 1.91601562 1.89648438\n",
      " 1.90039062 1.8828125  1.88964844 1.88671875 1.90039062 1.89453125\n",
      " 1.91796875 1.90820312 1.92578125 1.91015625 1.92382812 1.90820312\n",
      " 1.90527344 1.87792969 1.88378906 1.85546875 1.84863281 1.80761719\n",
      " 1.8046875  1.77734375 1.78222656 1.75390625 1.765625   1.75292969\n",
      " 1.7734375  1.75097656 1.76757812 1.76269531 1.78515625 1.75195312\n",
      " 1.7734375  1.74902344 1.76464844 1.72753906 1.73632812 1.71191406\n",
      " 1.72167969 1.67578125 1.68457031 1.66015625 1.67382812 1.63476562\n",
      " 1.64550781 1.62792969 1.64746094 1.60546875 1.61914062 1.58886719\n",
      " 1.60839844 1.55859375 1.57324219 1.54589844 1.55859375 1.49707031\n",
      " 1.50878906 1.47070312 1.48242188 1.42480469 1.42578125 1.39355469\n",
      " 1.3984375  1.35449219 1.36816406 1.34179688 1.36132812 1.31640625\n",
      " 1.32910156 1.31054688 1.3203125  1.28417969 1.30078125 1.28125\n",
      " 1.296875   1.24707031 1.25683594 1.23925781 1.24902344 1.20898438\n",
      " 1.22167969 1.20214844 1.21386719 1.18359375 1.20117188 1.19335938\n",
      " 1.20507812 1.17675781 1.19335938 1.18261719 1.1875     1.15234375\n",
      " 1.15722656 1.13867188 1.13671875 1.10644531 1.09863281 1.08984375\n",
      " 1.0859375  1.06542969 1.05859375 1.05664062 1.0625     1.05371094\n",
      " 1.04882812 1.05371094 1.0625     1.0625     1.06933594 1.07421875\n",
      " 1.09863281 1.09472656 1.10351562 1.1171875  1.13964844 1.14550781\n",
      " 1.16601562 1.18261719 1.20117188 1.21289062 1.21972656 1.234375\n",
      " 1.24804688 1.24023438 1.26660156 1.26074219 1.2734375  1.26269531\n",
      " 1.28027344 1.28417969 1.296875   1.29882812 1.32421875 1.34277344\n",
      " 1.36523438 1.38964844 1.43554688 1.46289062 1.5        1.52734375\n",
      " 1.57128906 1.59570312 1.63378906 1.66992188 1.71386719 1.74511719\n",
      " 1.7734375  1.78710938 1.82617188 1.84472656 1.875      1.90429688\n",
      " 1.94140625 1.9765625  2.00195312 2.02734375 2.06445312 2.10351562\n",
      " 2.14648438 2.1875     2.22851562 2.26757812 2.31054688 2.34765625\n",
      " 2.38476562 2.421875   2.45898438 2.48632812 2.51171875 2.52929688\n",
      " 2.546875   2.56445312 2.58984375 2.61328125 2.6328125  2.66015625\n",
      " 2.67773438 2.68554688 2.69921875 2.71875    2.73828125 2.75\n",
      " 2.76757812 2.77929688 2.7890625  2.79882812 2.8046875  2.82421875\n",
      " 2.83203125 2.85351562 2.86328125 2.89257812 2.89257812 2.91015625\n",
      " 2.90820312 2.93359375 2.9375     2.93945312 2.9375     2.93945312\n",
      " 2.92578125 2.93359375 2.91601562 2.91601562 2.91210938 2.9140625\n",
      " 2.90820312 2.91210938 2.91015625 2.90039062 2.89453125 2.88476562\n",
      " 2.88085938 2.87695312 2.86523438 2.859375   2.859375   2.85742188\n",
      " 2.84960938 2.8515625  2.86328125 2.859375   2.84960938 2.84765625\n",
      " 2.84960938 2.83789062 2.82421875 2.81835938 2.81054688 2.80664062\n",
      " 2.79296875 2.79101562 2.79101562 2.7890625  2.78710938 2.78710938\n",
      " 2.7890625  2.79296875 2.78710938 2.7890625  2.79101562 2.78320312\n",
      " 2.77539062 2.77539062 2.77734375 2.77929688 2.77734375 2.78320312\n",
      " 2.78710938 2.79492188 2.79296875 2.796875   2.79882812 2.80664062\n",
      " 2.8046875  2.79492188 2.7890625  2.77734375 2.7734375  2.7734375\n",
      " 2.78320312 2.80664062 2.80859375 2.8203125  2.84375    2.84570312\n",
      " 2.84179688 2.83984375 2.83203125 2.82617188 2.81445312 2.80859375\n",
      " 2.81640625 2.82226562 2.83007812 2.84179688 2.859375   2.875\n",
      " 2.88085938 2.88085938 2.87304688 2.86523438 2.84960938 2.83984375\n",
      " 2.83007812 2.82226562 2.80859375 2.81054688 2.81445312 2.828125\n",
      " 2.82617188 2.82617188 2.828125   2.83203125 2.83007812 2.828125\n",
      " 2.82226562 2.83007812 2.82421875 2.828125   2.83007812 2.83789062\n",
      " 2.83984375 2.83007812 2.81445312 2.828125   2.81054688 2.8125\n",
      " 2.80273438 2.80273438 2.8125     2.81640625 2.82226562 2.83398438\n",
      " 2.83398438 2.83984375 2.84375    2.84375    2.83203125 2.83007812\n",
      " 2.81640625 2.80273438 2.78515625 2.76757812 2.7578125  2.7578125\n",
      " 2.75585938 2.76367188 2.7734375  2.77734375 2.78320312 2.78710938\n",
      " 2.79492188 2.80078125 2.80273438 2.80078125 2.79882812 2.79101562\n",
      " 2.78320312 2.7734375  2.76367188 2.765625   2.76367188 2.76171875\n",
      " 2.75390625 2.75585938 2.75195312 2.7421875  2.734375   2.73828125\n",
      " 2.73242188 2.72265625 2.71875    2.72070312 2.7265625  2.72460938\n",
      " 2.734375   2.75585938 2.76367188 2.77148438 2.78515625 2.80273438\n",
      " 2.81054688 2.80664062 2.8046875  2.80664062 2.79101562 2.7890625\n",
      " 2.77734375 2.77148438 2.7578125  2.74804688 2.74414062 2.75195312\n",
      " 2.74804688 2.75585938 2.75976562 2.77148438 2.78125    2.7890625\n",
      " 2.79296875 2.80859375 2.8046875  2.80664062 2.80664062 2.81445312\n",
      " 2.80664062 2.81054688 2.80859375 2.80859375 2.8046875  2.80664062\n",
      " 2.80664062 2.82226562 2.83203125 2.84375    2.85351562 2.87890625\n",
      " 2.89257812 2.90625    2.92382812 2.93554688 2.95117188 2.95898438\n",
      " 2.98632812 3.01757812 3.046875   3.0859375  3.10546875 3.1640625\n",
      " 2.        ]\n",
      "shape P and P[0]= (69, 481) [ 0.14765     0.24620616  0.38609298  0.54770812  0.69877174  0.80467\n",
      "  0.83951841  0.79445918  0.68065645  0.52616575  0.36777     0.24038877\n",
      "  0.16732425  0.15423599  0.188496    0.24389     0.28903857  0.29689656\n",
      "  0.25252385  0.15700008  0.026614   -0.11212753 -0.22999219 -0.30279421\n",
      " -0.31737032 -0.2744     -0.18771331 -0.08068719  0.01902944  0.08503331\n",
      "  0.096731    0.04224923 -0.08046286 -0.26407821 -0.49343226 -0.74773\n",
      " -1.00312891 -1.2355386  -1.42351319 -1.55102961 -1.6098     -1.60065892\n",
      " -1.53359286 -1.42618454 -1.30059509 -1.1796     -1.08249414 -1.02177189\n",
      " -1.00132199 -1.01649281 -1.0559     -1.10441706 -1.14654373 -1.16935372\n",
      " -1.16445981 -1.1288     -1.06440542 -0.97753677 -0.87760832 -0.77617626\n",
      " -0.68604    -0.6203075  -0.59120894 -0.60854277 -0.67786552 -0.79879\n",
      " -0.96391581 -1.15889032 -1.36386816 -1.55626373 -1.7143     -1.82058585\n",
      " -1.86490891 -1.84563356 -1.76948026 -1.6499     -1.50459474 -1.35286057\n",
      " -1.21331431 -1.10227084 -1.0327     -1.01345863 -1.04846901 -1.13571589\n",
      " -1.26627402 -1.4239     -1.58585607 -1.72546887 -1.81646075 -1.83844857\n",
      " -1.7824     -1.65450716 -1.47705525 -1.28546892 -1.12168847 -1.0251\n",
      " -1.0230946  -1.12367436 -1.31220556 -1.55347867 -1.7989     -1.99727069\n",
      " -2.10658994 -2.10395248 -1.99101602 -1.7936     -1.55545831 -1.32775095\n",
      " -1.15682987 -1.07336804 -1.0855     -1.17761327 -1.31500994 -1.45321363\n",
      " -1.5495863  -1.5744     -1.51868375 -1.39696516 -1.24424155 -1.10785413\n",
      " -1.0361     -1.06615452 -1.21404708 -1.46901464 -1.79364449 -2.13\n",
      " -2.41064319 -2.57238331 -2.56991333 -2.38639868 -2.0386     -1.57517067\n",
      " -1.06817659 -0.59935987 -0.24388863 -0.055013   -0.05299191 -0.22083465\n",
      " -0.50795862 -0.84110723 -1.1402     -1.3356053  -1.38293948 -1.27202499\n",
      " -1.02798288 -0.70428    -0.36945523 -0.09074117  0.08149309  0.124805\n",
      "  0.048723   -0.10899876 -0.29277282 -0.44348113 -0.51306928 -0.47585\n",
      " -0.33385619 -0.11514056  0.13429922  0.362734    0.52587     0.59765741\n",
      "  0.57613024  0.48299244  0.35726539  0.24478     0.18627542  0.20712861\n",
      "  0.31124436  0.48052752  0.67993     0.86667394  1.00124201  1.05733641\n",
      "  1.0283223   0.9286      0.78965118  0.65185095  0.55419082  0.524558\n",
      "  0.57304     0.6899205   0.84880827  1.01401056  1.15016877  1.2316\n",
      "  1.24888373  1.21097507  1.14232014  1.07578172  1.0433      1.06681535\n",
      "  1.15190487  1.28584983  1.44065438  1.5802      1.66960764  1.68429405\n",
      "  1.6163083   1.47629091  1.2906      1.09446378  0.92308186  0.80311713\n",
      "  0.74685594  0.75052     0.79701838  0.86217469  0.92250711  0.96224808\n",
      "  0.97757     0.9768476   0.97698     0.99696947  1.05076576  1.1416\n",
      "  1.25958732  1.38340345  1.48562222  1.54019638  1.5299      1.45152564\n",
      "  1.3172587   1.15175398  0.98569749  0.84768     0.75672622  0.71765654\n",
      "  0.72064446  0.74510462  0.76676     0.76577243  0.73346984  0.67558208\n",
      "  0.61090668  0.56568     0.56523405  0.62538686  0.74617779  0.90995408\n",
      "  1.0846      1.23121752  1.31424447  1.31122092  1.21942417  1.0574\n",
      "  0.86080599  0.67356377  0.53664512  0.4775107   0.50308     0.5981685\n",
      "  0.72984426  0.85654244  0.93947996  0.95329     0.89301328  0.77557394\n",
      "  0.63535263  0.5150414   0.4542      0.47850943  0.59250029  0.77759862\n",
      "  0.99594738  1.199       1.33872027  1.3786436   1.30217545  1.11625956\n",
      "  0.84972     0.54685725  0.25794522  0.02889166 -0.10762452 -0.13771\n",
      " -0.06754445  0.07954777  0.26926509  0.46413194  0.63112     0.74748049\n",
      "  0.80373147  0.80348091  0.76050575  0.69408     0.62383412  0.56538886\n",
      "  0.52767663  0.51234477  0.51507     0.52814715  0.54346067  0.55495537\n",
      "  0.55997326  0.55923     0.55564142  0.55254798  0.55202679  0.55389265\n",
      "  0.55571     0.55376263  0.54458543  0.52646528  0.50033317  0.46969\n",
      "  0.43955965  0.4148226   0.39852558  0.39079845  0.38882     0.38791735\n",
      "  0.38347882  0.37304598  0.35784134  0.34313     0.33716966  0.34896271\n",
      "  0.38543591  0.4488997   0.5356      0.63587449  0.73595668  0.82097889\n",
      "  0.87836743  0.90071     0.8873403   0.8442691   0.78257001  0.7157477\n",
      "  0.65685     0.61607148  0.59935769  0.60815276  0.64007     0.69003\n",
      "  0.75137061  0.81658619  0.87762252  0.92592505  0.9526      0.94903159\n",
      "  0.90810807  0.82591207  0.70344246  0.54777     0.37206461  0.19417759\n",
      "  0.0338536  -0.09093128 -0.16769    -0.19227698 -0.1700889  -0.11519804\n",
      " -0.04750145  0.011532    0.04356807  0.03747811 -0.0081915  -0.08496257\n",
      " -0.17649    -0.26252366 -0.3238979  -0.34742026 -0.32951481 -0.27771\n",
      " -0.20950384 -0.14870788 -0.11995285 -0.14251094 -0.22484    -0.36120792\n",
      " -0.53138941 -0.70379378 -0.84160025 -0.91072    -0.88786028 -0.76679375\n",
      " -0.56121758 -0.30329183 -0.037932    0.18603618  0.32593701  0.35422519\n",
      "  0.26428393  0.071668   -0.18948889 -0.47400775 -0.73529694 -0.93477388\n",
      " -1.0489     -1.07234328 -1.01682946 -0.90635083 -0.77026596 -0.63622\n",
      " -0.52466182 -0.4461115  -0.40144979 -0.38463381 -0.38664    -0.39924827\n",
      " -0.41752788 -0.44044823 -0.46971576 -0.50751    -0.55409142 -0.60621216\n",
      " -0.65692282 -0.69686708 -0.71666    -0.70960934 -0.6739484  -0.6139104\n",
      " -0.53931645 -0.46376    -0.40182918 -0.3660295  -0.36411323 -0.39740049\n",
      " -0.46044    -0.54206575 -0.62762228 -0.70190121 -0.75218891 -0.77079\n",
      " -0.75647418 -0.71449277 -0.65510565 -0.59090018 -0.5335     -0.49046526\n",
      " -0.46320173 -0.44648675 -0.42981188 -0.40023    -0.34592501 -0.25945086\n",
      " -0.13962492  0.00856698  0.17608     0.3532816   0.5336171   0.71614552\n",
      "  0.90591156  1.1118      1.34238719  1.60107532  1.88218909  2.16955745\n",
      "  2.4384      2.66028359  2.80984554  2.87126356  2.84236608  2.7349\n",
      "  2.57064673  2.37444302  2.16626756  1.95500518  1.7361      1.49413662\n",
      "  1.20979023  0.86907197  0.47187672  0.036857   -0.39935482 -0.78884955\n",
      " -1.08345594 -1.24698872 -1.2651     -1.14967838 -0.93629394 -0.67525556\n",
      " -0.41878631 -0.20802    -0.06358937  0.01751703  0.05807012  0.09107033\n",
      "  2.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 2 shape(new5)= (690, 486)\tmx= 4.66796875\tmn= 1.001953125\n",
      "\n",
      "261 = 690\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,3):\n",
    "    aug_pls60,aug_pls61=2,3 #2 is MgWrp and 3 is TimeWrp Augmentes Data for Training GAN\n",
    "    vars()['ecg_aug'+str(i)+'60']=np.append(vars()['ecg_aug'+str(i)+'60'],GAN_Gnrt(ecg,i,aug_pls60),axis=0)\n",
    "    addqlty(base_wn,vars()['ecg_aug'+str(i)+'60'],60,i)\n",
    "    print(str(i)+'60 =',len(vars()['ecg_aug'+str(i)+'60']))\n",
    "    vars()['ecg_aug'+str(i)+'61']=np.append(vars()['ecg_aug'+str(i)+'61'],GAN_Gnrt(ecg,i,aug_pls61),axis=0)\n",
    "    addqlty(base_wn,vars()['ecg_aug'+str(i)+'61'],61,i)\n",
    "    print(str(i)+'61 =',len(vars()['ecg_aug'+str(i)+'61']))\n",
    "    #xtrain=np.append(xtrain,vars()['ecg_aug60'+str(i)],axis=0)\n",
    "    \n",
    "    aug_pls70,aug_pls71=2,3 #2 is MgWrp and 3 is TimeWrp Augmentes Data for LSTM Augmentation\n",
    "    vars()['ecg_aug'+str(i)+'70']=np.append(vars()['ecg_aug'+str(i)+'70'],LSTM_Gnrt_Pridc(ecg,i,aug_pls70),axis=0)\n",
    "    addqlty(base_wn,vars()['ecg_aug'+str(i)+'70'],70,i)\n",
    "    print(str(i)+'70 =',len(vars()['ecg_aug'+str(i)+'70']))\n",
    "    vars()['ecg_aug'+str(i)+'71']=np.append(vars()['ecg_aug'+str(i)+'71'],LSTM_Gnrt_Pridc(ecg,i,aug_pls71),axis=0)\n",
    "    addqlty(base_wn,vars()['ecg_aug'+str(i)+'71'],71,i)\n",
    "    print(str(i)+'71 =',len(vars()['ecg_aug'+str(i)+'71']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544fc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
