{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import time\n",
    "plc=1\n",
    "time.sleep(3000*plc)         #run after 1 houre = 3600 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#notebook { padding-top:0px !important; } .container { width:100% !important; } .end_space { min-height:0px !important; } html, body, .container{ margin:0!important;padding:0!important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "import random\n",
    "import bisect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess import *                         #ماژول استخراج پنجره ها\n",
    "from data import *                          #ماژول محلی ورود داده ها\n",
    "from augment import *                            #ماژول های داده افزایی\n",
    "from lstm_cnn import *                           #ماژول های داده افزایی با lstm_cnn\n",
    "import augment\n",
    "import importlib\n",
    "importlib.reload(augment)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report,recall_score,precision_score\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D,Conv1D,Dropout,MaxPooling1D,MaxPooling2D,Flatten,Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "cwd = os.getcwd() #\n",
    "fullscrn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><div style=\"direction:rtl;font-family:B Nazanin\">Importing Data</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_train_shape= (155, 1093)\n",
      "first_test_shape= (308, 1093)\n",
      "classes_quantity= 5\n",
      "tr_lbls=\t {1, 2, 3, 4, 5}\n",
      "Count_labels= [18 34 34 36 33]\n",
      "max(train_feature_Altitude)= 5.0\n",
      "min(train_feature_Altitude)= -11.147\n",
      "first_train_sample=\n",
      " [ 5.      -1.0475   0.54834 ...  0.89676 -2.6913  -8.1963 ]\n",
      "1 18\t2 34\t3 34\t4 36\t5 33\t"
     ]
    }
   ],
   "source": [
    "rate=1092\n",
    "cls_num=5\n",
    "btch=20\n",
    "for i in range (1,cls_num+1):\n",
    "    vars()['ecg'+str(i)],vars()['ecg_tst'+str(i)]=Haptics0(i)\n",
    "\n",
    "os.chdir(cwd)\n",
    "clses_lens=np.array([])\n",
    "i=0                               #جمع آوری داده ها و چاپ تعداد نمونه ی هر کلاس\n",
    "ecg=np.array(ecg1)\n",
    "print(1,len(vars()['ecg'+str(1)]), end='\\t')\n",
    "clses_lens=np.append(clses_lens,len(vars()['ecg'+str(1)]))\n",
    "for i in range (2,cls_num+1):\n",
    "    ecg=np.concatenate((ecg,vars()['ecg'+str(i)]),axis=0)\n",
    "    clses_lens=np.append(clses_lens,len(vars()['ecg'+str(i)]))\n",
    "    print(i,len(vars()['ecg'+str(i)]), end='\\t')\n",
    "\n",
    "mx_sig=max(clses_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 1093)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 4., 4., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center><div style=\"direction:rtl;font-family:B Nazanin\">Base Train windows</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each class and its windows =\n",
      "1 18\t2 34\t3 34\t4 36\t5 33\t\n",
      " max = 36\n"
     ]
    }
   ],
   "source": [
    "smpl_rte=rate                                              # در ماژول ها نیز همین مقدار ثبت شده\n",
    "i=0\n",
    "windws=np.array([])\n",
    "\n",
    "for cls in range (1,cls_num+1):                                 #ساخت پنجره های داده های آموزش اصلی\n",
    "    vars()['wndws'+str(cls)]=np.array(vars()['ecg'+str(cls)])  \n",
    "    \n",
    "print(\"each class and its windows =\")\n",
    "\n",
    "cls_wndws=np.array([])\n",
    "for cls in range (1,cls_num+1):                                # آرایه ی تعداد پنجره ی هر کلاس\n",
    "    wns=len(vars()['wndws'+str(cls)])\n",
    "    cls_wndws=np.append(cls_wndws,wns)\n",
    "    print(cls, wns, end='\\t')\n",
    "\n",
    "mx_wndws=int(np.max(cls_wndws))                        # حداکثر تعداد پنجره ی موجود بین کلاس ها\n",
    "print('\\n max =', mx_wndws)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#clses=3                                   #تعیین میزان افزایش نمونه (تولید داده)\n",
    "mx_wndws=int(mx_wndws)  #mx_wndws*0.3  # =classes-1 برای بررسی الگوریتم تعداد کمی کلاس آزمایش شد\n",
    "mx_wndws=2598           #+2\n",
    "print(mx_wndws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><div style=\"direction:rtl;font-family:B Nazanin\">Data Augmentation</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up to class  1 train shape =  (18, 1093)\n",
      "Up to class  2 train shape =  (52, 1093)\n",
      "Up to class  3 train shape =  (86, 1093)\n",
      "Up to class  4 train shape =  (122, 1093)\n",
      "Up to class  5 train shape =  (155, 1093)\n"
     ]
    }
   ],
   "source": [
    "smpl_rte=len(wndws1[0])                                        # در ماژول ها نیز همین مقدار ثبت شده\n",
    "\n",
    "#add augmented data to base data\n",
    "xtrain=np.empty((0,len(wndws1[0])), float) \n",
    "for i in range (1,cls_num+1):   \n",
    "    xtrain=np.append(xtrain,vars()['wndws'+str(i)],axis=0)\n",
    "    print('Up to class ', i, 'train shape = ', np.shape(xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 18 34 34 36 33]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(np.int16(xtrain[:,-1])))    #تعداد پنجره در هر کلاس از 0 تا 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 4., 4., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_aug=np.max(xtrain[:,:-1])\n",
    "mx=np.max(ecg[:,:-1])\n",
    "mn_aug=np.min(xtrain[:,:-1])\n",
    "mn=np.min(ecg[:,:-1])\n",
    "\n",
    "#for i in range (1,cls_num+1):             #نرمالسازی داده های افزایشی\n",
    "xtrain[:,:-1]= 2*(xtrain[:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min trn = -1.0\n",
      "max trn = 1.0\n"
     ]
    }
   ],
   "source": [
    "print('min trn =', np.min(xtrain[:,:-1]))\n",
    "print('max trn =', np.max(xtrain[:,:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center><div style=\"direction:rtl;font-family:B Nazanin\">Test Windows</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wndws_test=np.empty((0,len(wndws1[0])), float)\n",
    "i=0\n",
    "windws=np.array([])\n",
    "for cls in range (1,cls_num+1):                                 #ساخت پنجره های داده های آموزش اصلی\n",
    "    vars()['wndws_tst'+str(cls)]=np.empty((0,len(wndws1[0])), float)\n",
    "    vars()['wndws_tst'+str(cls)]=np.append(vars()['wndws_tst'+str(cls)],vars()['ecg_tst'+str(cls)],axis=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " cls 1  >> \n",
      "max magnitude class 1  =  3.903199999999999\n",
      "min magnitude class 1  =  -14.859999999999998\n",
      "after normalizing >>\n",
      "max magnitude class 1  =  1.1093335015171584\n",
      "min magnitude class 1  =  -1.5203887849419413\n",
      "\n",
      " cls 2  >> \n",
      "max magnitude class 2  =  2.7426000000000004\n",
      "min magnitude class 2  =  -10.213999999999999\n",
      "after normalizing >>\n",
      "max magnitude class 2  =  0.9466717121814145\n",
      "min magnitude class 2  =  -0.8692370761242035\n",
      "\n",
      " cls 3  >> \n",
      "max magnitude class 3  =  2.9853\n",
      "min magnitude class 3  =  -10.375999999999998\n",
      "after normalizing >>\n",
      "max magnitude class 3  =  0.9806868907716135\n",
      "min magnitude class 3  =  -0.8919418924884895\n",
      "\n",
      " cls 4  >> \n",
      "max magnitude class 4  =  2.5669999999999997\n",
      "min magnitude class 4  =  -9.867799999999999\n",
      "after normalizing >>\n",
      "max magnitude class 4  =  0.9220608124680276\n",
      "min magnitude class 4  =  -0.8207160426345994\n",
      "\n",
      " cls 5  >> \n",
      "max magnitude class 5  =  2.8078999999999996\n",
      "min magnitude class 5  =  -10.584999999999997\n",
      "after normalizing >>\n",
      "max magnitude class 5  =  0.9558237153208458\n",
      "min magnitude class 5  =  -0.9212339086621674\n",
      "each class and its windows =\n",
      "1 60\t2 58\t3 59\t4 64\t5 67\t\n",
      " max instance in classes of test windows = 67\n"
     ]
    }
   ],
   "source": [
    "#print(np.max(wndws_tst))\n",
    "for i in range (1,cls_num+1):                # Normalization test windows\n",
    "    cls=i\n",
    "    print('\\n cls', i, ' >> ')\n",
    "    print('max magnitude class', i , ' = ' ,np.max(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "    print('min magnitude class', i , ' = ' ,np.min(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "\n",
    "    vars()['wndws_tst'+str(i)][:,:-1]= 2*(vars()['wndws_tst'+str(i)][:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1\n",
    "    \n",
    "    print('after normalizing >>')\n",
    "    print('max magnitude class', i , ' = ' ,np.max(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "    print('min magnitude class', i , ' = ' ,np.min(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "    \n",
    "print(\"each class and its windows =\")                    #تجمیع کلاس های تست\n",
    "cls_wndws=np.array([])\n",
    "for cls in range (1,cls_num+1):                                # آرایه ی تعداد پنجره ی هر کلاس\n",
    "    wns=len(vars()['wndws_tst'+str(cls)])\n",
    "    cls_wndws=np.append(cls_wndws,wns)\n",
    "    print(cls, wns, end='\\t')\n",
    "    wndws_test=np.append(wndws_test,vars()['wndws_tst'+str(cls)],axis=0)\n",
    "    \n",
    "mx_wndws=int(np.max(cls_wndws))                        # حداکثر تعداد پنجره ی موجود بین کلاس ها\n",
    "print('\\n max instance in classes of test windows =', mx_wndws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min tst = -1.5203887849419413\n",
      "max tst = 1.1093335015171584\n"
     ]
    }
   ],
   "source": [
    "print('min tst =', np.min(wndws_test[:,:-1]))\n",
    "print('max tst =', np.max(wndws_test[:,:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wndws_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 1093)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(wndws_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=wndws_test[:,:-1]\n",
    "ytest=np.int16(wndws_test[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
      "      dtype=int16)\n"
     ]
    }
   ],
   "source": [
    "fullprint(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center><div style=\"direction:rtl;font-family:B Nazanin\">Train Windows</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nytestt=np.int32(np.array([ytest]).T)\\ntestx=np.concatenate((Xtest, ytestt), axis=1)\\ntestx=np.random.permutation(testx)\\nXtest=np.int32(testx[:,:-1])\\nytest=np.int32(testx[:,-1])'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ytraint=np.int32(np.array([ytrain]).T)\n",
    "#trainx=np.concatenate((Xtrain, ytraint), axis=1)\n",
    "trainx=np.random.permutation(xtrain)\n",
    "Xtrain=np.array(trainx[:,:-1])\n",
    "ytrain=np.int16(trainx[:,-1])\n",
    "'''\n",
    "ytestt=np.int32(np.array([ytest]).T)\n",
    "testx=np.concatenate((Xtest, ytestt), axis=1)\n",
    "testx=np.random.permutation(testx)\n",
    "Xtest=np.int32(testx[:,:-1])\n",
    "ytest=np.int32(testx[:,-1])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 1093)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(wndws1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center><div style=\"direction:rtl;font-family:B Nazanin\">Validation Windows</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvalid=np.array(Xtrain)\n",
    "yvalid=np.array(ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><div style=\"direction:rtl;font-family:B Nazanin\">CNN And UnBalanced RAW Data</div></center></h1>\n",
    "<h1><center><div style=\"direction:rtl;font-family:Arial\">Cross Entropy Loss Function</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train =>  (155, 1092)\n",
      "y_train =>  (155,)\n",
      "X_test  =>  (308, 1092)\n",
      "y_test  =>  (308,)\n",
      "X_valid  =>  (155, 1092)\n",
      "y_valid  =>  (155,)\n"
     ]
    }
   ],
   "source": [
    "X_train=np.array(Xtrain)\n",
    "y_train=np.array(ytrain)\n",
    "X_test=np.array(Xtest)\n",
    "y_test=np.array(ytest)\n",
    "X_valid=np.array(Xtrain)\n",
    "y_valid=np.array(ytrain)\n",
    "print('X_train => ', X_train.shape)\n",
    "print('y_train => ', y_train.shape)\n",
    "print('X_test  => ', X_test.shape)\n",
    "print('y_test  => ', y_test.shape)\n",
    "print('X_valid  => ', X_valid.shape)\n",
    "print('y_valid  => ', y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array(y_train+1)\n",
    "y_test=np.array(y_test+1)\n",
    "y_valid=np.array(y_valid+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat=to_categorical(y_train)\n",
    "y_valid_cat=to_categorical(y_valid)\n",
    "y_test_cat=to_categorical(y_test)\n",
    "\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_valid = np.expand_dims(X_valid, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "#y_train=np.transpose([y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 3s 92ms/step - loss: 1.8720 - accuracy: 0.1742 - val_loss: 1.6728 - val_accuracy: 0.2129\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.6769 - accuracy: 0.2065 - val_loss: 1.6186 - val_accuracy: 0.2774\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6365 - accuracy: 0.2387 - val_loss: 1.6157 - val_accuracy: 0.2129\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6460 - accuracy: 0.1742 - val_loss: 1.5902 - val_accuracy: 0.2129\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6148 - accuracy: 0.1742 - val_loss: 1.5893 - val_accuracy: 0.2194\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6002 - accuracy: 0.1742 - val_loss: 1.5834 - val_accuracy: 0.2129\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6335 - accuracy: 0.1484 - val_loss: 1.6377 - val_accuracy: 0.2129\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6123 - accuracy: 0.2065 - val_loss: 1.5763 - val_accuracy: 0.2645\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.5989 - accuracy: 0.2065 - val_loss: 1.5693 - val_accuracy: 0.2710\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.5900 - accuracy: 0.2774 - val_loss: 1.5915 - val_accuracy: 0.2323\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5964 - accuracy: 0.3161 - val_loss: 1.5225 - val_accuracy: 0.3806\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.5602 - accuracy: 0.2968 - val_loss: 1.5391 - val_accuracy: 0.2452\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.5228 - accuracy: 0.3161 - val_loss: 1.4585 - val_accuracy: 0.3355\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4992 - accuracy: 0.3548 - val_loss: 1.4222 - val_accuracy: 0.4194\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.4686 - accuracy: 0.3935 - val_loss: 1.4276 - val_accuracy: 0.4129\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.4334 - accuracy: 0.4000 - val_loss: 1.7022 - val_accuracy: 0.1806\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4668 - accuracy: 0.2968 - val_loss: 1.3764 - val_accuracy: 0.4774\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.3957 - accuracy: 0.4774 - val_loss: 1.5046 - val_accuracy: 0.3613\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.4312 - accuracy: 0.3935 - val_loss: 1.4705 - val_accuracy: 0.3484\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.4399 - accuracy: 0.4129 - val_loss: 1.4869 - val_accuracy: 0.2903\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.3863 - accuracy: 0.4452 - val_loss: 1.2906 - val_accuracy: 0.5419\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4615 - accuracy: 0.5355 - val_loss: 1.2862 - val_accuracy: 0.5677\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3282 - accuracy: 0.4903 - val_loss: 1.2214 - val_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.2849 - accuracy: 0.5161 - val_loss: 1.2637 - val_accuracy: 0.4839\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.3268 - accuracy: 0.5032 - val_loss: 1.1897 - val_accuracy: 0.5742\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.2816 - accuracy: 0.4645 - val_loss: 1.3475 - val_accuracy: 0.4129\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.2574 - accuracy: 0.5097 - val_loss: 1.1656 - val_accuracy: 0.6194\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.2133 - accuracy: 0.5548 - val_loss: 1.3751 - val_accuracy: 0.4194\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.2330 - accuracy: 0.5419 - val_loss: 1.2516 - val_accuracy: 0.5419\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.2365 - accuracy: 0.5226 - val_loss: 1.1715 - val_accuracy: 0.5355\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1273 - accuracy: 0.5806 - val_loss: 1.0806 - val_accuracy: 0.5935\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1417 - accuracy: 0.5548 - val_loss: 1.0779 - val_accuracy: 0.5871\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.1462 - accuracy: 0.5742 - val_loss: 1.1165 - val_accuracy: 0.6000\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1098 - accuracy: 0.5806 - val_loss: 1.1732 - val_accuracy: 0.5355\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1921 - accuracy: 0.5484 - val_loss: 1.1305 - val_accuracy: 0.5677\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.1707 - accuracy: 0.5161 - val_loss: 1.0727 - val_accuracy: 0.6194\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.1113 - accuracy: 0.6129 - val_loss: 1.0185 - val_accuracy: 0.5871\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0325 - accuracy: 0.6258 - val_loss: 0.9580 - val_accuracy: 0.6710\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0874 - accuracy: 0.5613 - val_loss: 0.9647 - val_accuracy: 0.6645\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.1139 - accuracy: 0.5161 - val_loss: 0.9367 - val_accuracy: 0.6645\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9784 - accuracy: 0.6129 - val_loss: 0.9505 - val_accuracy: 0.6581\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9858 - accuracy: 0.6000 - val_loss: 0.9641 - val_accuracy: 0.5806\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9643 - accuracy: 0.5935 - val_loss: 1.1555 - val_accuracy: 0.4903\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9600 - accuracy: 0.5871 - val_loss: 1.0241 - val_accuracy: 0.5548\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9989 - accuracy: 0.5677 - val_loss: 0.8582 - val_accuracy: 0.6774\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8971 - accuracy: 0.6903 - val_loss: 0.9023 - val_accuracy: 0.6387\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9085 - accuracy: 0.5935 - val_loss: 0.7791 - val_accuracy: 0.7097\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8552 - accuracy: 0.6710 - val_loss: 0.8424 - val_accuracy: 0.6710\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8836 - accuracy: 0.6258 - val_loss: 0.7148 - val_accuracy: 0.7097\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8871 - accuracy: 0.6258 - val_loss: 0.7912 - val_accuracy: 0.6968\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8020 - accuracy: 0.6645 - val_loss: 0.8110 - val_accuracy: 0.7032\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8766 - accuracy: 0.6645 - val_loss: 0.7915 - val_accuracy: 0.6903\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7790 - accuracy: 0.6968 - val_loss: 0.6515 - val_accuracy: 0.7355\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7391 - accuracy: 0.7097 - val_loss: 0.7235 - val_accuracy: 0.7097\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7107 - accuracy: 0.6968 - val_loss: 0.6307 - val_accuracy: 0.7355\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.8425 - accuracy: 0.6516 - val_loss: 0.5995 - val_accuracy: 0.7677\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7199 - accuracy: 0.7097 - val_loss: 0.5959 - val_accuracy: 0.8065\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6160 - accuracy: 0.7677 - val_loss: 1.2265 - val_accuracy: 0.5613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7232 - accuracy: 0.7032 - val_loss: 0.4889 - val_accuracy: 0.8065\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6352 - accuracy: 0.7677 - val_loss: 0.7273 - val_accuracy: 0.6968\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5441 - accuracy: 0.7935 - val_loss: 0.5590 - val_accuracy: 0.7935\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5439 - accuracy: 0.7935 - val_loss: 0.5286 - val_accuracy: 0.7419\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6210 - accuracy: 0.7548 - val_loss: 0.4781 - val_accuracy: 0.7806\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4411 - accuracy: 0.8129 - val_loss: 0.4996 - val_accuracy: 0.7806\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5371 - accuracy: 0.7871 - val_loss: 0.4170 - val_accuracy: 0.8387\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6030 - accuracy: 0.7613 - val_loss: 0.4356 - val_accuracy: 0.8129\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3768 - accuracy: 0.8581 - val_loss: 0.4928 - val_accuracy: 0.8323\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3925 - accuracy: 0.8516 - val_loss: 0.6645 - val_accuracy: 0.7097\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4503 - accuracy: 0.8194 - val_loss: 0.4084 - val_accuracy: 0.8452\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5130 - accuracy: 0.7871 - val_loss: 0.5687 - val_accuracy: 0.7290\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3904 - accuracy: 0.8516 - val_loss: 0.3083 - val_accuracy: 0.8839\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3448 - accuracy: 0.8774 - val_loss: 0.1960 - val_accuracy: 0.9355\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4384 - accuracy: 0.8258 - val_loss: 0.2269 - val_accuracy: 0.9097\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2716 - accuracy: 0.8839 - val_loss: 0.2162 - val_accuracy: 0.9419\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2903 - accuracy: 0.8839 - val_loss: 0.4258 - val_accuracy: 0.8516\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3297 - accuracy: 0.8710 - val_loss: 0.1351 - val_accuracy: 0.9742\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3427 - accuracy: 0.8645 - val_loss: 0.3263 - val_accuracy: 0.8710\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3939 - accuracy: 0.8516 - val_loss: 0.1482 - val_accuracy: 0.9548\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2593 - accuracy: 0.8968 - val_loss: 0.1946 - val_accuracy: 0.9355\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1489 - accuracy: 0.9355 - val_loss: 0.3381 - val_accuracy: 0.8581\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3677 - accuracy: 0.8774 - val_loss: 0.2203 - val_accuracy: 0.8968\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2224 - accuracy: 0.9226 - val_loss: 0.1094 - val_accuracy: 0.9613\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1255 - accuracy: 0.9548 - val_loss: 0.0830 - val_accuracy: 0.9871\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3055 - accuracy: 0.8968 - val_loss: 0.1229 - val_accuracy: 0.9484\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0945 - accuracy: 0.9742 - val_loss: 0.0667 - val_accuracy: 0.9871\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2325 - accuracy: 0.9355 - val_loss: 0.6631 - val_accuracy: 0.7548\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2575 - accuracy: 0.9097 - val_loss: 0.1449 - val_accuracy: 0.9548\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0809 - accuracy: 0.9806 - val_loss: 0.1990 - val_accuracy: 0.9226\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0410 - accuracy: 0.9935 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9548\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4436 - accuracy: 0.8645 - val_loss: 0.3364 - val_accuracy: 0.8903\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1662 - accuracy: 0.9484 - val_loss: 0.0779 - val_accuracy: 0.9742\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0953 - accuracy: 0.9871 - val_loss: 1.6486 - val_accuracy: 0.6581\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4506 - accuracy: 0.8968 - val_loss: 0.1006 - val_accuracy: 0.9613\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0623 - accuracy: 0.9806 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1183 - accuracy: 0.9677 - val_loss: 0.0578 - val_accuracy: 0.9871\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1448 - accuracy: 0.9355 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 0.9871\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.4952 - val_accuracy: 0.8452\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5329 - accuracy: 0.8452 - val_loss: 0.0238 - val_accuracy: 0.9935\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0331 - accuracy: 0.9935 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3681 - accuracy: 0.8903 - val_loss: 0.3260 - val_accuracy: 0.9032\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0614 - accuracy: 0.9806 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 1.0000\n",
      "np.shape(X_test)= (308, 1092, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1090, 32)          128       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1088, 64)          6208      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 362, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 360, 128)          24704     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 120, 128)         0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 118, 128)          49280     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 39, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 37, 256)           98560     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 12, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3072)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2000)              6146000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 14007     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,338,887\n",
      "Trainable params: 6,338,887\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Accuracy=  1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy=0\n",
    "acc_crs=np.array([])\n",
    "##for i in range (10):\n",
    "##    if accuracy<0.2 :\n",
    "\n",
    "verbose, epochs, batch_size = 1, 1000, btch\n",
    "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train_cat.shape[1]\n",
    "steps_per_epoch = len(X_train)//batch_size\n",
    "validation_steps = len(X_valid)//batch_size # if you have test data\n",
    "\n",
    "model_crs = Sequential()\n",
    "BatchNormalization()\n",
    "model_crs.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "#model_crs.add(MaxPooling1D(pool_size=3))\n",
    "BatchNormalization()\n",
    "model_crs.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "#model_crs.add(Dropout(0.5))\n",
    "model_crs.add(MaxPooling1D(pool_size=3))\n",
    "BatchNormalization()\n",
    "model_crs.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model_crs.add(MaxPooling1D(pool_size=3))\n",
    "BatchNormalization()\n",
    "model_crs.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model_crs.add(MaxPooling1D(pool_size=3))\n",
    "BatchNormalization()\n",
    "model_crs.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model_crs.add(MaxPooling1D(pool_size=3))\n",
    "'''model_crs.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "model_crs.add(MaxPooling1D(pool_size=3))\n",
    "model_crs.add(Conv1D(filters=1024, kernel_size=3, activation='relu'))\n",
    "model_crs.add(MaxPooling1D(pool_size=3))\n",
    "'''\n",
    "model_crs.add(Flatten())\n",
    "#model_crs.add(Dropout(0.5))\n",
    "model_crs.add(Dense(2000, activation='relu'))\n",
    "model_crs.add(Dense(n_outputs, activation='softmax'))\n",
    "model_crs.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# fit network   #CategoricalCrossentropy #sparse_categorical_crossentropy #SparseCategoricalCrossentropy\n",
    "\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_accuracy\", mode =\"max\", patience = 20, restore_best_weights = True)\n",
    "\n",
    "model_crs.fit(X_train, y_train_cat, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data = (X_valid, y_valid_cat), callbacks =[earlystopping])\n",
    "# evaluate model_crs\n",
    "_, accuracy = model_crs.evaluate(X_valid, y_valid_cat, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print('np.shape(X_test)=',np.shape(X_test))\n",
    "\n",
    "\n",
    "model_crs.summary()\n",
    "print('Accuracy= ', accuracy)\n",
    "\n",
    "#output = K.function([model_crs.layers[0].input],[model_crs.layers[3].output])\n",
    "#output(X_test)[0]\n",
    "#y_pred= model_crs.predict(X_test)                # Function 1\n",
    "\n",
    "##    print('Round ', i, '==>', 'accuracy = ', accuracy)\n",
    "##    acc_crs=np.append(acc_crs,accuracy)\n",
    "#y_pred_crs = model_crs.predict_classes(X_test)   # Function 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxindx(ar):\n",
    "    ar_cpy=np.array(ar)\n",
    "    pred=np.argmax(ar,axis=1)\n",
    "    for i in range (len(pred)):\n",
    "        if pred[i]==0:\n",
    "            ar_cpy[i,0]=-1000\n",
    "    pred=np.argmax(ar_cpy,axis=1)\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step\n",
      "array([[ 6,  8, 15, 10, 21],\n",
      "       [ 4, 33,  5, 11,  5],\n",
      "       [10,  9, 27,  7,  6],\n",
      "       [ 1, 14,  5, 28, 16],\n",
      "       [ 3, 12,  7,  9, 36]], dtype=int64)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.25      0.10      0.14        60\n",
      "           3       0.43      0.57      0.49        58\n",
      "           4       0.46      0.46      0.46        59\n",
      "           5       0.43      0.44      0.43        64\n",
      "           6       0.43      0.54      0.48        67\n",
      "\n",
      "    accuracy                           0.42       308\n",
      "   macro avg       0.40      0.42      0.40       308\n",
      "weighted avg       0.40      0.42      0.40       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_x=model_crs.predict(X_test)              # Function 1\n",
    "\n",
    "y_pred_crs=maxindx(predict_x)                    # function from augment.py to remove 0 index predictions\n",
    "\n",
    "#y_pred_crs = model_crs.predict_classes(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_crs)\n",
    "fullprint(cm)\n",
    "acc3=accuracy_score(y_test, y_pred_crs)\n",
    "\n",
    "print(classification_report(y_test, y_pred_crs))\n",
    "\n",
    "#sns.heatmap(cm, annot=True)\n",
    "\n",
    "#plt.imshow(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 1s 57ms/step - loss: 1.9550 - accuracy: 0.1742 - val_loss: 1.6712 - val_accuracy: 0.2194\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6700 - accuracy: 0.2000 - val_loss: 1.6107 - val_accuracy: 0.2194\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.6369 - accuracy: 0.1806 - val_loss: 1.6074 - val_accuracy: 0.2323\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6454 - accuracy: 0.2000 - val_loss: 1.6118 - val_accuracy: 0.2194\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6331 - accuracy: 0.2000 - val_loss: 1.6050 - val_accuracy: 0.2194\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6198 - accuracy: 0.1871 - val_loss: 1.6013 - val_accuracy: 0.2194\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6100 - accuracy: 0.1484 - val_loss: 1.6032 - val_accuracy: 0.2194\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6082 - accuracy: 0.2000 - val_loss: 1.5909 - val_accuracy: 0.2323\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5979 - accuracy: 0.2323 - val_loss: 1.5932 - val_accuracy: 0.2129\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6272 - accuracy: 0.2129 - val_loss: 1.5897 - val_accuracy: 0.2323\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6209 - accuracy: 0.1742 - val_loss: 1.5820 - val_accuracy: 0.2323\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6058 - accuracy: 0.1935 - val_loss: 1.5657 - val_accuracy: 0.3484\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5931 - accuracy: 0.2194 - val_loss: 1.6020 - val_accuracy: 0.2194\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.5834 - accuracy: 0.2452 - val_loss: 1.6039 - val_accuracy: 0.2839\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.5853 - accuracy: 0.2968 - val_loss: 1.5302 - val_accuracy: 0.3161\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.5091 - accuracy: 0.3226 - val_loss: 1.4548 - val_accuracy: 0.4194\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.4928 - accuracy: 0.3484 - val_loss: 1.4225 - val_accuracy: 0.3484\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.5001 - accuracy: 0.3226 - val_loss: 1.4518 - val_accuracy: 0.3355\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.4925 - accuracy: 0.3742 - val_loss: 1.4035 - val_accuracy: 0.4710\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4361 - accuracy: 0.4258 - val_loss: 1.3707 - val_accuracy: 0.4839\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.5324 - accuracy: 0.4065 - val_loss: 1.3862 - val_accuracy: 0.4194\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.3791 - accuracy: 0.4516 - val_loss: 1.4097 - val_accuracy: 0.4387\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4270 - accuracy: 0.4258 - val_loss: 1.3489 - val_accuracy: 0.5290\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3880 - accuracy: 0.4452 - val_loss: 1.3238 - val_accuracy: 0.5677\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.4001 - accuracy: 0.4323 - val_loss: 1.3747 - val_accuracy: 0.4581\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.3738 - accuracy: 0.4452 - val_loss: 1.2809 - val_accuracy: 0.5226\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.3260 - accuracy: 0.5032 - val_loss: 1.3584 - val_accuracy: 0.4194\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3657 - accuracy: 0.4903 - val_loss: 1.2231 - val_accuracy: 0.5742\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.3072 - accuracy: 0.4581 - val_loss: 1.2385 - val_accuracy: 0.5290\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2802 - accuracy: 0.5226 - val_loss: 1.5215 - val_accuracy: 0.3161\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3286 - accuracy: 0.4516 - val_loss: 1.3004 - val_accuracy: 0.5806\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2318 - accuracy: 0.5548 - val_loss: 1.2340 - val_accuracy: 0.5032\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2225 - accuracy: 0.4968 - val_loss: 1.1672 - val_accuracy: 0.5613\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2383 - accuracy: 0.5032 - val_loss: 1.1222 - val_accuracy: 0.5935\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2055 - accuracy: 0.5548 - val_loss: 1.1424 - val_accuracy: 0.5806\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1836 - accuracy: 0.5355 - val_loss: 1.1607 - val_accuracy: 0.5871\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1862 - accuracy: 0.6129 - val_loss: 1.1670 - val_accuracy: 0.5677\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1268 - accuracy: 0.5742 - val_loss: 1.0934 - val_accuracy: 0.5742\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1496 - accuracy: 0.5742 - val_loss: 1.0723 - val_accuracy: 0.5742\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2086 - accuracy: 0.5032 - val_loss: 1.1097 - val_accuracy: 0.6129\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1156 - accuracy: 0.5613 - val_loss: 1.1156 - val_accuracy: 0.5484\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0821 - accuracy: 0.5871 - val_loss: 1.1474 - val_accuracy: 0.5806\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0567 - accuracy: 0.6194 - val_loss: 1.3586 - val_accuracy: 0.4387\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0865 - accuracy: 0.5742 - val_loss: 1.1733 - val_accuracy: 0.4581\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0389 - accuracy: 0.6387 - val_loss: 0.9770 - val_accuracy: 0.6645\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0117 - accuracy: 0.6516 - val_loss: 1.0575 - val_accuracy: 0.6000\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 1.0425 - accuracy: 0.6129 - val_loss: 1.2201 - val_accuracy: 0.4968\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0593 - accuracy: 0.5742 - val_loss: 0.9130 - val_accuracy: 0.6774\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9853 - accuracy: 0.6323 - val_loss: 1.0204 - val_accuracy: 0.6387\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9857 - accuracy: 0.6258 - val_loss: 1.0425 - val_accuracy: 0.5484\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0657 - accuracy: 0.5677 - val_loss: 0.9113 - val_accuracy: 0.6323\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9199 - accuracy: 0.6452 - val_loss: 0.8619 - val_accuracy: 0.6452\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 2s 290ms/step - loss: 0.9333 - accuracy: 0.6258 - val_loss: 1.1795 - val_accuracy: 0.5484\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9302 - accuracy: 0.6645 - val_loss: 0.9227 - val_accuracy: 0.6129\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9160 - accuracy: 0.6452 - val_loss: 0.8069 - val_accuracy: 0.6968\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.8343 - accuracy: 0.6774 - val_loss: 0.8140 - val_accuracy: 0.6452\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9782 - accuracy: 0.6452 - val_loss: 0.7873 - val_accuracy: 0.7097\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.8475 - accuracy: 0.6645 - val_loss: 0.9086 - val_accuracy: 0.6258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "8/8 [==============================] - 2s 300ms/step - loss: 0.8763 - accuracy: 0.6323 - val_loss: 0.7495 - val_accuracy: 0.7419\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8595 - accuracy: 0.6645 - val_loss: 0.6956 - val_accuracy: 0.7548\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8119 - accuracy: 0.6774 - val_loss: 0.7489 - val_accuracy: 0.7097\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7473 - accuracy: 0.7097 - val_loss: 0.7474 - val_accuracy: 0.7097\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6643 - accuracy: 0.7355 - val_loss: 0.8058 - val_accuracy: 0.6581\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.8789 - accuracy: 0.6903 - val_loss: 0.7402 - val_accuracy: 0.7161\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 2s 320ms/step - loss: 0.7644 - accuracy: 0.6968 - val_loss: 0.6036 - val_accuracy: 0.7871\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7073 - accuracy: 0.7226 - val_loss: 0.6923 - val_accuracy: 0.7226\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.6822 - accuracy: 0.7548 - val_loss: 0.8046 - val_accuracy: 0.6968\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6493 - accuracy: 0.7677 - val_loss: 0.4953 - val_accuracy: 0.8452\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5734 - accuracy: 0.7484 - val_loss: 0.6145 - val_accuracy: 0.7742\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5766 - accuracy: 0.7871 - val_loss: 0.7682 - val_accuracy: 0.7032\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7272 - accuracy: 0.7226 - val_loss: 0.5441 - val_accuracy: 0.7935\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 2s 20ms/step - loss: 0.5738 - accuracy: 0.7613 - val_loss: 0.4446 - val_accuracy: 0.8452\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.5517 - accuracy: 0.7806 - val_loss: 0.4550 - val_accuracy: 0.8452\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.5802 - accuracy: 0.7677 - val_loss: 0.5312 - val_accuracy: 0.8000\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4677 - accuracy: 0.8129 - val_loss: 0.3933 - val_accuracy: 0.8645\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.5093 - accuracy: 0.7677 - val_loss: 0.4535 - val_accuracy: 0.8194\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.4969 - accuracy: 0.7871 - val_loss: 0.5568 - val_accuracy: 0.7742\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 2s 322ms/step - loss: 0.5584 - accuracy: 0.8129 - val_loss: 0.4903 - val_accuracy: 0.7226\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.4446 - accuracy: 0.8000 - val_loss: 0.4439 - val_accuracy: 0.7871\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3776 - accuracy: 0.8323 - val_loss: 0.3006 - val_accuracy: 0.8516\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4031 - accuracy: 0.8065 - val_loss: 0.2803 - val_accuracy: 0.9097\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3084 - accuracy: 0.8710 - val_loss: 0.4409 - val_accuracy: 0.8258\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3424 - accuracy: 0.8774 - val_loss: 0.2883 - val_accuracy: 0.9097\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 2s 325ms/step - loss: 0.3967 - accuracy: 0.8452 - val_loss: 0.6030 - val_accuracy: 0.7742\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4475 - accuracy: 0.8258 - val_loss: 0.1874 - val_accuracy: 0.9355\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3147 - accuracy: 0.9097 - val_loss: 0.2588 - val_accuracy: 0.8645\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2155 - accuracy: 0.9355 - val_loss: 0.2859 - val_accuracy: 0.8839\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.5253 - accuracy: 0.8323 - val_loss: 0.2425 - val_accuracy: 0.9226\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3058 - accuracy: 0.9161 - val_loss: 0.1900 - val_accuracy: 0.9484\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 2s 316ms/step - loss: 0.2291 - accuracy: 0.9097 - val_loss: 0.1190 - val_accuracy: 0.9613\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.1217 - accuracy: 0.9613 - val_loss: 0.2073 - val_accuracy: 0.9097\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3043 - accuracy: 0.8903 - val_loss: 0.3175 - val_accuracy: 0.8452\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.2455 - accuracy: 0.8903 - val_loss: 0.3105 - val_accuracy: 0.8839\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.2924 - accuracy: 0.8968 - val_loss: 0.1041 - val_accuracy: 0.9806\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.1434 - accuracy: 0.9548 - val_loss: 0.1763 - val_accuracy: 0.9484\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 2s 317ms/step - loss: 0.1629 - accuracy: 0.9355 - val_loss: 0.3131 - val_accuracy: 0.8839\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3286 - accuracy: 0.8710 - val_loss: 0.0971 - val_accuracy: 0.9806\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0630 - accuracy: 0.9871 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0312 - accuracy: 0.9935 - val_loss: 0.0653 - val_accuracy: 0.9871\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2981 - accuracy: 0.9355 - val_loss: 0.5298 - val_accuracy: 0.8323\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.2758 - accuracy: 0.9097 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 2s 318ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9613\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2628 - accuracy: 0.8710 - val_loss: 0.0557 - val_accuracy: 0.9935\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0441 - accuracy: 0.9871 - val_loss: 0.0319 - val_accuracy: 0.9935\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9871\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 1.4291 - val_accuracy: 0.7226\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3166 - accuracy: 0.7935 - val_loss: 0.0647 - val_accuracy: 0.9935\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 2s 313ms/step - loss: 0.0823 - accuracy: 0.9871 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 0.9935\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0122 - accuracy: 0.9935 - val_loss: 0.6276 - val_accuracy: 0.8581\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.4206 - accuracy: 0.8903 - val_loss: 0.1598 - val_accuracy: 0.9290\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1111 - accuracy: 0.9484 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9806\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2846 - accuracy: 0.9097 - val_loss: 0.1439 - val_accuracy: 0.9290\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2655 - accuracy: 0.9355 - val_loss: 0.1548 - val_accuracy: 0.9355\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0947 - accuracy: 0.9806 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 2s 312ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 1.0000\n",
      "np.shape(X_test)= (308, 1092, 1)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_5 (Conv1D)           (None, 1090, 64)          256       \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 1088, 128)         24704     \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 362, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 360, 256)          98560     \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 120, 256)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 118, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 39, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 37, 512)           393728    \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 12, 512)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6144)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2000)              12290000  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 14007     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,018,119\n",
      "Trainable params: 13,018,119\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Accuracy=  1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy=0\n",
    "acc_crs=np.array([])\n",
    "##for i in range (10):\n",
    "##    if accuracy<0.2 :\n",
    "\n",
    "verbose, epochs, batch_size = 1, 1000, btch\n",
    "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train_cat.shape[1]\n",
    "steps_per_epoch = len(X_train)//batch_size\n",
    "validation_steps = len(X_valid)//batch_size # if you have test data\n",
    "\n",
    "model_crs = Sequential()\n",
    "BatchNormalization()\n",
    "model_crs.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "#model_crs.add(MaxPooling1D(pool_size=3))\n",
    "BatchNormalization()\n",
    "model_crs.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "#model_crs.add(Dropout(0.5))\n",
    "model_crs.add(MaxPooling1D(pool_size=3))\n",
    "BatchNormalization()\n",
    "model_crs.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model_crs.add(MaxPooling1D(pool_size=3))\n",
    "BatchNormalization()\n",
    "model_crs.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model_crs.add(MaxPooling1D(pool_size=3))\n",
    "BatchNormalization()\n",
    "model_crs.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "model_crs.add(MaxPooling1D(pool_size=3))\n",
    "'''model_crs.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "model_crs.add(MaxPooling1D(pool_size=3))\n",
    "model_crs.add(Conv1D(filters=1024, kernel_size=3, activation='relu'))\n",
    "model_crs.add(MaxPooling1D(pool_size=3))\n",
    "'''\n",
    "model_crs.add(Flatten())\n",
    "#model_crs.add(Dropout(0.5))\n",
    "model_crs.add(Dense(2000, activation='relu'))\n",
    "model_crs.add(Dense(n_outputs, activation='softmax'))\n",
    "model_crs.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# fit network   #CategoricalCrossentropy #sparse_categorical_crossentropy #SparseCategoricalCrossentropy\n",
    "\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_accuracy\", mode =\"max\", patience = 20, restore_best_weights = True)\n",
    "\n",
    "model_crs.fit(X_train, y_train_cat, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data = (X_valid, y_valid_cat), callbacks =[earlystopping])\n",
    "# evaluate model_crs\n",
    "_, accuracy = model_crs.evaluate(X_valid, y_valid_cat, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print('np.shape(X_test)=',np.shape(X_test))\n",
    "\n",
    "\n",
    "model_crs.summary()\n",
    "print('Accuracy= ', accuracy)\n",
    "\n",
    "#output = K.function([model_crs.layers[0].input],[model_crs.layers[3].output])\n",
    "#output(X_test)[0]\n",
    "#y_pred= model_crs.predict(X_test)                # Function 1\n",
    "\n",
    "##    print('Round ', i, '==>', 'accuracy = ', accuracy)\n",
    "##    acc_crs=np.append(acc_crs,accuracy)\n",
    "#y_pred_crs = model_crs.predict_classes(X_test)   # Function 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step\n",
      "array([[12,  6, 12, 13, 17],\n",
      "       [ 3, 27,  5, 20,  3],\n",
      "       [12,  9, 23, 12,  3],\n",
      "       [ 4, 12,  5, 32, 11],\n",
      "       [ 6,  9,  7, 15, 30]], dtype=int64)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.32      0.20      0.25        60\n",
      "           3       0.43      0.47      0.45        58\n",
      "           4       0.44      0.39      0.41        59\n",
      "           5       0.35      0.50      0.41        64\n",
      "           6       0.47      0.45      0.46        67\n",
      "\n",
      "    accuracy                           0.40       308\n",
      "   macro avg       0.40      0.40      0.40       308\n",
      "weighted avg       0.40      0.40      0.40       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_x=model_crs.predict(X_test)              # Function 1\n",
    "\n",
    "y_pred_crs=maxindx(predict_x)                    # function from augment.py to remove 0 index predictions\n",
    "\n",
    "#y_pred_crs = model_crs.predict_classes(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_crs)\n",
    "fullprint(cm)\n",
    "acc3=accuracy_score(y_test, y_pred_crs)\n",
    "\n",
    "print(classification_report(y_test, y_pred_crs))\n",
    "\n",
    "#sns.heatmap(cm, annot=True)\n",
    "\n",
    "#plt.imshow(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
