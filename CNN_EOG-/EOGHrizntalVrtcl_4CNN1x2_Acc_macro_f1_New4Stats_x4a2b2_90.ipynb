{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import time\n",
    "plc=1\n",
    "time.sleep(1500*plc)         #run after 1 houre = 3600 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#notebook { padding-top:0px !important; } .container { width:100% !important; } .end_space { min-height:0px !important; } html, body, .container{ margin:0!important;padding:0!important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "import random\n",
    "import bisect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess import *                         #ماژول استخراج پنجره ها\n",
    "from data import *                          #ماژول محلی ورود داده ها\n",
    "from augment import *                            #ماژول های داده افزایی\n",
    "from lstm_cnn import *                           #ماژول های داده افزایی با lstm_cnn\n",
    "import augment\n",
    "import importlib\n",
    "importlib.reload(augment)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report,recall_score,precision_score\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D,Conv1D,Dropout,MaxPooling1D,MaxPooling2D,Flatten,Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "cwd = os.getcwd() #\n",
    "fullscrn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxindx(ar):\n",
    "    ar_cpy=np.array(ar)\n",
    "    pred=np.argmax(ar,axis=1)\n",
    "    for i in range (len(pred)):\n",
    "        if pred[i]==0:\n",
    "            ar_cpy[i,0]=-1000\n",
    "    pred=np.argmax(ar_cpy,axis=1)\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><div style=\"direction:rtl;font-family:B Nazanin\">Importing Data</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_train_shape= (362, 1251)\n",
      "first_test_shape= (362, 1251)\n",
      "classes_quantity= 12\n",
      "tr_lbls=\t {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "Count_labels= [30 30 30 30 30 31 31 30 30 30 30 30]\n",
      "max(train_feature_Altitude)= 446.32\n",
      "min(train_feature_Altitude)= -1110.8\n",
      "first_train_sample=\n",
      " [   1.         0.47769    0.60965 ... -110.76    -111.03    -110.9    ]\n",
      "1 30\t2 30\t3 30\t4 30\t5 30\t6 31\t7 31\t8 30\t9 30\t10 30\t11 30\t12 30\t\n",
      "shape ecgH= (362, 481)\n"
     ]
    }
   ],
   "source": [
    "cls_num=12\n",
    "btch=30\n",
    "for i in range (1,cls_num+1):\n",
    "    vars()['ecgH'+str(i)],vars()['ecg_tstH'+str(i)]=EOGHorizontalSignal(i)\n",
    "os.chdir(cwd)\n",
    "clses_lens=np.array([])\n",
    "clses_lensH=np.array([])\n",
    "i=0                               #جمع آوری داده ها و چاپ تعداد نمونه ی هر کلاس\n",
    "ecgH=np.array(ecgH1)\n",
    "print(1,len(vars()['ecgH'+str(1)]), end='\\t')\n",
    "clses_lensH=np.append(clses_lensH,len(vars()['ecgH'+str(1)]))\n",
    "for i in range (2,cls_num+1):\n",
    "    ecgH=np.concatenate((ecgH,vars()['ecgH'+str(i)]),axis=0)\n",
    "    clses_lensH=np.append(clses_lensH,len(vars()['ecgH'+str(i)]))\n",
    "    print( i,len(vars()['ecgH'+str(i)]), end='\\t')\n",
    "\n",
    "mx_sigH=max(clses_lensH)\n",
    "print('\\nshape ecgH=',np.shape(ecgH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_train_shape= (362, 1251)\n",
      "first_test_shape= (362, 1251)\n",
      "classes_quantity= 12\n",
      "tr_lbls=\t {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "Count_labels= [30 30 30 30 30 31 31 30 30 30 30 30]\n",
      "max(train_feature_Altitude)= 2540.7\n",
      "min(train_feature_Altitude)= -923.79\n",
      "first_train_sample=\n",
      " [   1.       -5.7032   -5.8955 ... -113.16   -112.85   -112.94  ]\n",
      "1 30\t2 30\t3 30\t4 30\t5 30\t6 31\t7 31\t8 30\t9 30\t10 30\t11 30\t12 30\t\n",
      "shape ecgV= (362, 481)\n"
     ]
    }
   ],
   "source": [
    "#Vertical\n",
    "for i in range (1,cls_num+1):\n",
    "    vars()['ecgV'+str(i)],vars()['ecg_tstV'+str(i)]=EOGVerticalSignal(i)\n",
    "os.chdir(cwd)\n",
    "clses_lensV=np.array([])\n",
    "i=0                               #جمع آوری داده ها و چاپ تعداد نمونه ی هر کلاس\n",
    "ecgV=np.array(ecgV1)\n",
    "print(1,len(vars()['ecgV'+str(1)]), end='\\t')\n",
    "clses_lens=np.append(clses_lens,len(vars()['ecgV'+str(1)]))\n",
    "for i in range (2,cls_num+1):\n",
    "    ecgV=np.concatenate((ecgV,vars()['ecgV'+str(i)]),axis=0)\n",
    "    clses_lensV=np.append(clses_lensV,len(vars()['ecgV'+str(i)]))\n",
    "    print( i,len(vars()['ecgV'+str(i)]), end='\\t')\n",
    "\n",
    "mx_sigV=max(clses_lensV)\n",
    "print('\\nshape ecgV=',np.shape(ecgV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,cls_num+1):\n",
    "    #vars()['ecgHV'+str(i)]=np.array([])\n",
    "    vars()['ecg'+str(i)]=np.array(np.concatenate((vars()['ecgH'+str(i)][:,0:-1],vars()['ecgV'+str(i)]),axis=1))\n",
    "    vars()['ecg_tst'+str(i)]=np.array(np.concatenate((vars()['ecg_tstH'+str(i)][:,0:-1],vars()['ecg_tstV'+str(i)]),axis=1))\n",
    "ecg=np.array(np.concatenate((ecgH[:,:-1],ecgV),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362, 961)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ecg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center><div style=\"direction:rtl;font-family:B Nazanin\">Base Train windows</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each class and its windows =\n",
      "1 30\t2 30\t3 30\t4 30\t5 30\t6 31\t7 31\t8 30\t9 30\t10 30\t11 30\t12 30\t"
     ]
    }
   ],
   "source": [
    "smpl_rte=960                                              # در ماژول ها نیز همین مقدار ثبت شده\n",
    "i=0\n",
    "windws=np.array([])\n",
    "\n",
    "for cls in range (1,cls_num+1):                                 #ساخت پنجره های داده های آموزش اصلی\n",
    "    vars()['wndws'+str(cls)]=np.array(vars()['ecg'+str(cls)])  \n",
    "    \n",
    "print(\"each class and its windows =\")\n",
    "\n",
    "cls_wndws=np.array([])\n",
    "for cls in range (1,cls_num+1):                                # آرایه ی تعداد پنجره ی هر کلاس\n",
    "    wns=len(vars()['wndws'+str(cls)])\n",
    "    cls_wndws=np.append(cls_wndws,wns)\n",
    "    print(cls, wns, end='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><div style=\"direction:rtl;font-family:B Nazanin\">Data Augmentation</div></center></h1>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for method in range(60,80,10):\n",
    "    print(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for alpha in range(1,7,2):\n",
    "    if alpha==5:\n",
    "        alpha=10\n",
    "    print(alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " max = 32\n",
      "[[4 3 0 1 1 1 1]\n",
      " [2 2 0 1 1 1 1]\n",
      " [4 4 0 2 2 2 2]\n",
      " [3 2 0 1 1 1 1]\n",
      " [1 1 0 0 0 0 0]\n",
      " [1 1 0 1 1 1 1]\n",
      " [1 1 0 1 1 1 1]\n",
      " [2 1 0 1 1 1 1]\n",
      " [2 2 0 1 1 1 1]\n",
      " [1 1 0 1 1 1 1]\n",
      " [4 3 0 1 1 1 1]\n",
      " [1 1 0 0 0 0 0]]\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "[[16 13  0  6  6  6  6]\n",
      " [13 11  0  5  5  5  5]\n",
      " [18 14  0  7  7  7  7]\n",
      " [15 12  0  6  6  6  6]\n",
      " [11  8  0  4  4  4  4]\n",
      " [12  9  0  5  5  5  5]\n",
      " [12 10  0  5  5  5  5]\n",
      " [12 10  0  5  5  5  5]\n",
      " [13 11  0  5  5  5  5]\n",
      " [12  9  0  5  5  5  5]\n",
      " [16 13  0  6  6  6  6]\n",
      " [11  9  0  4  4  4  4]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[28 23  0 11 11 11 11]\n",
      " [25 20  0 10 10 10 10]\n",
      " [31 25  0 12 12 12 12]\n",
      " [27 21  0 11 11 11 11]\n",
      " [20 16  0  8  8  8  8]\n",
      " [22 18  0  9  9  9  9]\n",
      " [23 18  0  9  9  9  9]\n",
      " [23 18  0  9  9  9  9]\n",
      " [25 20  0 10 10 10 10]\n",
      " [22 17  0  9  9  9  9]\n",
      " [29 23  0 11 11 11 11]\n",
      " [21 17  0  9  9  9  9]]\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[5 3 0 1 1 1 1]\n",
      " [3 2 0 1 1 1 1]\n",
      " [7 4 0 1 1 1 1]\n",
      " [5 3 0 1 1 1 1]\n",
      " [1 1 0 0 0 0 0]\n",
      " [2 1 0 0 0 0 0]\n",
      " [2 1 0 0 0 0 0]\n",
      " [2 2 0 0 0 0 0]\n",
      " [3 2 0 1 1 1 1]\n",
      " [2 1 0 0 0 0 0]\n",
      " [5 4 0 1 1 1 1]\n",
      " [2 1 0 0 0 0 0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[24 15  0  4  4  4  4]\n",
      " [20 13  0  3  3  3  3]\n",
      " [26 17  0  4  4  4  4]\n",
      " [22 14  0  4  4  4  4]\n",
      " [16 10  0  3  3  3  3]\n",
      " [18 11  0  3  3  3  3]\n",
      " [18 11  0  3  3  3  3]\n",
      " [18 12  0  3  3  3  3]\n",
      " [20 13  0  3  3  3  3]\n",
      " [17 11  0  3  3  3  3]\n",
      " [24 15  0  4  4  4  4]\n",
      " [17 11  0  3  3  3  3]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[42 27  0  7  7  7  7]\n",
      " [37 23  0  6  6  6  6]\n",
      " [46 29  0  7  7  7  7]\n",
      " [40 26  0  6  6  6  6]\n",
      " [30 19  0  5  5  5  5]\n",
      " [33 21  0  5  5  5  5]\n",
      " [34 22  0  5  5  5  5]\n",
      " [34 22  0  5  5  5  5]\n",
      " [37 23  0  6  6  6  6]\n",
      " [33 21  0  5  5  5  5]\n",
      " [43 27  0  7  7  7  7]\n",
      " [32 20  0  5  5  5  5]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[10  2  0  0  0  0  0]\n",
      " [ 6  2  0  0  0  0  0]\n",
      " [12  3  0  0  0  0  0]\n",
      " [ 8  2  0  0  0  0  0]\n",
      " [ 2  1  0  0  0  0  0]\n",
      " [ 4  1  0  0  0  0  0]\n",
      " [ 4  1  0  0  0  0  0]\n",
      " [ 4  1  0  0  0  0  0]\n",
      " [ 6  2  0  0  0  0  0]\n",
      " [ 4  1  0  0  0  0  0]\n",
      " [10  3  0  0  0  0  0]\n",
      " [ 3  1  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[42 11  0  0  0  0  0]\n",
      " [36  9  0  0  0  0  0]\n",
      " [47 12  0  0  0  0  0]\n",
      " [40 10  0  0  0  0  0]\n",
      " [28  7  0  0  0  0  0]\n",
      " [32  8  0  0  0  0  0]\n",
      " [32  8  0  0  0  0  0]\n",
      " [32  8  0  0  0  0  0]\n",
      " [36  9  0  0  0  0  0]\n",
      " [31  8  0  0  0  0  0]\n",
      " [43 11  0  0  0  0  0]\n",
      " [30  8  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "[[75 20  0  0  0  0  0]\n",
      " [65 17  0  0  0  0  0]\n",
      " [82 21  0  0  0  0  0]\n",
      " [71 19  0  0  0  0  0]\n",
      " [54 14  0  0  0  0  0]\n",
      " [59 16  0  0  0  0  0]\n",
      " [60 16  0  0  0  0  0]\n",
      " [60 16  0  0  0  0  0]\n",
      " [65 17  0  0  0  0  0]\n",
      " [58 15  0  0  0  0  0]\n",
      " [76 20  0  0  0  0  0]\n",
      " [57 15  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "mx_wndws=int(np.max(cls_wndws)+1)   # حداکثر تعداد پنجره ی موجود بین کلاس ها\n",
    "print('\\n max =', mx_wndws)\n",
    "aug_amnt_Ttl=np.empty((0,7), int) \n",
    "rpt_cnn_clsfctn=5                 #تعداد اجرای شبکه عصبی برای میانگین گیری هر حالت \n",
    "rslts=np.array([])\n",
    "alpha=1                           #چند برابر کردن داده افزایی هر کلاس متناسب ضعیف بودن آن کلاس\n",
    "for beta in range(1,4):\n",
    "    if beta==3:\n",
    "        beta=beta*2\n",
    "    for X in range(1,4):          #داده افزایی تا چند برابر کلاس اکثریت\n",
    "        mx_wndws=int(np.max(cls_wndws))   # حداکثر تعداد پنجره ی موجود بین کلاس ها\n",
    "        mx_wndws=int(X*mx_wndws)          #داده افزایی تا چند برابر کلاس اکثریت\n",
    "        scors0=np.array([64,78,55,70,94,85,84,85,78,88,63,90])         #Class Recalls without Augmentation\n",
    "        AgScr=1+alpha*(100-scors0)/100                                 #Class Specific\n",
    "        f_scr=np.array([83,88,87,83,85,85,85,85])                      #UnAg,Scl.2,Mag.05,Tm.2,Gs1,frqnc2,GAN,LSTMexpgdo\n",
    "        f_scr_difrnc=f_scr-f_scr[0]\n",
    "        for z in range (len(f_scr_difrnc)):\n",
    "            if f_scr_difrnc[z]<0:\n",
    "                f_scr_difrnc[z]=0\n",
    "        f_scr_difrnc=f_scr_difrnc**beta\n",
    "        f_scr_rtio=f_scr_difrnc/(sum(f_scr_difrnc))\n",
    "        aug_amnt=np.empty((0,len(f_scr_rtio)-1), int) \n",
    "        for i in range (1,cls_num+1):\n",
    "            aug_amnt=np.append(aug_amnt,[f_scr_rtio[1:]*(mx_wndws*AgScr[i-1]-cls_wndws[i-1])],axis=0)\n",
    "            #vlum_win=mx_wndws-cls_wndws[i-1]             #میزان داده افزایی در روش های عمیق (پنجره)\n",
    "        aug_amnt=np.int16(np.round(aug_amnt))\n",
    "        \n",
    "        aug_amnt_Ttl=np.append(aug_amnt_Ttl,aug_amnt,axis=0)\n",
    "        #print(np.int16(100*f_scr_rtio))\n",
    "        #print(aug_amnt)\n",
    "        rprt=np.empty((0,3),float)\n",
    "        print(aug_amnt)\n",
    "        for repeat in range(1,rpt_cnn_clsfctn+1):\n",
    "            xtrain=np.empty((0,smpl_rte+1), float) \n",
    "            for i in range (1,cls_num+1):                                     #تعریف آرایه ی پنجره های کلاس ها\n",
    "                xtrain=np.append(xtrain,vars()['wndws'+str(i)],axis=0)\n",
    "                if aug_amnt[i-1,0]>0:\n",
    "                    methd=10\n",
    "                    sort=-3  #-5=Dis_sam_Cls=qlty1 #-4=var_Dis=qlty2 #-3=DisSm/DisOthr=qlty3  #-2=invrs_GDO_papr=qlty4   #-1=GDO_papr=qlty5\n",
    "                    dp_slct_dstrb=4            #1-sequencial 2-linear 3-beta 4-exponential 5-unfrm\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,0],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,0],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,1]>0:\n",
    "                    methd=20\n",
    "                    sort=-3\n",
    "                    dp_slct_dstrb=2\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,1],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,1],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,2]>0:\n",
    "                    methd=30\n",
    "                    sort=-3\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,2],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,2],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,3]>0:\n",
    "                    methd=40\n",
    "                    sort=-1\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,3],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,3],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,4]>0:\n",
    "                    methd=50\n",
    "                    sort=-3\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,4],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,4],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,5]>0:\n",
    "                    methd=60\n",
    "                    sort=-1\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,5],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,5],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,6]>0:\n",
    "                    methd=70\n",
    "                    sort=-1\n",
    "                    dp_slct_dstrb=2\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,6],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,6],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                #print('class ', i, 'train shape = ', np.shape(xtrain))\n",
    "\n",
    "            # Normalization train windows\n",
    "            mx_aug=np.max(xtrain[:,:-1])\n",
    "            mx=np.max(ecg[:,:-1])\n",
    "            mn_aug=np.min(xtrain[:,:-1])\n",
    "            mn=np.min(ecg[:,:-1])\n",
    "            xtrain[:,:-1]= 2*(xtrain[:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1\n",
    "\n",
    "\n",
    "            ###Test Windows:\n",
    "            wndws_test=np.empty((0,len(wndws1[0])), float)\n",
    "            i=0\n",
    "            windws=np.array([])\n",
    "            for cls in range (1,cls_num+1):                                 #ساخت پنجره های داده های تست\n",
    "                vars()['wndws_tst'+str(cls)]=np.empty((0,len(wndws1[0])), float)\n",
    "                vars()['wndws_tst'+str(cls)]=np.append(vars()['wndws_tst'+str(cls)],vars()['ecg_tst'+str(cls)],axis=0)   \n",
    "\n",
    "            # Normalization test windows\n",
    "            for i in range (1,cls_num+1):                \n",
    "                cls=i\n",
    "                vars()['wndws_tst'+str(i)][:,:-1]= 2*(vars()['wndws_tst'+str(i)][:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1\n",
    "            for cls in range (1,cls_num+1):                                # آرایه ی تعداد پنجره ی هر کلاس\n",
    "                wns=len(vars()['wndws_tst'+str(cls)])\n",
    "                wndws_test=np.append(wndws_test,vars()['wndws_tst'+str(cls)],axis=0)\n",
    "\n",
    "            Xtest=wndws_test[:,:-1]\n",
    "            ytest=np.int16(wndws_test[:,-1])\n",
    "\n",
    "            trainx=np.random.permutation(xtrain)\n",
    "            Xtrain=np.array(trainx[:,:-1])\n",
    "            ytrain=np.int16(trainx[:,-1])\n",
    "\n",
    "            X_train=np.array(Xtrain)\n",
    "            y_train=np.array(ytrain)\n",
    "            X_test=np.array(Xtest)\n",
    "            y_test=np.array(ytest)\n",
    "            X_valid=np.array(Xtrain)\n",
    "            y_valid=np.array(ytrain)\n",
    "            #print('X_train => ', X_train.shape)\n",
    "            #print('y_train => ', y_train.shape)\n",
    "            #print('X_test  => ', X_test.shape)\n",
    "            #print('y_test  => ', y_test.shape)\n",
    "            #print('X_valid  => ', X_valid.shape)\n",
    "            #print('y_valid  => ', y_valid.shape)\n",
    "\n",
    "            y_train_cat=to_categorical(y_train)\n",
    "            y_valid_cat=to_categorical(y_valid)\n",
    "            y_test_cat=to_categorical(y_test)\n",
    "            X_train = np.expand_dims(X_train, axis=2)\n",
    "            X_valid = np.expand_dims(X_valid, axis=2)\n",
    "            X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "            ####### NETWORK #######\n",
    "            accuracy=0\n",
    "            acc_crs=np.array([])\n",
    "            ##for i in range (10):\n",
    "            ##    if accuracy<0.2 :\n",
    "            verbose, epochs, batch_size = 0, 1000, btch\n",
    "            n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train_cat.shape[1]\n",
    "            steps_per_epoch = len(X_train)//batch_size\n",
    "            validation_steps = len(X_valid)//batch_size # if you have test data\n",
    "            model_crs = Sequential()\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "            #model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "            #model_crs.add(Dropout(0.5))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            '''model_crs.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            model_crs.add(Conv1D(filters=1024, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            '''\n",
    "            model_crs.add(Flatten())\n",
    "            #model_crs.add(Dropout(0.5))\n",
    "            model_crs.add(Dense(2000, activation='relu'))\n",
    "            model_crs.add(Dense(n_outputs, activation='softmax'))\n",
    "            model_crs.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            # fit network   #CategoricalCrossentropy #sparse_categorical_crossentropy #SparseCategoricalCrossentropy\n",
    "            earlystopping = callbacks.EarlyStopping(monitor =\"val_accuracy\", mode =\"max\", patience = 20, restore_best_weights = True)\n",
    "            model_crs.fit(X_train, y_train_cat, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data = (X_valid, y_valid_cat), callbacks =[earlystopping])\n",
    "            # evaluate model_crs\n",
    "            _, accuracy = model_crs.evaluate(X_valid, y_valid_cat, batch_size=batch_size, verbose=verbose)\n",
    "            predict_x=model_crs.predict(X_test)              # Function 1\n",
    "            y_pred_crs=maxindx(predict_x)                    # function from augment.py to remove 0 index predictions\n",
    "            rprt0=classification_report(y_test, y_pred_crs,output_dict=True)\n",
    "            rprt_row=np.array([])\n",
    "            rprt_row=np.append(rprt_row,rprt0['accuracy'])\n",
    "            rprt_row=np.append(rprt_row,rprt0['macro avg']['f1-score'])\n",
    "            rprt_row=np.append(rprt_row,rprt0['weighted avg']['f1-score'])\n",
    "            rprt=np.append(rprt,[rprt_row],axis=0)\n",
    "        #print('rprt=',rprt)\n",
    "        maxm=rprt[np.argmax(rprt[:,1])]\n",
    "        #print('maxm=',maxm)\n",
    "        avrg=np.mean(rprt,axis=0)\n",
    "        #print('avrg=',avrg)\n",
    "        rslts=np.append(rslts,['Beta '+str(beta)+'  X '+str(X)+'  average= '+str(np.int16(100*avrg))+'  max= '+str(np.int16(100*maxm))+'  var= '+str(np.int16(np.var(100*rprt,axis=0)))],axis=0)\n",
    "        #print('rslts=',rslts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  3,  0,  1,  1,  1,  1],\n",
       "       [ 2,  2,  0,  1,  1,  1,  1],\n",
       "       [ 4,  4,  0,  2,  2,  2,  2],\n",
       "       [ 3,  2,  0,  1,  1,  1,  1],\n",
       "       [ 1,  1,  0,  0,  0,  0,  0],\n",
       "       [ 1,  1,  0,  1,  1,  1,  1],\n",
       "       [ 1,  1,  0,  1,  1,  1,  1],\n",
       "       [ 2,  1,  0,  1,  1,  1,  1],\n",
       "       [ 2,  2,  0,  1,  1,  1,  1],\n",
       "       [ 1,  1,  0,  1,  1,  1,  1],\n",
       "       [ 4,  3,  0,  1,  1,  1,  1],\n",
       "       [ 1,  1,  0,  0,  0,  0,  0],\n",
       "       [16, 13,  0,  6,  6,  6,  6],\n",
       "       [13, 11,  0,  5,  5,  5,  5],\n",
       "       [18, 14,  0,  7,  7,  7,  7],\n",
       "       [15, 12,  0,  6,  6,  6,  6],\n",
       "       [11,  8,  0,  4,  4,  4,  4],\n",
       "       [12,  9,  0,  5,  5,  5,  5],\n",
       "       [12, 10,  0,  5,  5,  5,  5],\n",
       "       [12, 10,  0,  5,  5,  5,  5],\n",
       "       [13, 11,  0,  5,  5,  5,  5],\n",
       "       [12,  9,  0,  5,  5,  5,  5],\n",
       "       [16, 13,  0,  6,  6,  6,  6],\n",
       "       [11,  9,  0,  4,  4,  4,  4],\n",
       "       [28, 23,  0, 11, 11, 11, 11],\n",
       "       [25, 20,  0, 10, 10, 10, 10],\n",
       "       [31, 25,  0, 12, 12, 12, 12],\n",
       "       [27, 21,  0, 11, 11, 11, 11],\n",
       "       [20, 16,  0,  8,  8,  8,  8],\n",
       "       [22, 18,  0,  9,  9,  9,  9],\n",
       "       [23, 18,  0,  9,  9,  9,  9],\n",
       "       [23, 18,  0,  9,  9,  9,  9],\n",
       "       [25, 20,  0, 10, 10, 10, 10],\n",
       "       [22, 17,  0,  9,  9,  9,  9],\n",
       "       [29, 23,  0, 11, 11, 11, 11],\n",
       "       [21, 17,  0,  9,  9,  9,  9],\n",
       "       [ 5,  3,  0,  1,  1,  1,  1],\n",
       "       [ 3,  2,  0,  1,  1,  1,  1],\n",
       "       [ 7,  4,  0,  1,  1,  1,  1],\n",
       "       [ 5,  3,  0,  1,  1,  1,  1],\n",
       "       [ 1,  1,  0,  0,  0,  0,  0],\n",
       "       [ 2,  1,  0,  0,  0,  0,  0],\n",
       "       [ 2,  1,  0,  0,  0,  0,  0],\n",
       "       [ 2,  2,  0,  0,  0,  0,  0],\n",
       "       [ 3,  2,  0,  1,  1,  1,  1],\n",
       "       [ 2,  1,  0,  0,  0,  0,  0],\n",
       "       [ 5,  4,  0,  1,  1,  1,  1],\n",
       "       [ 2,  1,  0,  0,  0,  0,  0],\n",
       "       [24, 15,  0,  4,  4,  4,  4],\n",
       "       [20, 13,  0,  3,  3,  3,  3],\n",
       "       [26, 17,  0,  4,  4,  4,  4],\n",
       "       [22, 14,  0,  4,  4,  4,  4],\n",
       "       [16, 10,  0,  3,  3,  3,  3],\n",
       "       [18, 11,  0,  3,  3,  3,  3],\n",
       "       [18, 11,  0,  3,  3,  3,  3],\n",
       "       [18, 12,  0,  3,  3,  3,  3],\n",
       "       [20, 13,  0,  3,  3,  3,  3],\n",
       "       [17, 11,  0,  3,  3,  3,  3],\n",
       "       [24, 15,  0,  4,  4,  4,  4],\n",
       "       [17, 11,  0,  3,  3,  3,  3],\n",
       "       [42, 27,  0,  7,  7,  7,  7],\n",
       "       [37, 23,  0,  6,  6,  6,  6],\n",
       "       [46, 29,  0,  7,  7,  7,  7],\n",
       "       [40, 26,  0,  6,  6,  6,  6],\n",
       "       [30, 19,  0,  5,  5,  5,  5],\n",
       "       [33, 21,  0,  5,  5,  5,  5],\n",
       "       [34, 22,  0,  5,  5,  5,  5],\n",
       "       [34, 22,  0,  5,  5,  5,  5],\n",
       "       [37, 23,  0,  6,  6,  6,  6],\n",
       "       [33, 21,  0,  5,  5,  5,  5],\n",
       "       [43, 27,  0,  7,  7,  7,  7],\n",
       "       [32, 20,  0,  5,  5,  5,  5],\n",
       "       [10,  2,  0,  0,  0,  0,  0],\n",
       "       [ 6,  2,  0,  0,  0,  0,  0],\n",
       "       [12,  3,  0,  0,  0,  0,  0],\n",
       "       [ 8,  2,  0,  0,  0,  0,  0],\n",
       "       [ 2,  1,  0,  0,  0,  0,  0],\n",
       "       [ 4,  1,  0,  0,  0,  0,  0],\n",
       "       [ 4,  1,  0,  0,  0,  0,  0],\n",
       "       [ 4,  1,  0,  0,  0,  0,  0],\n",
       "       [ 6,  2,  0,  0,  0,  0,  0],\n",
       "       [ 4,  1,  0,  0,  0,  0,  0],\n",
       "       [10,  3,  0,  0,  0,  0,  0],\n",
       "       [ 3,  1,  0,  0,  0,  0,  0],\n",
       "       [42, 11,  0,  0,  0,  0,  0],\n",
       "       [36,  9,  0,  0,  0,  0,  0],\n",
       "       [47, 12,  0,  0,  0,  0,  0],\n",
       "       [40, 10,  0,  0,  0,  0,  0],\n",
       "       [28,  7,  0,  0,  0,  0,  0],\n",
       "       [32,  8,  0,  0,  0,  0,  0],\n",
       "       [32,  8,  0,  0,  0,  0,  0],\n",
       "       [32,  8,  0,  0,  0,  0,  0],\n",
       "       [36,  9,  0,  0,  0,  0,  0],\n",
       "       [31,  8,  0,  0,  0,  0,  0],\n",
       "       [43, 11,  0,  0,  0,  0,  0],\n",
       "       [30,  8,  0,  0,  0,  0,  0],\n",
       "       [75, 20,  0,  0,  0,  0,  0],\n",
       "       [65, 17,  0,  0,  0,  0,  0],\n",
       "       [82, 21,  0,  0,  0,  0,  0],\n",
       "       [71, 19,  0,  0,  0,  0,  0],\n",
       "       [54, 14,  0,  0,  0,  0,  0],\n",
       "       [59, 16,  0,  0,  0,  0,  0],\n",
       "       [60, 16,  0,  0,  0,  0,  0],\n",
       "       [60, 16,  0,  0,  0,  0,  0],\n",
       "       [65, 17,  0,  0,  0,  0,  0],\n",
       "       [58, 15,  0,  0,  0,  0,  0],\n",
       "       [76, 20,  0,  0,  0,  0,  0],\n",
       "       [57, 15,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_amnt_Ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Beta 1  X 1  average= [86 86 85]  max= [87 87 87]  var= [2 2 2]',\n",
       "       'Beta 1  X 2  average= [86 86 86]  max= [87 87 87]  var= [0 1 1]',\n",
       "       'Beta 1  X 3  average= [86 86 86]  max= [88 88 88]  var= [4 4 4]',\n",
       "       'Beta 2  X 1  average= [84 84 84]  max= [85 85 85]  var= [1 1 1]',\n",
       "       'Beta 2  X 2  average= [85 85 85]  max= [87 87 87]  var= [1 1 1]',\n",
       "       'Beta 2  X 3  average= [88 88 88]  max= [90 89 89]  var= [1 1 1]',\n",
       "       'Beta 6  X 1  average= [82 82 82]  max= [83 82 82]  var= [0 0 0]',\n",
       "       'Beta 6  X 2  average= [85 85 85]  max= [88 87 87]  var= [1 1 1]',\n",
       "       'Beta 6  X 3  average= [85 85 85]  max= [88 87 87]  var= [3 3 3]'],\n",
       "      dtype='<U63')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1=rslts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " max = 32\n",
      "[[8 6 0 3 3 3 3]\n",
      " [5 4 0 2 2 2 2]\n",
      " [9 8 0 4 4 4 4]\n",
      " [6 5 0 3 3 3 3]\n",
      " [2 1 0 1 1 1 1]\n",
      " [3 2 0 1 1 1 1]\n",
      " [3 3 0 1 1 1 1]\n",
      " [3 3 0 1 1 1 1]\n",
      " [5 4 0 2 2 2 2]\n",
      " [3 2 0 1 1 1 1]\n",
      " [8 6 0 3 3 3 3]\n",
      " [2 2 0 1 1 1 1]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[24 19  0 10 10 10 10]\n",
      " [18 15  0  7  7  7  7]\n",
      " [28 22  0 11 11 11 11]\n",
      " [22 17  0  9  9  9  9]\n",
      " [12  9  0  5  5  5  5]\n",
      " [15 12  0  6  6  6  6]\n",
      " [16 12  0  6  6  6  6]\n",
      " [15 12  0  6  6  6  6]\n",
      " [18 15  0  7  7  7  7]\n",
      " [14 11  0  6  6  6  6]\n",
      " [24 20  0 10 10 10 10]\n",
      " [13 11  0  5  5  5  5]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[40 32  0 16 16 16 16]\n",
      " [32 26  0 13 13 13 13]\n",
      " [46 37  0 18 18 18 18]\n",
      " [37 29  0 15 15 15 15]\n",
      " [22 18  0  9  9  9  9]\n",
      " [27 22  0 11 11 11 11]\n",
      " [28 22  0 11 11 11 11]\n",
      " [28 22  0 11 11 11 11]\n",
      " [32 26  0 13 13 13 13]\n",
      " [26 21  0 10 10 10 10]\n",
      " [41 33  0 16 16 16 16]\n",
      " [25 20  0 10 10 10 10]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[ 9  6  0  1  1  1  1]\n",
      " [ 4  2  0  1  1  1  1]\n",
      " [14  9  0  2  2  2  2]\n",
      " [ 6  4  0  1  1  1  1]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  1  0  0  0  0  0]\n",
      " [ 2  1  0  0  0  0  0]\n",
      " [ 2  1  0  0  0  0  0]\n",
      " [ 4  2  0  1  1  1  1]\n",
      " [ 1  1  0  0  0  0  0]\n",
      " [10  6  0  2  2  2  2]\n",
      " [ 1  1  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[31 20  0  5  5  5  5]\n",
      " [21 13  0  3  3  3  3]\n",
      " [41 26  0  7  7  7  7]\n",
      " [26 17  0  4  4  4  4]\n",
      " [15  9  0  2  2  2  2]\n",
      " [17 11  0  3  3  3  3]\n",
      " [17 11  0  3  3  3  3]\n",
      " [17 11  0  3  3  3  3]\n",
      " [21 13  0  3  3  3  3]\n",
      " [16 10  0  3  3  3  3]\n",
      " [32 21  0  5  5  5  5]\n",
      " [15 10  0  2  2  2  2]]\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[54 34  0  9  9  9  9]\n",
      " [37 24  0  6  6  6  6]\n",
      " [68 44  0 11 11 11 11]\n",
      " [46 29  0  7  7  7  7]\n",
      " [28 18  0  5  5  5  5]\n",
      " [32 20  0  5  5  5  5]\n",
      " [32 21  0  5  5  5  5]\n",
      " [32 21  0  5  5  5  5]\n",
      " [37 24  0  6  6  6  6]\n",
      " [31 20  0  5  5  5  5]\n",
      " [55 35  0  9  9  9  9]\n",
      " [30 19  0  5  5  5  5]]\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[ 7  2  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [25  7  0  0  0  0  0]\n",
      " [ 3  1  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 8  2  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[38 10  0  0  0  0  0]\n",
      " [26  7  0  0  0  0  0]\n",
      " [74 19  0  0  0  0  0]\n",
      " [29  8  0  0  0  0  0]\n",
      " [25  7  0  0  0  0  0]\n",
      " [24  6  0  0  0  0  0]\n",
      " [24  6  0  0  0  0  0]\n",
      " [25  7  0  0  0  0  0]\n",
      " [26  7  0  0  0  0  0]\n",
      " [25  7  0  0  0  0  0]\n",
      " [40 10  0  0  0  0  0]\n",
      " [25  7  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "[[ 68  18   0   0   0   0   0]\n",
      " [ 50  13   0   0   0   0   0]\n",
      " [122  32   0   0   0   0   0]\n",
      " [ 56  15   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 50  13   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 72  19   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "mx_wndws=int(np.max(cls_wndws)+1)   # حداکثر تعداد پنجره ی موجود بین کلاس ها\n",
    "print('\\n max =', mx_wndws)\n",
    "aug_amnt_Ttl=np.empty((0,7), int) \n",
    "rpt_cnn_clsfctn=5                 #تعداد اجرای شبکه عصبی برای میانگین گیری هر حالت \n",
    "rslts=np.array([])\n",
    "alpha=1                           #چند برابر کردن داده افزایی هر کلاس متناسب ضعیف بودن آن کلاس\n",
    "for beta in range(1,4):\n",
    "    if beta==3:\n",
    "        beta=beta*2\n",
    "    for X in range(1,4):          #داده افزایی تا چند برابر کلاس اکثریت\n",
    "        mx_wndws=int(np.max(cls_wndws))   # حداکثر تعداد پنجره ی موجود بین کلاس ها\n",
    "        mx_wndws=int(X*mx_wndws)          #داده افزایی تا چند برابر کلاس اکثریت\n",
    "        scors0=np.array([64,78,55,70,94,85,84,85,78,88,63,90])         #Class Recalls without Augmentation\n",
    "        AgScr=1+alpha*((100-scors0)/(np.max(100-scors0)))**beta            #Class Specific\n",
    "        f_scr=np.array([83,88,87,83,85,85,85,85])                      #UnAg,Scl.2,Mag.05,Tm.2,Gs1,frqnc2,GAN,LSTMexpgdo\n",
    "        f_scr_difrnc=f_scr-f_scr[0]\n",
    "        for z in range (len(f_scr_difrnc)):\n",
    "            if f_scr_difrnc[z]<0:\n",
    "                f_scr_difrnc[z]=0\n",
    "        f_scr_difrnc=f_scr_difrnc**beta\n",
    "        f_scr_rtio=f_scr_difrnc/(sum(f_scr_difrnc))\n",
    "        aug_amnt=np.empty((0,len(f_scr_rtio)-1), int) \n",
    "        for i in range (1,cls_num+1):\n",
    "            aug_amnt=np.append(aug_amnt,[f_scr_rtio[1:]*(mx_wndws*AgScr[i-1]-cls_wndws[i-1])],axis=0)\n",
    "            #vlum_win=mx_wndws-cls_wndws[i-1]             #میزان داده افزایی در روش های عمیق (پنجره)\n",
    "        aug_amnt=np.int16(np.round(aug_amnt))\n",
    "        \n",
    "        aug_amnt_Ttl=np.append(aug_amnt_Ttl,aug_amnt,axis=0)\n",
    "        #print(np.int16(100*f_scr_rtio))\n",
    "        #print(aug_amnt)\n",
    "        rprt=np.empty((0,3),float)\n",
    "        print(aug_amnt)\n",
    "        for repeat in range(1,rpt_cnn_clsfctn+1):\n",
    "            xtrain=np.empty((0,smpl_rte+1), float) \n",
    "            for i in range (1,cls_num+1):                                     #تعریف آرایه ی پنجره های کلاس ها\n",
    "                xtrain=np.append(xtrain,vars()['wndws'+str(i)],axis=0)\n",
    "                if aug_amnt[i-1,0]>0:\n",
    "                    methd=10\n",
    "                    sort=-3  #-5=Dis_sam_Cls=qlty1 #-4=var_Dis=qlty2 #-3=DisSm/DisOthr=qlty3  #-2=invrs_GDO_papr=qlty4   #-1=GDO_papr=qlty5\n",
    "                    dp_slct_dstrb=4            #1-sequencial 2-linear 3-beta 4-exponential 5-unfrm\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,0],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,0],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,1]>0:\n",
    "                    methd=20\n",
    "                    sort=-3\n",
    "                    dp_slct_dstrb=2\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,1],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,1],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,2]>0:\n",
    "                    methd=30\n",
    "                    sort=-3\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,2],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,2],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,3]>0:\n",
    "                    methd=40\n",
    "                    sort=-1\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,3],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,3],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,4]>0:\n",
    "                    methd=50\n",
    "                    sort=-3\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,4],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,4],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,5]>0:\n",
    "                    methd=60\n",
    "                    sort=-1\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,5],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,5],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,6]>0:\n",
    "                    methd=70\n",
    "                    sort=-1\n",
    "                    dp_slct_dstrb=2\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,6],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,6],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                #print('class ', i, 'train shape = ', np.shape(xtrain))\n",
    "\n",
    "            # Normalization train windows\n",
    "            mx_aug=np.max(xtrain[:,:-1])\n",
    "            mx=np.max(ecg[:,:-1])\n",
    "            mn_aug=np.min(xtrain[:,:-1])\n",
    "            mn=np.min(ecg[:,:-1])\n",
    "            xtrain[:,:-1]= 2*(xtrain[:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1\n",
    "\n",
    "\n",
    "            ###Test Windows:\n",
    "            wndws_test=np.empty((0,len(wndws1[0])), float)\n",
    "            i=0\n",
    "            windws=np.array([])\n",
    "            for cls in range (1,cls_num+1):                                 #ساخت پنجره های داده های تست\n",
    "                vars()['wndws_tst'+str(cls)]=np.empty((0,len(wndws1[0])), float)\n",
    "                vars()['wndws_tst'+str(cls)]=np.append(vars()['wndws_tst'+str(cls)],vars()['ecg_tst'+str(cls)],axis=0)   \n",
    "\n",
    "            # Normalization test windows\n",
    "            for i in range (1,cls_num+1):                \n",
    "                cls=i\n",
    "                vars()['wndws_tst'+str(i)][:,:-1]= 2*(vars()['wndws_tst'+str(i)][:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1\n",
    "            for cls in range (1,cls_num+1):                                # آرایه ی تعداد پنجره ی هر کلاس\n",
    "                wns=len(vars()['wndws_tst'+str(cls)])\n",
    "                wndws_test=np.append(wndws_test,vars()['wndws_tst'+str(cls)],axis=0)\n",
    "\n",
    "            Xtest=wndws_test[:,:-1]\n",
    "            ytest=np.int16(wndws_test[:,-1])\n",
    "\n",
    "            trainx=np.random.permutation(xtrain)\n",
    "            Xtrain=np.array(trainx[:,:-1])\n",
    "            ytrain=np.int16(trainx[:,-1])\n",
    "\n",
    "            X_train=np.array(Xtrain)\n",
    "            y_train=np.array(ytrain)\n",
    "            X_test=np.array(Xtest)\n",
    "            y_test=np.array(ytest)\n",
    "            X_valid=np.array(Xtrain)\n",
    "            y_valid=np.array(ytrain)\n",
    "            #print('X_train => ', X_train.shape)\n",
    "            #print('y_train => ', y_train.shape)\n",
    "            #print('X_test  => ', X_test.shape)\n",
    "            #print('y_test  => ', y_test.shape)\n",
    "            #print('X_valid  => ', X_valid.shape)\n",
    "            #print('y_valid  => ', y_valid.shape)\n",
    "\n",
    "            y_train_cat=to_categorical(y_train)\n",
    "            y_valid_cat=to_categorical(y_valid)\n",
    "            y_test_cat=to_categorical(y_test)\n",
    "            X_train = np.expand_dims(X_train, axis=2)\n",
    "            X_valid = np.expand_dims(X_valid, axis=2)\n",
    "            X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "            ####### NETWORK #######\n",
    "            accuracy=0\n",
    "            acc_crs=np.array([])\n",
    "            ##for i in range (10):\n",
    "            ##    if accuracy<0.2 :\n",
    "            verbose, epochs, batch_size = 0, 1000, btch\n",
    "            n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train_cat.shape[1]\n",
    "            steps_per_epoch = len(X_train)//batch_size\n",
    "            validation_steps = len(X_valid)//batch_size # if you have test data\n",
    "            model_crs = Sequential()\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "            #model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "            #model_crs.add(Dropout(0.5))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            '''model_crs.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            model_crs.add(Conv1D(filters=1024, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            '''\n",
    "            model_crs.add(Flatten())\n",
    "            #model_crs.add(Dropout(0.5))\n",
    "            model_crs.add(Dense(2000, activation='relu'))\n",
    "            model_crs.add(Dense(n_outputs, activation='softmax'))\n",
    "            model_crs.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            # fit network   #CategoricalCrossentropy #sparse_categorical_crossentropy #SparseCategoricalCrossentropy\n",
    "            earlystopping = callbacks.EarlyStopping(monitor =\"val_accuracy\", mode =\"max\", patience = 20, restore_best_weights = True)\n",
    "            model_crs.fit(X_train, y_train_cat, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data = (X_valid, y_valid_cat), callbacks =[earlystopping])\n",
    "            # evaluate model_crs\n",
    "            _, accuracy = model_crs.evaluate(X_valid, y_valid_cat, batch_size=batch_size, verbose=verbose)\n",
    "            predict_x=model_crs.predict(X_test)              # Function 1\n",
    "            y_pred_crs=maxindx(predict_x)                    # function from augment.py to remove 0 index predictions\n",
    "            rprt0=classification_report(y_test, y_pred_crs,output_dict=True)\n",
    "            rprt_row=np.array([])\n",
    "            rprt_row=np.append(rprt_row,rprt0['accuracy'])\n",
    "            rprt_row=np.append(rprt_row,rprt0['macro avg']['f1-score'])\n",
    "            rprt_row=np.append(rprt_row,rprt0['weighted avg']['f1-score'])\n",
    "            rprt=np.append(rprt,[rprt_row],axis=0)\n",
    "        #print('rprt=',rprt)\n",
    "        maxm=rprt[np.argmax(rprt[:,1])]\n",
    "        #print('maxm=',maxm)\n",
    "        avrg=np.mean(rprt,axis=0)\n",
    "        #print('avrg=',avrg)\n",
    "        rslts=np.append(rslts,['Beta '+str(beta)+'  X '+str(X)+'  average= '+str(np.int16(100*avrg))+'  max= '+str(np.int16(100*maxm))+'  var= '+str(np.int16(np.var(100*rprt,axis=0)))],axis=0)\n",
    "        #print('rslts=',rslts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8,   6,   0,   3,   3,   3,   3],\n",
       "       [  5,   4,   0,   2,   2,   2,   2],\n",
       "       [  9,   8,   0,   4,   4,   4,   4],\n",
       "       [  6,   5,   0,   3,   3,   3,   3],\n",
       "       [  2,   1,   0,   1,   1,   1,   1],\n",
       "       [  3,   2,   0,   1,   1,   1,   1],\n",
       "       [  3,   3,   0,   1,   1,   1,   1],\n",
       "       [  3,   3,   0,   1,   1,   1,   1],\n",
       "       [  5,   4,   0,   2,   2,   2,   2],\n",
       "       [  3,   2,   0,   1,   1,   1,   1],\n",
       "       [  8,   6,   0,   3,   3,   3,   3],\n",
       "       [  2,   2,   0,   1,   1,   1,   1],\n",
       "       [ 24,  19,   0,  10,  10,  10,  10],\n",
       "       [ 18,  15,   0,   7,   7,   7,   7],\n",
       "       [ 28,  22,   0,  11,  11,  11,  11],\n",
       "       [ 22,  17,   0,   9,   9,   9,   9],\n",
       "       [ 12,   9,   0,   5,   5,   5,   5],\n",
       "       [ 15,  12,   0,   6,   6,   6,   6],\n",
       "       [ 16,  12,   0,   6,   6,   6,   6],\n",
       "       [ 15,  12,   0,   6,   6,   6,   6],\n",
       "       [ 18,  15,   0,   7,   7,   7,   7],\n",
       "       [ 14,  11,   0,   6,   6,   6,   6],\n",
       "       [ 24,  20,   0,  10,  10,  10,  10],\n",
       "       [ 13,  11,   0,   5,   5,   5,   5],\n",
       "       [ 40,  32,   0,  16,  16,  16,  16],\n",
       "       [ 32,  26,   0,  13,  13,  13,  13],\n",
       "       [ 46,  37,   0,  18,  18,  18,  18],\n",
       "       [ 37,  29,   0,  15,  15,  15,  15],\n",
       "       [ 22,  18,   0,   9,   9,   9,   9],\n",
       "       [ 27,  22,   0,  11,  11,  11,  11],\n",
       "       [ 28,  22,   0,  11,  11,  11,  11],\n",
       "       [ 28,  22,   0,  11,  11,  11,  11],\n",
       "       [ 32,  26,   0,  13,  13,  13,  13],\n",
       "       [ 26,  21,   0,  10,  10,  10,  10],\n",
       "       [ 41,  33,   0,  16,  16,  16,  16],\n",
       "       [ 25,  20,   0,  10,  10,  10,  10],\n",
       "       [  9,   6,   0,   1,   1,   1,   1],\n",
       "       [  4,   2,   0,   1,   1,   1,   1],\n",
       "       [ 14,   9,   0,   2,   2,   2,   2],\n",
       "       [  6,   4,   0,   1,   1,   1,   1],\n",
       "       [  1,   0,   0,   0,   0,   0,   0],\n",
       "       [  2,   1,   0,   0,   0,   0,   0],\n",
       "       [  2,   1,   0,   0,   0,   0,   0],\n",
       "       [  2,   1,   0,   0,   0,   0,   0],\n",
       "       [  4,   2,   0,   1,   1,   1,   1],\n",
       "       [  1,   1,   0,   0,   0,   0,   0],\n",
       "       [ 10,   6,   0,   2,   2,   2,   2],\n",
       "       [  1,   1,   0,   0,   0,   0,   0],\n",
       "       [ 31,  20,   0,   5,   5,   5,   5],\n",
       "       [ 21,  13,   0,   3,   3,   3,   3],\n",
       "       [ 41,  26,   0,   7,   7,   7,   7],\n",
       "       [ 26,  17,   0,   4,   4,   4,   4],\n",
       "       [ 15,   9,   0,   2,   2,   2,   2],\n",
       "       [ 17,  11,   0,   3,   3,   3,   3],\n",
       "       [ 17,  11,   0,   3,   3,   3,   3],\n",
       "       [ 17,  11,   0,   3,   3,   3,   3],\n",
       "       [ 21,  13,   0,   3,   3,   3,   3],\n",
       "       [ 16,  10,   0,   3,   3,   3,   3],\n",
       "       [ 32,  21,   0,   5,   5,   5,   5],\n",
       "       [ 15,  10,   0,   2,   2,   2,   2],\n",
       "       [ 54,  34,   0,   9,   9,   9,   9],\n",
       "       [ 37,  24,   0,   6,   6,   6,   6],\n",
       "       [ 68,  44,   0,  11,  11,  11,  11],\n",
       "       [ 46,  29,   0,   7,   7,   7,   7],\n",
       "       [ 28,  18,   0,   5,   5,   5,   5],\n",
       "       [ 32,  20,   0,   5,   5,   5,   5],\n",
       "       [ 32,  21,   0,   5,   5,   5,   5],\n",
       "       [ 32,  21,   0,   5,   5,   5,   5],\n",
       "       [ 37,  24,   0,   6,   6,   6,   6],\n",
       "       [ 31,  20,   0,   5,   5,   5,   5],\n",
       "       [ 55,  35,   0,   9,   9,   9,   9],\n",
       "       [ 30,  19,   0,   5,   5,   5,   5],\n",
       "       [  7,   2,   0,   0,   0,   0,   0],\n",
       "       [  1,   0,   0,   0,   0,   0,   0],\n",
       "       [ 25,   7,   0,   0,   0,   0,   0],\n",
       "       [  3,   1,   0,   0,   0,   0,   0],\n",
       "       [  1,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0],\n",
       "       [  1,   0,   0,   0,   0,   0,   0],\n",
       "       [  1,   0,   0,   0,   0,   0,   0],\n",
       "       [  1,   0,   0,   0,   0,   0,   0],\n",
       "       [  8,   2,   0,   0,   0,   0,   0],\n",
       "       [  1,   0,   0,   0,   0,   0,   0],\n",
       "       [ 38,  10,   0,   0,   0,   0,   0],\n",
       "       [ 26,   7,   0,   0,   0,   0,   0],\n",
       "       [ 74,  19,   0,   0,   0,   0,   0],\n",
       "       [ 29,   8,   0,   0,   0,   0,   0],\n",
       "       [ 25,   7,   0,   0,   0,   0,   0],\n",
       "       [ 24,   6,   0,   0,   0,   0,   0],\n",
       "       [ 24,   6,   0,   0,   0,   0,   0],\n",
       "       [ 25,   7,   0,   0,   0,   0,   0],\n",
       "       [ 26,   7,   0,   0,   0,   0,   0],\n",
       "       [ 25,   7,   0,   0,   0,   0,   0],\n",
       "       [ 40,  10,   0,   0,   0,   0,   0],\n",
       "       [ 25,   7,   0,   0,   0,   0,   0],\n",
       "       [ 68,  18,   0,   0,   0,   0,   0],\n",
       "       [ 50,  13,   0,   0,   0,   0,   0],\n",
       "       [122,  32,   0,   0,   0,   0,   0],\n",
       "       [ 56,  15,   0,   0,   0,   0,   0],\n",
       "       [ 49,  13,   0,   0,   0,   0,   0],\n",
       "       [ 49,  13,   0,   0,   0,   0,   0],\n",
       "       [ 49,  13,   0,   0,   0,   0,   0],\n",
       "       [ 49,  13,   0,   0,   0,   0,   0],\n",
       "       [ 50,  13,   0,   0,   0,   0,   0],\n",
       "       [ 49,  13,   0,   0,   0,   0,   0],\n",
       "       [ 72,  19,   0,   0,   0,   0,   0],\n",
       "       [ 49,  13,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_amnt_Ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Beta 1  X 1  average= [84 84 84]  max= [85 85 85]  var= [1 1 1]',\n",
       "       'Beta 1  X 2  average= [88 87 87]  max= [88 88 88]  var= [0 0 0]',\n",
       "       'Beta 1  X 3  average= [87 87 87]  max= [88 88 88]  var= [1 1 1]',\n",
       "       'Beta 2  X 1  average= [85 85 85]  max= [88 88 88]  var= [2 2 2]',\n",
       "       'Beta 2  X 2  average= [87 87 87]  max= [88 88 88]  var= [0 0 0]',\n",
       "       'Beta 2  X 3  average= [88 88 88]  max= [90 90 89]  var= [0 0 0]',\n",
       "       'Beta 6  X 1  average= [84 84 84]  max= [87 87 87]  var= [3 2 2]',\n",
       "       'Beta 6  X 2  average= [86 85 85]  max= [87 86 86]  var= [0 0 0]',\n",
       "       'Beta 6  X 3  average= [86 86 86]  max= [89 89 89]  var= [3 4 4]'],\n",
       "      dtype='<U63')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2=rslts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " max = 32\n",
      "[[4 3 0 2 2 2 2]\n",
      " [3 2 0 1 1 1 1]\n",
      " [5 4 0 2 2 2 2]\n",
      " [3 3 0 1 1 1 1]\n",
      " [1 1 0 0 0 0 0]\n",
      " [2 1 0 1 1 1 1]\n",
      " [2 1 0 1 1 1 1]\n",
      " [2 2 0 1 1 1 1]\n",
      " [3 2 0 1 1 1 1]\n",
      " [2 1 0 1 1 1 1]\n",
      " [4 3 0 2 2 2 2]\n",
      " [2 1 0 1 1 1 1]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "[[11  9  0  4  4  4  4]\n",
      " [ 7  5  0  3  3  3  3]\n",
      " [13 11  0  5  5  5  5]\n",
      " [ 9  7  0  4  4  4  4]\n",
      " [ 2  2  0  1  1  1  1]\n",
      " [ 5  4  0  2  2  2  2]\n",
      " [ 5  4  0  2  2  2  2]\n",
      " [ 5  4  0  2  2  2  2]\n",
      " [ 7  5  0  3  3  3  3]\n",
      " [ 4  3  0  2  2  2  2]\n",
      " [11  9  0  4  4  4  4]\n",
      " [ 3  3  0  1  1  1  1]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[34 28  0 14 14 14 14]\n",
      " [21 17  0  9  9  9  9]\n",
      " [43 34  0 17 17 17 17]\n",
      " [29 23  0 12 12 12 12]\n",
      " [ 6  5  0  2  2  2  2]\n",
      " [14 12  0  6  6  6  6]\n",
      " [15 12  0  6  6  6  6]\n",
      " [15 12  0  6  6  6  6]\n",
      " [21 17  0  9  9  9  9]\n",
      " [12 10  0  5  5  5  5]\n",
      " [35 28  0 14 14 14 14]\n",
      " [10  8  0  4  4  4  4]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[6 4 0 1 1 1 1]\n",
      " [4 3 0 1 1 1 1]\n",
      " [7 5 0 1 1 1 1]\n",
      " [5 3 0 1 1 1 1]\n",
      " [2 1 0 0 0 0 0]\n",
      " [3 2 0 0 0 0 0]\n",
      " [3 2 0 0 0 0 0]\n",
      " [3 2 0 0 0 0 0]\n",
      " [4 3 0 1 1 1 1]\n",
      " [3 2 0 0 0 0 0]\n",
      " [6 4 0 1 1 1 1]\n",
      " [2 1 0 0 0 0 0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[16 10  0  3  3  3  3]\n",
      " [10  6  0  2  2  2  2]\n",
      " [20 13  0  3  3  3  3]\n",
      " [14  9  0  2  2  2  2]\n",
      " [ 3  2  0  1  1  1  1]\n",
      " [ 7  4  0  1  1  1  1]\n",
      " [ 7  5  0  1  1  1  1]\n",
      " [ 7  5  0  1  1  1  1]\n",
      " [10  6  0  2  2  2  2]\n",
      " [ 6  4  0  1  1  1  1]\n",
      " [16 11  0  3  3  3  3]\n",
      " [ 5  3  0  1  1  1  1]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[51 33  0  8  8  8  8]\n",
      " [32 20  0  5  5  5  5]\n",
      " [64 41  0 10 10 10 10]\n",
      " [43 28  0  7  7  7  7]\n",
      " [ 9  6  0  1  1  1  1]\n",
      " [21 14  0  3  3  3  3]\n",
      " [23 15  0  4  4  4  4]\n",
      " [22 14  0  4  4  4  4]\n",
      " [32 20  0  5  5  5  5]\n",
      " [18 11  0  3  3  3  3]\n",
      " [53 34  0  8  8  8  8]\n",
      " [15 10  0  2  2  2  2]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[11  3  0  0  0  0  0]\n",
      " [ 7  2  0  0  0  0  0]\n",
      " [13  3  0  0  0  0  0]\n",
      " [ 9  2  0  0  0  0  0]\n",
      " [ 3  1  0  0  0  0  0]\n",
      " [ 5  1  0  0  0  0  0]\n",
      " [ 5  1  0  0  0  0  0]\n",
      " [ 5  1  0  0  0  0  0]\n",
      " [ 7  2  0  0  0  0  0]\n",
      " [ 5  1  0  0  0  0  0]\n",
      " [11  3  0  0  0  0  0]\n",
      " [ 4  1  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[29  7  0  0  0  0  0]\n",
      " [18  5  0  0  0  0  0]\n",
      " [35  9  0  0  0  0  0]\n",
      " [24  6  0  0  0  0  0]\n",
      " [ 6  2  0  0  0  0  0]\n",
      " [12  3  0  0  0  0  0]\n",
      " [13  3  0  0  0  0  0]\n",
      " [13  3  0  0  0  0  0]\n",
      " [18  5  0  0  0  0  0]\n",
      " [11  3  0  0  0  0  0]\n",
      " [29  8  0  0  0  0  0]\n",
      " [ 9  2  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[ 92  24   0   0   0   0   0]\n",
      " [ 57  15   0   0   0   0   0]\n",
      " [114  30   0   0   0   0   0]\n",
      " [ 77  20   0   0   0   0   0]\n",
      " [ 17   4   0   0   0   0   0]\n",
      " [ 38  10   0   0   0   0   0]\n",
      " [ 41  11   0   0   0   0   0]\n",
      " [ 39  10   0   0   0   0   0]\n",
      " [ 57  15   0   0   0   0   0]\n",
      " [ 32   8   0   0   0   0   0]\n",
      " [ 94  25   0   0   0   0   0]\n",
      " [ 27   7   0   0   0   0   0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "mx_wndws=int(np.max(cls_wndws)+1)   # حداکثر تعداد پنجره ی موجود بین کلاس ها\n",
    "print('\\n max =', mx_wndws)\n",
    "aug_amnt_Ttl=np.empty((0,7), int) \n",
    "rslts=np.array([])\n",
    "X=1                               #داده افزایی تا چند برابر کلاس اکثریت\n",
    "for beta in range(1,4):\n",
    "    if beta==3:\n",
    "        beta=beta*2\n",
    "    rprt=np.array([])\n",
    "    for alpha in range(1,7,2):    #چند برابر کردن داده افزایی هر کلاس متناسب ضعیف بودن آن کلاس\n",
    "        if alpha==5:\n",
    "            alpha=10\n",
    "        scors0=np.array([64,78,55,70,94,85,84,85,78,88,63,90])         #Class Recalls without Augmentation\n",
    "        AgScr=1+alpha*(100-scors0)/100            #Class Specific\n",
    "\n",
    "        f_scr=np.array([83,88,87,83,85,85,85,85])                      #UnAg,Scl.2,Mag.05,Tm.2,Gs1,frqnc2,GAN,LSTMexpgdo\n",
    "        f_scr_difrnc=f_scr-f_scr[0]\n",
    "        for z in range (len(f_scr_difrnc)):\n",
    "            if f_scr_difrnc[z]<0:\n",
    "                f_scr_difrnc[z]=0\n",
    "        f_scr_difrnc=f_scr_difrnc**beta\n",
    "        f_scr_rtio=f_scr_difrnc/(sum(f_scr_difrnc))\n",
    "        aug_amnt=np.empty((0,len(f_scr_rtio)-1), int) \n",
    "\n",
    "        for i in range (1,cls_num+1):\n",
    "            aug_amnt=np.append(aug_amnt,[f_scr_rtio[1:]*(mx_wndws*AgScr[i-1]-cls_wndws[i-1])],axis=0)\n",
    "            #vlum_win=mx_wndws-cls_wndws[i-1]             #میزان داده افزایی در روش های عمیق (پنجره)\n",
    "        aug_amnt=np.int16(np.round(aug_amnt))\n",
    "        aug_amnt_Ttl=np.append(aug_amnt_Ttl,aug_amnt,axis=0)\n",
    "        #print(np.int16(100*f_scr_rtio))\n",
    "        #print(aug_amnt)\n",
    "        rprt=np.empty((0,3),float)\n",
    "        print(aug_amnt)\n",
    "        for repeat in range(1,rpt_cnn_clsfctn+1):\n",
    "            xtrain=np.empty((0,smpl_rte+1), float) \n",
    "            for i in range (1,cls_num+1):                                     #تعریف آرایه ی پنجره های کلاس ها\n",
    "                xtrain=np.append(xtrain,vars()['wndws'+str(i)],axis=0)\n",
    "                if aug_amnt[i-1,0]>0:\n",
    "                    methd=10\n",
    "                    sort=-3  #-5=Dis_sam_Cls=qlty1 #-4=var_Dis=qlty2 #-3=DisSm/DisOthr=qlty3  #-2=invrs_GDO_papr=qlty4   #-1=GDO_papr=qlty5\n",
    "                    dp_slct_dstrb=4            #1-sequencial 2-linear 3-beta 4-exponential 5-unfrm\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,0],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,0],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,1]>0:\n",
    "                    methd=20\n",
    "                    sort=-3\n",
    "                    dp_slct_dstrb=2\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,0],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,0],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,2]>0:\n",
    "                    methd=30\n",
    "                    sort=-3\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,2],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,2],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,3]>0:\n",
    "                    methd=40\n",
    "                    sort=-1\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,3],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,3],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,4]>0:\n",
    "                    methd=50\n",
    "                    sort=-3\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,4],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,4],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,5]>0:\n",
    "                    methd=60\n",
    "                    sort=-1\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,5],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,5],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,6]>0:\n",
    "                    methd=70\n",
    "                    sort=-1\n",
    "                    dp_slct_dstrb=2\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,6],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,6],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                #print('class ', i, 'train shape = ', np.shape(xtrain))\n",
    "\n",
    "            # Normalization train windows\n",
    "            mx_aug=np.max(xtrain[:,:-1])\n",
    "            mx=np.max(ecg[:,:-1])\n",
    "            mn_aug=np.min(xtrain[:,:-1])\n",
    "            mn=np.min(ecg[:,:-1])\n",
    "            xtrain[:,:-1]= 2*(xtrain[:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1\n",
    "\n",
    "\n",
    "            ###Test Windows:\n",
    "            wndws_test=np.empty((0,len(wndws1[0])), float)\n",
    "            i=0\n",
    "            windws=np.array([])\n",
    "            for cls in range (1,cls_num+1):                                 #ساخت پنجره های داده های آموزش اصلی\n",
    "                vars()['wndws_tst'+str(cls)]=np.empty((0,len(wndws1[0])), float)\n",
    "                vars()['wndws_tst'+str(cls)]=np.append(vars()['wndws_tst'+str(cls)],vars()['ecg_tst'+str(cls)],axis=0)   \n",
    "\n",
    "            # Normalization test windows\n",
    "            for i in range (1,cls_num+1):                \n",
    "                cls=i\n",
    "                #print('\\n cls', i, ' >> ')\n",
    "                #print('max magnitude class', i , ' = ' ,np.max(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "                #print('min magnitude class', i , ' = ' ,np.min(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "                vars()['wndws_tst'+str(i)][:,:-1]= 2*(vars()['wndws_tst'+str(i)][:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1\n",
    "                #print('after normalizing >>')\n",
    "                #print('max magnitude class', i , ' = ' ,np.max(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "                #print('min magnitude class', i , ' = ' ,np.min(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "            #print(\"each class and its windows =\")                    #تجمیع کلاس های تست\n",
    "            for cls in range (1,cls_num+1):                                # آرایه ی تعداد پنجره ی هر کلاس\n",
    "                wns=len(vars()['wndws_tst'+str(cls)])\n",
    "                wndws_test=np.append(wndws_test,vars()['wndws_tst'+str(cls)],axis=0)\n",
    "            Xtest=wndws_test[:,:-1]\n",
    "            ytest=np.int16(wndws_test[:,-1])\n",
    "\n",
    "            trainx=np.random.permutation(xtrain)\n",
    "            Xtrain=np.array(trainx[:,:-1])\n",
    "            ytrain=np.int16(trainx[:,-1])\n",
    "\n",
    "            X_train=np.array(Xtrain)\n",
    "            y_train=np.array(ytrain)\n",
    "            X_test=np.array(Xtest)\n",
    "            y_test=np.array(ytest)\n",
    "            X_valid=np.array(Xtrain)\n",
    "            y_valid=np.array(ytrain)\n",
    "            #print('X_train => ', X_train.shape)\n",
    "            #print('y_train => ', y_train.shape)\n",
    "            #print('X_test  => ', X_test.shape)\n",
    "            #print('y_test  => ', y_test.shape)\n",
    "            #print('X_valid  => ', X_valid.shape)\n",
    "            #print('y_valid  => ', y_valid.shape)\n",
    "\n",
    "            y_train_cat=to_categorical(y_train)\n",
    "            y_valid_cat=to_categorical(y_valid)\n",
    "            y_test_cat=to_categorical(y_test)\n",
    "            X_train = np.expand_dims(X_train, axis=2)\n",
    "            X_valid = np.expand_dims(X_valid, axis=2)\n",
    "            X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "            ####### NETWORK #######\n",
    "            accuracy=0\n",
    "            acc_crs=np.array([])\n",
    "            ##for i in range (10):\n",
    "            ##    if accuracy<0.2 :\n",
    "            verbose, epochs, batch_size = 0, 1000, btch\n",
    "            n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train_cat.shape[1]\n",
    "            steps_per_epoch = len(X_train)//batch_size\n",
    "            validation_steps = len(X_valid)//batch_size # if you have test data\n",
    "            model_crs = Sequential()\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "            #model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "            #model_crs.add(Dropout(0.5))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            '''model_crs.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            model_crs.add(Conv1D(filters=1024, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            '''\n",
    "            model_crs.add(Flatten())\n",
    "            #model_crs.add(Dropout(0.5))\n",
    "            model_crs.add(Dense(2000, activation='relu'))\n",
    "            model_crs.add(Dense(n_outputs, activation='softmax'))\n",
    "            model_crs.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            # fit network   #CategoricalCrossentropy #sparse_categorical_crossentropy #SparseCategoricalCrossentropy\n",
    "            earlystopping = callbacks.EarlyStopping(monitor =\"val_accuracy\", mode =\"max\", patience = 20, restore_best_weights = True)\n",
    "            model_crs.fit(X_train, y_train_cat, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data = (X_valid, y_valid_cat), callbacks =[earlystopping])\n",
    "            # evaluate model_crs\n",
    "            _, accuracy = model_crs.evaluate(X_valid, y_valid_cat, batch_size=batch_size, verbose=verbose)\n",
    "            predict_x=model_crs.predict(X_test)              # Function 1\n",
    "            y_pred_crs=maxindx(predict_x)                    # function from augment.py to remove 0 index predictions\n",
    "            rprt0=classification_report(y_test, y_pred_crs,output_dict=True)\n",
    "            rprt_row=np.array([])\n",
    "            rprt_row=np.append(rprt_row,rprt0['accuracy'])\n",
    "            rprt_row=np.append(rprt_row,rprt0['macro avg']['f1-score'])\n",
    "            rprt_row=np.append(rprt_row,rprt0['weighted avg']['f1-score'])\n",
    "            rprt=np.append(rprt,[rprt_row],axis=0)\n",
    "        #print('rprt=',rprt)\n",
    "        maxm=rprt[np.argmax(rprt[:,1])]\n",
    "        #print('maxm=',maxm)\n",
    "        avrg=np.mean(rprt,axis=0)\n",
    "        #print('avrg=',avrg)\n",
    "        rslts=np.append(rslts,['Beta '+str(beta)+'  alpha '+str(alpha) +'  average= '+str(np.int16(100*avrg))+'  max= '+str(np.int16(100*maxm))+'  var= '+str(np.int16(np.var(100*rprt,axis=0)))],axis=0)\n",
    "        #print('rslts=',rslts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4,   3,   0,   2,   2,   2,   2],\n",
       "       [  3,   2,   0,   1,   1,   1,   1],\n",
       "       [  5,   4,   0,   2,   2,   2,   2],\n",
       "       [  3,   3,   0,   1,   1,   1,   1],\n",
       "       [  1,   1,   0,   0,   0,   0,   0],\n",
       "       [  2,   1,   0,   1,   1,   1,   1],\n",
       "       [  2,   1,   0,   1,   1,   1,   1],\n",
       "       [  2,   2,   0,   1,   1,   1,   1],\n",
       "       [  3,   2,   0,   1,   1,   1,   1],\n",
       "       [  2,   1,   0,   1,   1,   1,   1],\n",
       "       [  4,   3,   0,   2,   2,   2,   2],\n",
       "       [  2,   1,   0,   1,   1,   1,   1],\n",
       "       [ 11,   9,   0,   4,   4,   4,   4],\n",
       "       [  7,   5,   0,   3,   3,   3,   3],\n",
       "       [ 13,  11,   0,   5,   5,   5,   5],\n",
       "       [  9,   7,   0,   4,   4,   4,   4],\n",
       "       [  2,   2,   0,   1,   1,   1,   1],\n",
       "       [  5,   4,   0,   2,   2,   2,   2],\n",
       "       [  5,   4,   0,   2,   2,   2,   2],\n",
       "       [  5,   4,   0,   2,   2,   2,   2],\n",
       "       [  7,   5,   0,   3,   3,   3,   3],\n",
       "       [  4,   3,   0,   2,   2,   2,   2],\n",
       "       [ 11,   9,   0,   4,   4,   4,   4],\n",
       "       [  3,   3,   0,   1,   1,   1,   1],\n",
       "       [ 34,  28,   0,  14,  14,  14,  14],\n",
       "       [ 21,  17,   0,   9,   9,   9,   9],\n",
       "       [ 43,  34,   0,  17,  17,  17,  17],\n",
       "       [ 29,  23,   0,  12,  12,  12,  12],\n",
       "       [  6,   5,   0,   2,   2,   2,   2],\n",
       "       [ 14,  12,   0,   6,   6,   6,   6],\n",
       "       [ 15,  12,   0,   6,   6,   6,   6],\n",
       "       [ 15,  12,   0,   6,   6,   6,   6],\n",
       "       [ 21,  17,   0,   9,   9,   9,   9],\n",
       "       [ 12,  10,   0,   5,   5,   5,   5],\n",
       "       [ 35,  28,   0,  14,  14,  14,  14],\n",
       "       [ 10,   8,   0,   4,   4,   4,   4],\n",
       "       [  6,   4,   0,   1,   1,   1,   1],\n",
       "       [  4,   3,   0,   1,   1,   1,   1],\n",
       "       [  7,   5,   0,   1,   1,   1,   1],\n",
       "       [  5,   3,   0,   1,   1,   1,   1],\n",
       "       [  2,   1,   0,   0,   0,   0,   0],\n",
       "       [  3,   2,   0,   0,   0,   0,   0],\n",
       "       [  3,   2,   0,   0,   0,   0,   0],\n",
       "       [  3,   2,   0,   0,   0,   0,   0],\n",
       "       [  4,   3,   0,   1,   1,   1,   1],\n",
       "       [  3,   2,   0,   0,   0,   0,   0],\n",
       "       [  6,   4,   0,   1,   1,   1,   1],\n",
       "       [  2,   1,   0,   0,   0,   0,   0],\n",
       "       [ 16,  10,   0,   3,   3,   3,   3],\n",
       "       [ 10,   6,   0,   2,   2,   2,   2],\n",
       "       [ 20,  13,   0,   3,   3,   3,   3],\n",
       "       [ 14,   9,   0,   2,   2,   2,   2],\n",
       "       [  3,   2,   0,   1,   1,   1,   1],\n",
       "       [  7,   4,   0,   1,   1,   1,   1],\n",
       "       [  7,   5,   0,   1,   1,   1,   1],\n",
       "       [  7,   5,   0,   1,   1,   1,   1],\n",
       "       [ 10,   6,   0,   2,   2,   2,   2],\n",
       "       [  6,   4,   0,   1,   1,   1,   1],\n",
       "       [ 16,  11,   0,   3,   3,   3,   3],\n",
       "       [  5,   3,   0,   1,   1,   1,   1],\n",
       "       [ 51,  33,   0,   8,   8,   8,   8],\n",
       "       [ 32,  20,   0,   5,   5,   5,   5],\n",
       "       [ 64,  41,   0,  10,  10,  10,  10],\n",
       "       [ 43,  28,   0,   7,   7,   7,   7],\n",
       "       [  9,   6,   0,   1,   1,   1,   1],\n",
       "       [ 21,  14,   0,   3,   3,   3,   3],\n",
       "       [ 23,  15,   0,   4,   4,   4,   4],\n",
       "       [ 22,  14,   0,   4,   4,   4,   4],\n",
       "       [ 32,  20,   0,   5,   5,   5,   5],\n",
       "       [ 18,  11,   0,   3,   3,   3,   3],\n",
       "       [ 53,  34,   0,   8,   8,   8,   8],\n",
       "       [ 15,  10,   0,   2,   2,   2,   2],\n",
       "       [ 11,   3,   0,   0,   0,   0,   0],\n",
       "       [  7,   2,   0,   0,   0,   0,   0],\n",
       "       [ 13,   3,   0,   0,   0,   0,   0],\n",
       "       [  9,   2,   0,   0,   0,   0,   0],\n",
       "       [  3,   1,   0,   0,   0,   0,   0],\n",
       "       [  5,   1,   0,   0,   0,   0,   0],\n",
       "       [  5,   1,   0,   0,   0,   0,   0],\n",
       "       [  5,   1,   0,   0,   0,   0,   0],\n",
       "       [  7,   2,   0,   0,   0,   0,   0],\n",
       "       [  5,   1,   0,   0,   0,   0,   0],\n",
       "       [ 11,   3,   0,   0,   0,   0,   0],\n",
       "       [  4,   1,   0,   0,   0,   0,   0],\n",
       "       [ 29,   7,   0,   0,   0,   0,   0],\n",
       "       [ 18,   5,   0,   0,   0,   0,   0],\n",
       "       [ 35,   9,   0,   0,   0,   0,   0],\n",
       "       [ 24,   6,   0,   0,   0,   0,   0],\n",
       "       [  6,   2,   0,   0,   0,   0,   0],\n",
       "       [ 12,   3,   0,   0,   0,   0,   0],\n",
       "       [ 13,   3,   0,   0,   0,   0,   0],\n",
       "       [ 13,   3,   0,   0,   0,   0,   0],\n",
       "       [ 18,   5,   0,   0,   0,   0,   0],\n",
       "       [ 11,   3,   0,   0,   0,   0,   0],\n",
       "       [ 29,   8,   0,   0,   0,   0,   0],\n",
       "       [  9,   2,   0,   0,   0,   0,   0],\n",
       "       [ 92,  24,   0,   0,   0,   0,   0],\n",
       "       [ 57,  15,   0,   0,   0,   0,   0],\n",
       "       [114,  30,   0,   0,   0,   0,   0],\n",
       "       [ 77,  20,   0,   0,   0,   0,   0],\n",
       "       [ 17,   4,   0,   0,   0,   0,   0],\n",
       "       [ 38,  10,   0,   0,   0,   0,   0],\n",
       "       [ 41,  11,   0,   0,   0,   0,   0],\n",
       "       [ 39,  10,   0,   0,   0,   0,   0],\n",
       "       [ 57,  15,   0,   0,   0,   0,   0],\n",
       "       [ 32,   8,   0,   0,   0,   0,   0],\n",
       "       [ 94,  25,   0,   0,   0,   0,   0],\n",
       "       [ 27,   7,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_amnt_Ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Beta 1  alpha 1  average= [86 86 86]  max= [87 87 87]  var= [2 2 2]',\n",
       "       'Beta 1  alpha 3  average= [86 86 86]  max= [89 89 89]  var= [3 3 3]',\n",
       "       'Beta 1  alpha 10  average= [87 87 87]  max= [89 89 89]  var= [2 2 2]',\n",
       "       'Beta 2  alpha 1  average= [84 84 84]  max= [86 86 86]  var= [5 4 4]',\n",
       "       'Beta 2  alpha 3  average= [86 86 86]  max= [89 89 89]  var= [1 1 1]',\n",
       "       'Beta 2  alpha 10  average= [87 87 87]  max= [89 89 89]  var= [1 1 1]',\n",
       "       'Beta 6  alpha 1  average= [83 83 83]  max= [86 86 86]  var= [3 3 3]',\n",
       "       'Beta 6  alpha 3  average= [86 85 85]  max= [87 87 87]  var= [1 1 1]',\n",
       "       'Beta 6  alpha 10  average= [86 86 86]  max= [88 88 88]  var= [3 3 3]'],\n",
       "      dtype='<U68')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3=rslts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " max = 32\n",
      "[[ 8  6  0  3  3  3  3]\n",
      " [ 5  4  0  2  2  2  2]\n",
      " [10  8  0  4  4  4  4]\n",
      " [ 7  5  0  3  3  3  3]\n",
      " [ 2  1  0  1  1  1  1]\n",
      " [ 3  3  0  1  1  1  1]\n",
      " [ 4  3  0  1  1  1  1]\n",
      " [ 4  3  0  1  1  1  1]\n",
      " [ 5  4  0  2  2  2  2]\n",
      " [ 3  2  0  1  1  1  1]\n",
      " [ 8  7  0  3  3  3  3]\n",
      " [ 3  2  0  1  1  1  1]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[16 13  0  6  6  6  6]\n",
      " [10  8  0  4  4  4  4]\n",
      " [19 16  0  8  8  8  8]\n",
      " [13 11  0  5  5  5  5]\n",
      " [ 3  2  0  1  1  1  1]\n",
      " [ 7  5  0  3  3  3  3]\n",
      " [ 7  6  0  3  3  3  3]\n",
      " [ 7  5  0  3  3  3  3]\n",
      " [10  8  0  4  4  4  4]\n",
      " [ 6  4  0  2  2  2  2]\n",
      " [16 13  0  6  6  6  6]\n",
      " [ 5  4  0  2  2  2  2]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[23 19  0  9  9  9  9]\n",
      " [14 12  0  6  6  6  6]\n",
      " [29 23  0 12 12 12 12]\n",
      " [19 16  0  8  8  8  8]\n",
      " [ 4  3  0  2  2  2  2]\n",
      " [10  8  0  4  4  4  4]\n",
      " [10  8  0  4  4  4  4]\n",
      " [10  8  0  4  4  4  4]\n",
      " [14 12  0  6  6  6  6]\n",
      " [ 8  6  0  3  3  3  3]\n",
      " [24 19  0 10 10 10 10]\n",
      " [ 7  5  0  3  3  3  3]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[10  6  0  2  2  2  2]\n",
      " [ 4  3  0  1  1  1  1]\n",
      " [15 10  0  2  2  2  2]\n",
      " [ 7  5  0  1  1  1  1]\n",
      " [ 1  1  0  0  0  0  0]\n",
      " [ 2  1  0  0  0  0  0]\n",
      " [ 2  1  0  0  0  0  0]\n",
      " [ 2  2  0  0  0  0  0]\n",
      " [ 4  3  0  1  1  1  1]\n",
      " [ 2  1  0  0  0  0  0]\n",
      " [10  7  0  2  2  2  2]\n",
      " [ 2  1  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[19 12  0  3  3  3  3]\n",
      " [ 8  5  0  1  1  1  1]\n",
      " [29 19  0  5  5  5  5]\n",
      " [13  9  0  2  2  2  2]\n",
      " [ 1  1  0  0  0  0  0]\n",
      " [ 4  2  0  1  1  1  1]\n",
      " [ 4  3  0  1  1  1  1]\n",
      " [ 4  3  0  1  1  1  1]\n",
      " [ 8  5  0  1  1  1  1]\n",
      " [ 3  2  0  0  0  0  0]\n",
      " [20 13  0  3  3  3  3]\n",
      " [ 2  1  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[28 18  0  4  4  4  4]\n",
      " [11  7  0  2  2  2  2]\n",
      " [43 28  0  7  7  7  7]\n",
      " [20 13  0  3  3  3  3]\n",
      " [ 2  1  0  0  0  0  0]\n",
      " [ 5  3  0  1  1  1  1]\n",
      " [ 6  4  0  1  1  1  1]\n",
      " [ 6  4  0  1  1  1  1]\n",
      " [11  7  0  2  2  2  2]\n",
      " [ 4  2  0  1  1  1  1]\n",
      " [29 19  0  5  5  5  5]\n",
      " [ 3  2  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[ 8  2  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [27  7  0  0  0  0  0]\n",
      " [ 4  1  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 9  2  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[15  4  0  0  0  0  0]\n",
      " [ 2  1  0  0  0  0  0]\n",
      " [52 14  0  0  0  0  0]\n",
      " [ 6  2  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 2  1  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [17  4  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[[21  6  0  0  0  0  0]\n",
      " [ 3  1  0  0  0  0  0]\n",
      " [77 20  0  0  0  0  0]\n",
      " [ 8  2  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 3  1  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [25  6  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "mx_wndws=int(np.max(cls_wndws)+1)   # حداکثر تعداد پنجره ی موجود بین کلاس ها\n",
    "print('\\n max =', mx_wndws)\n",
    "aug_amnt_Ttl=np.empty((0,7), int) \n",
    "rslts=np.array([])\n",
    "X=1                               #داده افزایی تا چند برابر کلاس اکثریت\n",
    "for beta in range(1,4):\n",
    "    if beta==3:\n",
    "        beta=beta*2\n",
    "    rprt=np.array([])\n",
    "    for alpha in range(1,4):    #چند برابر کردن داده افزایی هر کلاس متناسب ضعیف بودن آن کلاس\n",
    "        scors0=np.array([64,78,55,70,94,85,84,85,78,88,63,90])         #Class Recalls without Augmentation\n",
    "        AgScr=1+alpha*((100-scors0)/(np.max(100-scors0)))**beta            #Class Specific\n",
    "\n",
    "        f_scr=np.array([83,88,87,83,85,85,85,85])                      #UnAg,Scl.2,Mag.05,Tm.2,Gs1,frqnc2,GAN,LSTMexpgdo\n",
    "        f_scr_difrnc=f_scr-f_scr[0]\n",
    "        for z in range (len(f_scr_difrnc)):\n",
    "            if f_scr_difrnc[z]<0:\n",
    "                f_scr_difrnc[z]=0\n",
    "        f_scr_difrnc=f_scr_difrnc**beta\n",
    "        f_scr_rtio=f_scr_difrnc/(sum(f_scr_difrnc))\n",
    "        aug_amnt=np.empty((0,len(f_scr_rtio)-1), int) \n",
    "\n",
    "        for i in range (1,cls_num+1):\n",
    "            aug_amnt=np.append(aug_amnt,[f_scr_rtio[1:]*(mx_wndws*AgScr[i-1]-cls_wndws[i-1])],axis=0)\n",
    "            #vlum_win=mx_wndws-cls_wndws[i-1]             #میزان داده افزایی در روش های عمیق (پنجره)\n",
    "        aug_amnt=np.int16(np.round(aug_amnt))\n",
    "        aug_amnt_Ttl=np.append(aug_amnt_Ttl,aug_amnt,axis=0)\n",
    "        #print(np.int16(100*f_scr_rtio))\n",
    "        #print(aug_amnt)\n",
    "        rprt=np.empty((0,3),float)\n",
    "        print(aug_amnt)\n",
    "        for repeat in range(1,rpt_cnn_clsfctn+1):\n",
    "            xtrain=np.empty((0,smpl_rte+1), float) \n",
    "            for i in range (1,cls_num+1):                                     #تعریف آرایه ی پنجره های کلاس ها\n",
    "                xtrain=np.append(xtrain,vars()['wndws'+str(i)],axis=0)\n",
    "                if aug_amnt[i-1,0]>0:\n",
    "                    methd=10\n",
    "                    sort=-3  #-5=Dis_sam_Cls=qlty1 #-4=var_Dis=qlty2 #-3=DisSm/DisOthr=qlty3  #-2=invrs_GDO_papr=qlty4   #-1=GDO_papr=qlty5\n",
    "                    dp_slct_dstrb=4            #1-sequencial 2-linear 3-beta 4-exponential 5-unfrm\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,0],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,0],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,1]>0:\n",
    "                    methd=20\n",
    "                    sort=-3\n",
    "                    dp_slct_dstrb=2\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,1],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,1],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,2]>0:\n",
    "                    methd=30\n",
    "                    sort=-3\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,2],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,2],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,3]>0:\n",
    "                    methd=40\n",
    "                    sort=-1\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,3],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,3],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,4]>0:\n",
    "                    methd=50\n",
    "                    sort=-3\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,4],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,4],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,5]>0:\n",
    "                    methd=60\n",
    "                    sort=-1\n",
    "                    dp_slct_dstrb=4\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,5],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,5],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                if aug_amnt[i-1,6]>0:\n",
    "                    methd=70\n",
    "                    sort=-1\n",
    "                    dp_slct_dstrb=2\n",
    "                    Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,6],dp_slct_dstrb,sort)\n",
    "                    Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,6],dp_slct_dstrb,sort)\n",
    "                    HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                    xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                #print('class ', i, 'train shape = ', np.shape(xtrain))\n",
    "\n",
    "            # Normalization train windows\n",
    "            mx_aug=np.max(xtrain[:,:-1])\n",
    "            mx=np.max(ecg[:,:-1])\n",
    "            mn_aug=np.min(xtrain[:,:-1])\n",
    "            mn=np.min(ecg[:,:-1])\n",
    "            xtrain[:,:-1]= 2*(xtrain[:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1\n",
    "\n",
    "\n",
    "            ###Test Windows:\n",
    "            wndws_test=np.empty((0,len(wndws1[0])), float)\n",
    "            i=0\n",
    "            windws=np.array([])\n",
    "            for cls in range (1,cls_num+1):                                 #ساخت پنجره های داده های آموزش اصلی\n",
    "                vars()['wndws_tst'+str(cls)]=np.empty((0,len(wndws1[0])), float)\n",
    "                vars()['wndws_tst'+str(cls)]=np.append(vars()['wndws_tst'+str(cls)],vars()['ecg_tst'+str(cls)],axis=0)   \n",
    "\n",
    "            # Normalization test windows\n",
    "            for i in range (1,cls_num+1):                \n",
    "                cls=i\n",
    "                #print('\\n cls', i, ' >> ')\n",
    "                #print('max magnitude class', i , ' = ' ,np.max(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "                #print('min magnitude class', i , ' = ' ,np.min(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "                vars()['wndws_tst'+str(i)][:,:-1]= 2*(vars()['wndws_tst'+str(i)][:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1\n",
    "                #print('after normalizing >>')\n",
    "                #print('max magnitude class', i , ' = ' ,np.max(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "                #print('min magnitude class', i , ' = ' ,np.min(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "            #print(\"each class and its windows =\")                    #تجمیع کلاس های تست\n",
    "            for cls in range (1,cls_num+1):                                # آرایه ی تعداد پنجره ی هر کلاس\n",
    "                wns=len(vars()['wndws_tst'+str(cls)])\n",
    "                wndws_test=np.append(wndws_test,vars()['wndws_tst'+str(cls)],axis=0)\n",
    "            Xtest=wndws_test[:,:-1]\n",
    "            ytest=np.int16(wndws_test[:,-1])\n",
    "\n",
    "            trainx=np.random.permutation(xtrain)\n",
    "            Xtrain=np.array(trainx[:,:-1])\n",
    "            ytrain=np.int16(trainx[:,-1])\n",
    "\n",
    "            X_train=np.array(Xtrain)\n",
    "            y_train=np.array(ytrain)\n",
    "            X_test=np.array(Xtest)\n",
    "            y_test=np.array(ytest)\n",
    "            X_valid=np.array(Xtrain)\n",
    "            y_valid=np.array(ytrain)\n",
    "            #print('X_train => ', X_train.shape)\n",
    "            #print('y_train => ', y_train.shape)\n",
    "            #print('X_test  => ', X_test.shape)\n",
    "            #print('y_test  => ', y_test.shape)\n",
    "            #print('X_valid  => ', X_valid.shape)\n",
    "            #print('y_valid  => ', y_valid.shape)\n",
    "\n",
    "            y_train_cat=to_categorical(y_train)\n",
    "            y_valid_cat=to_categorical(y_valid)\n",
    "            y_test_cat=to_categorical(y_test)\n",
    "            X_train = np.expand_dims(X_train, axis=2)\n",
    "            X_valid = np.expand_dims(X_valid, axis=2)\n",
    "            X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "            ####### NETWORK #######\n",
    "            accuracy=0\n",
    "            acc_crs=np.array([])\n",
    "            ##for i in range (10):\n",
    "            ##    if accuracy<0.2 :\n",
    "            verbose, epochs, batch_size = 0, 1000, btch\n",
    "            n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train_cat.shape[1]\n",
    "            steps_per_epoch = len(X_train)//batch_size\n",
    "            validation_steps = len(X_valid)//batch_size # if you have test data\n",
    "            model_crs = Sequential()\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "            #model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "            #model_crs.add(Dropout(0.5))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            BatchNormalization()\n",
    "            model_crs.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            '''model_crs.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            model_crs.add(Conv1D(filters=1024, kernel_size=3, activation='relu'))\n",
    "            model_crs.add(MaxPooling1D(pool_size=3))\n",
    "            '''\n",
    "            model_crs.add(Flatten())\n",
    "            #model_crs.add(Dropout(0.5))\n",
    "            model_crs.add(Dense(2000, activation='relu'))\n",
    "            model_crs.add(Dense(n_outputs, activation='softmax'))\n",
    "            model_crs.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            # fit network   #CategoricalCrossentropy #sparse_categorical_crossentropy #SparseCategoricalCrossentropy\n",
    "            earlystopping = callbacks.EarlyStopping(monitor =\"val_accuracy\", mode =\"max\", patience = 20, restore_best_weights = True)\n",
    "            model_crs.fit(X_train, y_train_cat, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data = (X_valid, y_valid_cat), callbacks =[earlystopping])\n",
    "            # evaluate model_crs\n",
    "            _, accuracy = model_crs.evaluate(X_valid, y_valid_cat, batch_size=batch_size, verbose=verbose)\n",
    "            predict_x=model_crs.predict(X_test)              # Function 1\n",
    "            y_pred_crs=maxindx(predict_x)                    # function from augment.py to remove 0 index predictions\n",
    "            rprt0=classification_report(y_test, y_pred_crs,output_dict=True)\n",
    "            rprt_row=np.array([])\n",
    "            rprt_row=np.append(rprt_row,rprt0['accuracy'])\n",
    "            rprt_row=np.append(rprt_row,rprt0['macro avg']['f1-score'])\n",
    "            rprt_row=np.append(rprt_row,rprt0['weighted avg']['f1-score'])\n",
    "            rprt=np.append(rprt,[rprt_row],axis=0)\n",
    "        #print('rprt=',rprt)\n",
    "        maxm=rprt[np.argmax(rprt[:,1])]\n",
    "        #print('maxm=',maxm)\n",
    "        avrg=np.mean(rprt,axis=0)\n",
    "        #print('avrg=',avrg)\n",
    "        rslts=np.append(rslts,['X '+str(X)+'  Beta '+str(beta)+'  alpha '+str(alpha) +'  average= '+str(np.int16(100*avrg))+'  max= '+str(np.int16(100*maxm))+'  var= '+str(np.int16(np.var(100*rprt,axis=0)))],axis=0)\n",
    "        #print('rslts=',rslts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  6,  0,  3,  3,  3,  3],\n",
       "       [ 5,  4,  0,  2,  2,  2,  2],\n",
       "       [10,  8,  0,  4,  4,  4,  4],\n",
       "       [ 7,  5,  0,  3,  3,  3,  3],\n",
       "       [ 2,  1,  0,  1,  1,  1,  1],\n",
       "       [ 3,  3,  0,  1,  1,  1,  1],\n",
       "       [ 4,  3,  0,  1,  1,  1,  1],\n",
       "       [ 4,  3,  0,  1,  1,  1,  1],\n",
       "       [ 5,  4,  0,  2,  2,  2,  2],\n",
       "       [ 3,  2,  0,  1,  1,  1,  1],\n",
       "       [ 8,  7,  0,  3,  3,  3,  3],\n",
       "       [ 3,  2,  0,  1,  1,  1,  1],\n",
       "       [16, 13,  0,  6,  6,  6,  6],\n",
       "       [10,  8,  0,  4,  4,  4,  4],\n",
       "       [19, 16,  0,  8,  8,  8,  8],\n",
       "       [13, 11,  0,  5,  5,  5,  5],\n",
       "       [ 3,  2,  0,  1,  1,  1,  1],\n",
       "       [ 7,  5,  0,  3,  3,  3,  3],\n",
       "       [ 7,  6,  0,  3,  3,  3,  3],\n",
       "       [ 7,  5,  0,  3,  3,  3,  3],\n",
       "       [10,  8,  0,  4,  4,  4,  4],\n",
       "       [ 6,  4,  0,  2,  2,  2,  2],\n",
       "       [16, 13,  0,  6,  6,  6,  6],\n",
       "       [ 5,  4,  0,  2,  2,  2,  2],\n",
       "       [23, 19,  0,  9,  9,  9,  9],\n",
       "       [14, 12,  0,  6,  6,  6,  6],\n",
       "       [29, 23,  0, 12, 12, 12, 12],\n",
       "       [19, 16,  0,  8,  8,  8,  8],\n",
       "       [ 4,  3,  0,  2,  2,  2,  2],\n",
       "       [10,  8,  0,  4,  4,  4,  4],\n",
       "       [10,  8,  0,  4,  4,  4,  4],\n",
       "       [10,  8,  0,  4,  4,  4,  4],\n",
       "       [14, 12,  0,  6,  6,  6,  6],\n",
       "       [ 8,  6,  0,  3,  3,  3,  3],\n",
       "       [24, 19,  0, 10, 10, 10, 10],\n",
       "       [ 7,  5,  0,  3,  3,  3,  3],\n",
       "       [10,  6,  0,  2,  2,  2,  2],\n",
       "       [ 4,  3,  0,  1,  1,  1,  1],\n",
       "       [15, 10,  0,  2,  2,  2,  2],\n",
       "       [ 7,  5,  0,  1,  1,  1,  1],\n",
       "       [ 1,  1,  0,  0,  0,  0,  0],\n",
       "       [ 2,  1,  0,  0,  0,  0,  0],\n",
       "       [ 2,  1,  0,  0,  0,  0,  0],\n",
       "       [ 2,  2,  0,  0,  0,  0,  0],\n",
       "       [ 4,  3,  0,  1,  1,  1,  1],\n",
       "       [ 2,  1,  0,  0,  0,  0,  0],\n",
       "       [10,  7,  0,  2,  2,  2,  2],\n",
       "       [ 2,  1,  0,  0,  0,  0,  0],\n",
       "       [19, 12,  0,  3,  3,  3,  3],\n",
       "       [ 8,  5,  0,  1,  1,  1,  1],\n",
       "       [29, 19,  0,  5,  5,  5,  5],\n",
       "       [13,  9,  0,  2,  2,  2,  2],\n",
       "       [ 1,  1,  0,  0,  0,  0,  0],\n",
       "       [ 4,  2,  0,  1,  1,  1,  1],\n",
       "       [ 4,  3,  0,  1,  1,  1,  1],\n",
       "       [ 4,  3,  0,  1,  1,  1,  1],\n",
       "       [ 8,  5,  0,  1,  1,  1,  1],\n",
       "       [ 3,  2,  0,  0,  0,  0,  0],\n",
       "       [20, 13,  0,  3,  3,  3,  3],\n",
       "       [ 2,  1,  0,  0,  0,  0,  0],\n",
       "       [28, 18,  0,  4,  4,  4,  4],\n",
       "       [11,  7,  0,  2,  2,  2,  2],\n",
       "       [43, 28,  0,  7,  7,  7,  7],\n",
       "       [20, 13,  0,  3,  3,  3,  3],\n",
       "       [ 2,  1,  0,  0,  0,  0,  0],\n",
       "       [ 5,  3,  0,  1,  1,  1,  1],\n",
       "       [ 6,  4,  0,  1,  1,  1,  1],\n",
       "       [ 6,  4,  0,  1,  1,  1,  1],\n",
       "       [11,  7,  0,  2,  2,  2,  2],\n",
       "       [ 4,  2,  0,  1,  1,  1,  1],\n",
       "       [29, 19,  0,  5,  5,  5,  5],\n",
       "       [ 3,  2,  0,  0,  0,  0,  0],\n",
       "       [ 8,  2,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0],\n",
       "       [27,  7,  0,  0,  0,  0,  0],\n",
       "       [ 4,  1,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0],\n",
       "       [15,  4,  0,  0,  0,  0,  0],\n",
       "       [ 2,  1,  0,  0,  0,  0,  0],\n",
       "       [52, 14,  0,  0,  0,  0,  0],\n",
       "       [ 6,  2,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  1,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0],\n",
       "       [17,  4,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0],\n",
       "       [21,  6,  0,  0,  0,  0,  0],\n",
       "       [ 3,  1,  0,  0,  0,  0,  0],\n",
       "       [77, 20,  0,  0,  0,  0,  0],\n",
       "       [ 8,  2,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3,  1,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0],\n",
       "       [25,  6,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_amnt_Ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Beta 1  alpha 1  average= [86 86 86]  max= [88 88 88]  var= [1 2 2]',\n",
       "       'Beta 1  alpha 2  average= [85 85 85]  max= [85 86 85]  var= [0 0 0]',\n",
       "       'Beta 1  alpha 3  average= [87 87 87]  max= [88 88 88]  var= [2 2 2]',\n",
       "       'Beta 2  alpha 1  average= [85 85 85]  max= [89 89 89]  var= [6 6 6]',\n",
       "       'Beta 2  alpha 2  average= [85 85 85]  max= [87 87 87]  var= [1 1 1]',\n",
       "       'Beta 2  alpha 3  average= [86 86 86]  max= [87 87 87]  var= [0 0 0]',\n",
       "       'Beta 6  alpha 1  average= [84 84 84]  max= [86 85 85]  var= [0 1 1]',\n",
       "       'Beta 6  alpha 2  average= [85 85 85]  max= [86 85 85]  var= [0 0 0]',\n",
       "       'Beta 6  alpha 3  average= [84 84 84]  max= [86 86 86]  var= [1 1 1]'],\n",
       "      dtype='<U67')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results4=rslts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " max = 32\n",
      "[[8 6 0 3 3 3 3]\n",
      " [5 4 0 2 2 2 2]\n",
      " [9 8 0 4 4 4 4]\n",
      " [6 5 0 3 3 3 3]\n",
      " [2 1 0 1 1 1 1]\n",
      " [3 2 0 1 1 1 1]\n",
      " [3 3 0 1 1 1 1]\n",
      " [3 3 0 1 1 1 1]\n",
      " [5 4 0 2 2 2 2]\n",
      " [3 2 0 1 1 1 1]\n",
      " [8 6 0 3 3 3 3]\n",
      " [2 2 0 1 1 1 1]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "rslts= X 1  alpha 1  Beta 1  average= [85 85 85]  max= [86 86 86]  var= [1 0 0]\n",
      "[[ 9  6  0  1  1  1  1]\n",
      " [ 4  2  0  1  1  1  1]\n",
      " [14  9  0  2  2  2  2]\n",
      " [ 6  4  0  1  1  1  1]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  1  0  0  0  0  0]\n",
      " [ 2  1  0  0  0  0  0]\n",
      " [ 2  1  0  0  0  0  0]\n",
      " [ 4  2  0  1  1  1  1]\n",
      " [ 1  1  0  0  0  0  0]\n",
      " [10  6  0  2  2  2  2]\n",
      " [ 1  1  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 1  alpha 1  Beta 2  average= [59 56 56]  max= [84 84 84]  var= [1277 1514 1512]\n",
      "[[ 7  2  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [25  7  0  0  0  0  0]\n",
      " [ 3  1  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 8  2  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 1  alpha 1  Beta 6  average= [82 82 82]  max= [85 84 84]  var= [2 3 3]\n",
      "[[15 12  0  6  6  6  6]\n",
      " [ 9  7  0  4  4  4  4]\n",
      " [19 15  0  7  7  7  7]\n",
      " [12 10  0  5  5  5  5]\n",
      " [ 3  2  0  1  1  1  1]\n",
      " [ 6  5  0  2  2  2  2]\n",
      " [ 6  5  0  3  3  3  3]\n",
      " [ 6  5  0  3  3  3  3]\n",
      " [ 9  7  0  4  4  4  4]\n",
      " [ 5  4  0  2  2  2  2]\n",
      " [15 12  0  6  6  6  6]\n",
      " [ 4  3  0  2  2  2  2]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 1  alpha 2  Beta 1  average= [85 85 85]  max= [85 85 85]  var= [0 0 0]\n",
      "[[18 11  0  3  3  3  3]\n",
      " [ 7  4  0  1  1  1  1]\n",
      " [28 18  0  4  4  4  4]\n",
      " [13  8  0  2  2  2  2]\n",
      " [ 1  1  0  0  0  0  0]\n",
      " [ 3  2  0  0  0  0  0]\n",
      " [ 3  2  0  1  1  1  1]\n",
      " [ 3  2  0  1  1  1  1]\n",
      " [ 7  4  0  1  1  1  1]\n",
      " [ 2  2  0  0  0  0  0]\n",
      " [19 12  0  3  3  3  3]\n",
      " [ 2  1  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 1  alpha 2  Beta 2  average= [87 87 87]  max= [87 87 87]  var= [0 0 0]\n",
      "[[13  4  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [49 13  0  0  0  0  0]\n",
      " [ 5  1  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [16  4  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 1  alpha 2  Beta 6  average= [84 84 84]  max= [85 85 85]  var= [0 0 0]\n",
      "[[22 18  0  9  9  9  9]\n",
      " [14 11  0  5  5  5  5]\n",
      " [28 22  0 11 11 11 11]\n",
      " [19 15  0  7  7  7  7]\n",
      " [ 4  3  0  2  2  2  2]\n",
      " [ 9  7  0  4  4  4  4]\n",
      " [10  8  0  4  4  4  4]\n",
      " [ 9  8  0  4  4  4  4]\n",
      " [14 11  0  5  5  5  5]\n",
      " [ 8  6  0  3  3  3  3]\n",
      " [23 18  0  9  9  9  9]\n",
      " [ 6  5  0  3  3  3  3]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 1  alpha 3  Beta 1  average= [87 87 86]  max= [88 88 88]  var= [1 1 1]\n",
      "[[27 17  0  4  4  4  4]\n",
      " [10  7  0  2  2  2  2]\n",
      " [41 26  0  7  7  7  7]\n",
      " [19 12  0  3  3  3  3]\n",
      " [ 1  1  0  0  0  0  0]\n",
      " [ 5  3  0  1  1  1  1]\n",
      " [ 5  3  0  1  1  1  1]\n",
      " [ 5  3  0  1  1  1  1]\n",
      " [10  7  0  2  2  2  2]\n",
      " [ 3  2  0  1  1  1  1]\n",
      " [28 18  0  4  4  4  4]\n",
      " [ 2  2  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 1  alpha 3  Beta 2  average= [84 84 84]  max= [85 86 86]  var= [2 2 2]\n",
      "[[20  5  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [74 19  0  0  0  0  0]\n",
      " [ 7  2  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [23  6  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 1  alpha 3  Beta 6  average= [84 84 84]  max= [85 85 85]  var= [0 0 0]\n",
      "[[24 19  0 10 10 10 10]\n",
      " [18 15  0  7  7  7  7]\n",
      " [28 22  0 11 11 11 11]\n",
      " [22 17  0  9  9  9  9]\n",
      " [12  9  0  5  5  5  5]\n",
      " [15 12  0  6  6  6  6]\n",
      " [16 12  0  6  6  6  6]\n",
      " [15 12  0  6  6  6  6]\n",
      " [18 15  0  7  7  7  7]\n",
      " [14 11  0  6  6  6  6]\n",
      " [24 20  0 10 10 10 10]\n",
      " [13 11  0  5  5  5  5]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 2  alpha 1  Beta 1  average= [86 86 86]  max= [87 87 87]  var= [0 0 0]\n",
      "[[31 20  0  5  5  5  5]\n",
      " [21 13  0  3  3  3  3]\n",
      " [41 26  0  7  7  7  7]\n",
      " [26 17  0  4  4  4  4]\n",
      " [15  9  0  2  2  2  2]\n",
      " [17 11  0  3  3  3  3]\n",
      " [17 11  0  3  3  3  3]\n",
      " [17 11  0  3  3  3  3]\n",
      " [21 13  0  3  3  3  3]\n",
      " [16 10  0  3  3  3  3]\n",
      " [32 21  0  5  5  5  5]\n",
      " [15 10  0  2  2  2  2]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 2  alpha 1  Beta 2  average= [88 88 88]  max= [89 89 89]  var= [0 0 0]\n",
      "[[38 10  0  0  0  0  0]\n",
      " [26  7  0  0  0  0  0]\n",
      " [74 19  0  0  0  0  0]\n",
      " [29  8  0  0  0  0  0]\n",
      " [25  7  0  0  0  0  0]\n",
      " [24  6  0  0  0  0  0]\n",
      " [24  6  0  0  0  0  0]\n",
      " [25  7  0  0  0  0  0]\n",
      " [26  7  0  0  0  0  0]\n",
      " [25  7  0  0  0  0  0]\n",
      " [40 10  0  0  0  0  0]\n",
      " [25  7  0  0  0  0  0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 2  alpha 1  Beta 6  average= [85 85 85]  max= [88 88 87]  var= [5 5 5]\n",
      "[[39 31  0 15 15 15 15]\n",
      " [27 22  0 11 11 11 11]\n",
      " [46 37  0 18 18 18 18]\n",
      " [34 27  0 13 13 13 13]\n",
      " [14 11  0  6  6  6  6]\n",
      " [21 17  0  9  9  9  9]\n",
      " [22 18  0  9  9  9  9]\n",
      " [22 17  0  9  9  9  9]\n",
      " [27 22  0 11 11 11 11]\n",
      " [19 15  0  8  8  8  8]\n",
      " [39 32  0 16 16 16 16]\n",
      " [18 14  0  7  7  7  7]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 2  alpha 2  Beta 1  average= [87 87 87]  max= [90 90 90]  var= [6 6 6]\n",
      "[[49 31  0  8  8  8  8]\n",
      " [27 17  0  4  4  4  4]\n",
      " [68 44  0 11 11 11 11]\n",
      " [38 24  0  6  6  6  6]\n",
      " [15 10  0  2  2  2  2]\n",
      " [20 13  0  3  3  3  3]\n",
      " [20 13  0  3  3  3  3]\n",
      " [20 13  0  3  3  3  3]\n",
      " [27 17  0  4  4  4  4]\n",
      " [18 11  0  3  3  3  3]\n",
      " [51 33  0  8  8  8  8]\n",
      " [17 11  0  3  3  3  3]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 2  alpha 2  Beta 2  average= [88 88 87]  max= [90 90 90]  var= [2 2 2]\n",
      "[[ 50  13   0   0   0   0   0]\n",
      " [ 26   7   0   0   0   0   0]\n",
      " [122  32   0   0   0   0   0]\n",
      " [ 34   9   0   0   0   0   0]\n",
      " [ 25   7   0   0   0   0   0]\n",
      " [ 24   6   0   0   0   0   0]\n",
      " [ 24   6   0   0   0   0   0]\n",
      " [ 25   7   0   0   0   0   0]\n",
      " [ 26   7   0   0   0   0   0]\n",
      " [ 25   7   0   0   0   0   0]\n",
      " [ 55  14   0   0   0   0   0]\n",
      " [ 25   7   0   0   0   0   0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 2  alpha 2  Beta 6  average= [87 87 87]  max= [88 87 87]  var= [0 0 0]\n",
      "[[53 43  0 21 21 21 21]\n",
      " [36 29  0 14 14 14 14]\n",
      " [64 51  0 26 26 26 26]\n",
      " [46 37  0 18 18 18 18]\n",
      " [17 13  0  7  7  7  7]\n",
      " [27 22  0 11 11 11 11]\n",
      " [29 23  0 11 11 11 11]\n",
      " [28 22  0 11 11 11 11]\n",
      " [36 29  0 14 14 14 14]\n",
      " [24 19  0 10 10 10 10]\n",
      " [54 44  0 22 22 22 22]\n",
      " [22 17  0  9  9  9  9]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 2  alpha 3  Beta 1  average= [87 87 86]  max= [88 88 88]  var= [1 1 1]\n",
      "[[66 42  0 11 11 11 11]\n",
      " [34 21  0  5  5  5  5]\n",
      " [96 61  0 15 15 15 15]\n",
      " [50 32  0  8  8  8  8]\n",
      " [15 10  0  2  2  2  2]\n",
      " [23 15  0  4  4  4  4]\n",
      " [24 15  0  4  4  4  4]\n",
      " [23 15  0  4  4  4  4]\n",
      " [34 21  0  5  5  5  5]\n",
      " [20 13  0  3  3  3  3]\n",
      " [69 44  0 11 11 11 11]\n",
      " [18 12  0  3  3  3  3]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 2  alpha 3  Beta 2  average= [88 88 88]  max= [89 89 89]  var= [0 0 0]\n",
      "[[ 63  17   0   0   0   0   0]\n",
      " [ 27   7   0   0   0   0   0]\n",
      " [171  45   0   1   1   1   1]\n",
      " [ 38  10   0   0   0   0   0]\n",
      " [ 25   7   0   0   0   0   0]\n",
      " [ 24   6   0   0   0   0   0]\n",
      " [ 25   6   0   0   0   0   0]\n",
      " [ 25   7   0   0   0   0   0]\n",
      " [ 27   7   0   0   0   0   0]\n",
      " [ 25   7   0   0   0   0   0]\n",
      " [ 70  18   0   0   0   0   0]\n",
      " [ 25   7   0   0   0   0   0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 2  alpha 3  Beta 6  average= [87 87 87]  max= [89 89 89]  var= [1 1 1]\n",
      "[[40 32  0 16 16 16 16]\n",
      " [32 26  0 13 13 13 13]\n",
      " [46 37  0 18 18 18 18]\n",
      " [37 29  0 15 15 15 15]\n",
      " [22 18  0  9  9  9  9]\n",
      " [27 22  0 11 11 11 11]\n",
      " [28 22  0 11 11 11 11]\n",
      " [28 22  0 11 11 11 11]\n",
      " [32 26  0 13 13 13 13]\n",
      " [26 21  0 10 10 10 10]\n",
      " [41 33  0 16 16 16 16]\n",
      " [25 20  0 10 10 10 10]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 3  alpha 1  Beta 1  average= [87 87 87]  max= [90 90 90]  var= [3 3 3]\n",
      "[[54 34  0  9  9  9  9]\n",
      " [37 24  0  6  6  6  6]\n",
      " [68 44  0 11 11 11 11]\n",
      " [46 29  0  7  7  7  7]\n",
      " [28 18  0  5  5  5  5]\n",
      " [32 20  0  5  5  5  5]\n",
      " [32 21  0  5  5  5  5]\n",
      " [32 21  0  5  5  5  5]\n",
      " [37 24  0  6  6  6  6]\n",
      " [31 20  0  5  5  5  5]\n",
      " [55 35  0  9  9  9  9]\n",
      " [30 19  0  5  5  5  5]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 3  alpha 1  Beta 2  average= [88 88 88]  max= [90 90 90]  var= [1 1 1]\n",
      "[[ 68  18   0   0   0   0   0]\n",
      " [ 50  13   0   0   0   0   0]\n",
      " [122  32   0   0   0   0   0]\n",
      " [ 56  15   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 50  13   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 72  19   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 3  alpha 1  Beta 6  average= [85 84 84]  max= [86 86 86]  var= [1 1 1]\n",
      "[[62 50  0 25 25 25 25]\n",
      " [45 36  0 18 18 18 18]\n",
      " [73 59  0 29 29 29 29]\n",
      " [55 44  0 22 22 22 22]\n",
      " [26 21  0 10 10 10 10]\n",
      " [36 29  0 15 15 15 15]\n",
      " [38 30  0 15 15 15 15]\n",
      " [37 29  0 15 15 15 15]\n",
      " [45 36  0 18 18 18 18]\n",
      " [33 26  0 13 13 13 13]\n",
      " [64 51  0 25 25 25 25]\n",
      " [31 25  0 12 12 12 12]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 3  alpha 2  Beta 1  average= [87 87 87]  max= [90 90 90]  var= [5 5 5]\n",
      "[[ 80  51   0  13  13  13  13]\n",
      " [ 47  30   0   8   8   8   8]\n",
      " [109  70   0  17  17  17  17]\n",
      " [ 64  41   0  10  10  10  10]\n",
      " [ 29  19   0   5   5   5   5]\n",
      " [ 36  23   0   6   6   6   6]\n",
      " [ 38  24   0   6   6   6   6]\n",
      " [ 37  23   0   6   6   6   6]\n",
      " [ 47  30   0   8   8   8   8]\n",
      " [ 33  21   0   5   5   5   5]\n",
      " [ 83  53   0  13  13  13  13]\n",
      " [ 32  20   0   5   5   5   5]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 3  alpha 2  Beta 2  average= [87 87 87]  max= [88 88 88]  var= [0 0 0]\n",
      "[[ 87  23   0   0   0   0   0]\n",
      " [ 51  13   0   0   0   0   0]\n",
      " [195  51   0   1   1   1   1]\n",
      " [ 62  16   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 51  13   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 94  25   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 3  alpha 2  Beta 6  average= [88 88 88]  max= [91 91 91]  var= [9 9 9]\n",
      "[[ 84  67   0  34  34  34  34]\n",
      " [ 59  47   0  23  23  23  23]\n",
      " [101  80   0  40  40  40  40]\n",
      " [ 73  59   0  29  29  29  29]\n",
      " [ 29  24   0  12  12  12  12]\n",
      " [ 46  36   0  18  18  18  18]\n",
      " [ 47  38   0  19  19  19  19]\n",
      " [ 46  37   0  18  18  18  18]\n",
      " [ 59  47   0  23  23  23  23]\n",
      " [ 40  32   0  16  16  16  16]\n",
      " [ 86  69   0  34  34  34  34]\n",
      " [ 37  29   0  15  15  15  15]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 3  alpha 3  Beta 1  average= [86 85 85]  max= [88 89 88]  var= [ 7 10 10]\n",
      "[[106  68   0  17  17  17  17]\n",
      " [ 57  36   0   9   9   9   9]\n",
      " [150  96   0  24  24  24  24]\n",
      " [ 82  52   0  13  13  13  13]\n",
      " [ 30  19   0   5   5   5   5]\n",
      " [ 41  26   0   7   7   7   7]\n",
      " [ 43  27   0   7   7   7   7]\n",
      " [ 41  26   0   7   7   7   7]\n",
      " [ 57  36   0   9   9   9   9]\n",
      " [ 36  23   0   6   6   6   6]\n",
      " [110  71   0  18  18  18  18]\n",
      " [ 34  22   0   5   5   5   5]]\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 3  alpha 3  Beta 2  average= [86 86 86]  max= [87 87 87]  var= [0 0 0]\n",
      "[[106  28   0   0   0   0   0]\n",
      " [ 52  14   0   0   0   0   0]\n",
      " [267  70   0   1   1   1   1]\n",
      " [ 68  18   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [ 50  13   0   0   0   0   0]\n",
      " [ 52  14   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]\n",
      " [117  31   0   0   0   0   0]\n",
      " [ 49  13   0   0   0   0   0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 3  alpha 3  Beta 6  average= [88 88 88]  max= [90 90 90]  var= [2 3 3]\n"
     ]
    }
   ],
   "source": [
    "mx_wndws=int(np.max(cls_wndws)+1)   # حداکثر تعداد پنجره ی موجود بین کلاس ها\n",
    "print('\\n max =', mx_wndws)\n",
    "rpt_cnn_clsfctn=3                 #تعداد اجرای شبکه عصبی برای میانگین گیری هر حالت \n",
    "aug_amnt_Ttl=np.empty((0,7), int) \n",
    "rslts=np.array([])\n",
    "for X in range(1,4):                               #داده افزایی تا چند برابر کلاس اکثریت\n",
    "    mx_wndws=int(np.max(cls_wndws))   # حداکثر تعداد پنجره ی موجود بین کلاس ها\n",
    "    mx_wndws=int(X*mx_wndws)          #\n",
    "    for alpha in range(1,4):\n",
    "        rprt=np.array([])\n",
    "        for beta in range(1,4):                        #چند برابر کردن داده افزایی هر کلاس متناسب ضعیف بودن آن کلاس\n",
    "            if beta==3:\n",
    "                beta=beta*2\n",
    "            scors0=np.array([64,78,55,70,94,85,84,85,78,88,63,90])         #Class Recalls without Augmentation\n",
    "            AgScr=1+alpha*((100-scors0)/(np.max(100-scors0)))**beta        #Class Specific\n",
    "\n",
    "            f_scr=np.array([83,88,87,83,85,85,85,85])                      #UnAg,Scl.2,Mag.05,Tm.2,Gs1,frqnc2,GAN,LSTMexpgdo\n",
    "            f_scr_difrnc=f_scr-f_scr[0]\n",
    "            for z in range (len(f_scr_difrnc)):\n",
    "                if f_scr_difrnc[z]<0:\n",
    "                    f_scr_difrnc[z]=0\n",
    "            f_scr_difrnc=f_scr_difrnc**beta\n",
    "            f_scr_rtio=f_scr_difrnc/(sum(f_scr_difrnc))\n",
    "            aug_amnt=np.empty((0,len(f_scr_rtio)-1), int) \n",
    "\n",
    "            for i in range (1,cls_num+1):\n",
    "                aug_amnt=np.append(aug_amnt,[f_scr_rtio[1:]*(mx_wndws*AgScr[i-1]-cls_wndws[i-1])],axis=0)\n",
    "                #vlum_win=mx_wndws-cls_wndws[i-1]                        #میزان داده افزایی در روش های عمیق (پنجره)\n",
    "            aug_amnt=np.int16(np.round(aug_amnt))\n",
    "            aug_amnt_Ttl=np.append(aug_amnt_Ttl,aug_amnt,axis=0)\n",
    "            #print(np.int16(100*f_scr_rtio))\n",
    "            #print(aug_amnt)\n",
    "            rprt=np.empty((0,3),float)\n",
    "            print(aug_amnt)\n",
    "            for repeat in range(1,rpt_cnn_clsfctn+1):\n",
    "                xtrain=np.empty((0,smpl_rte+1), float) \n",
    "                for i in range (1,cls_num+1):                            #تعریف آرایه ی پنجره های کلاس ها\n",
    "                    xtrain=np.append(xtrain,vars()['wndws'+str(i)],axis=0)\n",
    "                    if aug_amnt[i-1,0]>0:\n",
    "                        methd=10\n",
    "                        sort=-3  #-5=Dis_sam_Cls=qlty1 #-4=var_Dis=qlty2 #-3=DisSm/DisOthr=qlty3  #-2=invrs_GDO_papr=qlty4   #-1=GDO_papr=qlty5\n",
    "                        dp_slct_dstrb=4            #1-sequencial 2-linear 3-beta 4-exponential 5-unfrm\n",
    "                        Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,0],dp_slct_dstrb,sort)\n",
    "                        Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,0],dp_slct_dstrb,sort)\n",
    "                        HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                        xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                    if aug_amnt[i-1,1]>0:\n",
    "                        methd=20\n",
    "                        sort=-3\n",
    "                        dp_slct_dstrb=2\n",
    "                        Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,1],dp_slct_dstrb,sort)\n",
    "                        Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,1],dp_slct_dstrb,sort)\n",
    "                        HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                        xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                    if aug_amnt[i-1,2]>0:\n",
    "                        methd=30\n",
    "                        sort=-3\n",
    "                        dp_slct_dstrb=4\n",
    "                        Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,2],dp_slct_dstrb,sort)\n",
    "                        Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,2],dp_slct_dstrb,sort)\n",
    "                        HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                        xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                    if aug_amnt[i-1,3]>0:\n",
    "                        methd=40\n",
    "                        sort=-1\n",
    "                        dp_slct_dstrb=4\n",
    "                        Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,3],dp_slct_dstrb,sort)\n",
    "                        Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,3],dp_slct_dstrb,sort)\n",
    "                        HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                        xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                    if aug_amnt[i-1,4]>0:\n",
    "                        methd=50\n",
    "                        sort=-3\n",
    "                        dp_slct_dstrb=4\n",
    "                        Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,4],dp_slct_dstrb,sort)\n",
    "                        Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,4],dp_slct_dstrb,sort)\n",
    "                        HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                        xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                    if aug_amnt[i-1,5]>0:\n",
    "                        methd=60\n",
    "                        sort=-1\n",
    "                        dp_slct_dstrb=4\n",
    "                        Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,5],dp_slct_dstrb,sort)\n",
    "                        Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,5],dp_slct_dstrb,sort)\n",
    "                        HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                        xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                    if aug_amnt[i-1,6]>0:\n",
    "                        methd=70\n",
    "                        sort=-1\n",
    "                        dp_slct_dstrb=2\n",
    "                        Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,6],dp_slct_dstrb,sort)\n",
    "                        Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,6],dp_slct_dstrb,sort)\n",
    "                        HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                        xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                    #print('class ', i, 'train shape = ', np.shape(xtrain))\n",
    "\n",
    "                # Normalization train windows\n",
    "                mx_aug=np.max(xtrain[:,:-1])\n",
    "                mx=np.max(ecg[:,:-1])\n",
    "                mn_aug=np.min(xtrain[:,:-1])\n",
    "                mn=np.min(ecg[:,:-1])\n",
    "                xtrain[:,:-1]= 2*(xtrain[:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1\n",
    "\n",
    "\n",
    "                ###Test Windows:\n",
    "                wndws_test=np.empty((0,len(wndws1[0])), float)\n",
    "                i=0\n",
    "                windws=np.array([])\n",
    "                for cls in range (1,cls_num+1):                                 #ساخت پنجره های داده های آموزش اصلی\n",
    "                    vars()['wndws_tst'+str(cls)]=np.empty((0,len(wndws1[0])), float)\n",
    "                    vars()['wndws_tst'+str(cls)]=np.append(vars()['wndws_tst'+str(cls)],vars()['ecg_tst'+str(cls)],axis=0)   \n",
    "\n",
    "                # Normalization test windows\n",
    "                for i in range (1,cls_num+1):                \n",
    "                    cls=i\n",
    "                    #print('\\n cls', i, ' >> ')\n",
    "                    #print('max magnitude class', i , ' = ' ,np.max(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "                    #print('min magnitude class', i , ' = ' ,np.min(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "                    vars()['wndws_tst'+str(i)][:,:-1]= 2*(vars()['wndws_tst'+str(i)][:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1\n",
    "                    #print('after normalizing >>')\n",
    "                    #print('max magnitude class', i , ' = ' ,np.max(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "                    #print('min magnitude class', i , ' = ' ,np.min(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "                #print(\"each class and its windows =\")                    #تجمیع کلاس های تست\n",
    "                for cls in range (1,cls_num+1):                                # آرایه ی تعداد پنجره ی هر کلاس\n",
    "                    wns=len(vars()['wndws_tst'+str(cls)])\n",
    "                    wndws_test=np.append(wndws_test,vars()['wndws_tst'+str(cls)],axis=0)\n",
    "                Xtest=wndws_test[:,:-1]\n",
    "                ytest=np.int16(wndws_test[:,-1])\n",
    "\n",
    "                trainx=np.random.permutation(xtrain)\n",
    "                Xtrain=np.array(trainx[:,:-1])\n",
    "                ytrain=np.int16(trainx[:,-1])\n",
    "\n",
    "                X_train=np.array(Xtrain)\n",
    "                y_train=np.array(ytrain)\n",
    "                X_test=np.array(Xtest)\n",
    "                y_test=np.array(ytest)\n",
    "                X_valid=np.array(Xtrain)\n",
    "                y_valid=np.array(ytrain)\n",
    "                #print('X_train => ', X_train.shape)\n",
    "                #print('y_train => ', y_train.shape)\n",
    "                #print('X_test  => ', X_test.shape)\n",
    "                #print('y_test  => ', y_test.shape)\n",
    "                #print('X_valid  => ', X_valid.shape)\n",
    "                #print('y_valid  => ', y_valid.shape)\n",
    "\n",
    "                y_train_cat=to_categorical(y_train)\n",
    "                y_valid_cat=to_categorical(y_valid)\n",
    "                y_test_cat=to_categorical(y_test)\n",
    "                X_train = np.expand_dims(X_train, axis=2)\n",
    "                X_valid = np.expand_dims(X_valid, axis=2)\n",
    "                X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "                ####### NETWORK #######\n",
    "                accuracy=0\n",
    "                acc_crs=np.array([])\n",
    "                ##for i in range (10):\n",
    "                ##    if accuracy<0.2 :\n",
    "                verbose, epochs, batch_size = 0, 1000, btch\n",
    "                n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train_cat.shape[1]\n",
    "                steps_per_epoch = len(X_train)//batch_size\n",
    "                validation_steps = len(X_valid)//batch_size # if you have test data\n",
    "                model_crs = Sequential()\n",
    "                BatchNormalization()\n",
    "                model_crs.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "                #model_crs.add(MaxPooling1D(pool_size=3))\n",
    "                BatchNormalization()\n",
    "                model_crs.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "                #model_crs.add(Dropout(0.5))\n",
    "                model_crs.add(MaxPooling1D(pool_size=3))\n",
    "                BatchNormalization()\n",
    "                model_crs.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "                model_crs.add(MaxPooling1D(pool_size=3))\n",
    "                BatchNormalization()\n",
    "                model_crs.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "                model_crs.add(MaxPooling1D(pool_size=3))\n",
    "                BatchNormalization()\n",
    "                model_crs.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "                model_crs.add(MaxPooling1D(pool_size=3))\n",
    "                '''model_crs.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "                model_crs.add(MaxPooling1D(pool_size=3))\n",
    "                model_crs.add(Conv1D(filters=1024, kernel_size=3, activation='relu'))\n",
    "                model_crs.add(MaxPooling1D(pool_size=3))\n",
    "                '''\n",
    "                model_crs.add(Flatten())\n",
    "                #model_crs.add(Dropout(0.5))\n",
    "                model_crs.add(Dense(2000, activation='relu'))\n",
    "                model_crs.add(Dense(n_outputs, activation='softmax'))\n",
    "                model_crs.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                # fit network   #CategoricalCrossentropy #sparse_categorical_crossentropy #SparseCategoricalCrossentropy\n",
    "                earlystopping = callbacks.EarlyStopping(monitor =\"val_accuracy\", mode =\"max\", patience = 20, restore_best_weights = True)\n",
    "                model_crs.fit(X_train, y_train_cat, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data = (X_valid, y_valid_cat), callbacks =[earlystopping])\n",
    "                # evaluate model_crs\n",
    "                _, accuracy = model_crs.evaluate(X_valid, y_valid_cat, batch_size=batch_size, verbose=verbose)\n",
    "                predict_x=model_crs.predict(X_test)              # Function 1\n",
    "                y_pred_crs=maxindx(predict_x)                    # function from augment.py to remove 0 index predictions\n",
    "                rprt0=classification_report(y_test, y_pred_crs,output_dict=True)\n",
    "                rprt_row=np.array([])\n",
    "                rprt_row=np.append(rprt_row,rprt0['accuracy'])\n",
    "                rprt_row=np.append(rprt_row,rprt0['macro avg']['f1-score'])\n",
    "                rprt_row=np.append(rprt_row,rprt0['weighted avg']['f1-score'])\n",
    "                rprt=np.append(rprt,[rprt_row],axis=0)\n",
    "            #print('rprt=',rprt)\n",
    "            maxm=rprt[np.argmax(rprt[:,1])]\n",
    "            #print('maxm=',maxm)\n",
    "            avrg=np.mean(rprt,axis=0)\n",
    "            #print('avrg=',avrg)\n",
    "            rslts=np.append(rslts,['X '+str(X)+'  alpha '+str(alpha) +'  Beta '+str(beta)+'  average= '+str(np.int16(100*avrg))+'  max= '+str(np.int16(100*maxm))+'  var= '+str(np.int16(np.var(100*rprt,axis=0)))],axis=0)\n",
    "            print('rslts=',rslts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['X 1  alpha 1  Beta 1  average= [85 85 85]  max= [86 86 86]  var= [1 0 0]',\n",
       "       'X 1  alpha 1  Beta 2  average= [59 56 56]  max= [84 84 84]  var= [1277 1514 1512]',\n",
       "       'X 1  alpha 1  Beta 6  average= [82 82 82]  max= [85 84 84]  var= [2 3 3]',\n",
       "       'X 1  alpha 2  Beta 1  average= [85 85 85]  max= [85 85 85]  var= [0 0 0]',\n",
       "       'X 1  alpha 2  Beta 2  average= [87 87 87]  max= [87 87 87]  var= [0 0 0]',\n",
       "       'X 1  alpha 2  Beta 6  average= [84 84 84]  max= [85 85 85]  var= [0 0 0]',\n",
       "       'X 1  alpha 3  Beta 1  average= [87 87 86]  max= [88 88 88]  var= [1 1 1]',\n",
       "       'X 1  alpha 3  Beta 2  average= [84 84 84]  max= [85 86 86]  var= [2 2 2]',\n",
       "       'X 1  alpha 3  Beta 6  average= [84 84 84]  max= [85 85 85]  var= [0 0 0]',\n",
       "       'X 2  alpha 1  Beta 1  average= [86 86 86]  max= [87 87 87]  var= [0 0 0]',\n",
       "       'X 2  alpha 1  Beta 2  average= [88 88 88]  max= [89 89 89]  var= [0 0 0]',\n",
       "       'X 2  alpha 1  Beta 6  average= [85 85 85]  max= [88 88 87]  var= [5 5 5]',\n",
       "       'X 2  alpha 2  Beta 1  average= [87 87 87]  max= [90 90 90]  var= [6 6 6]',\n",
       "       'X 2  alpha 2  Beta 2  average= [88 88 87]  max= [90 90 90]  var= [2 2 2]',\n",
       "       'X 2  alpha 2  Beta 6  average= [87 87 87]  max= [88 87 87]  var= [0 0 0]',\n",
       "       'X 2  alpha 3  Beta 1  average= [87 87 86]  max= [88 88 88]  var= [1 1 1]',\n",
       "       'X 2  alpha 3  Beta 2  average= [88 88 88]  max= [89 89 89]  var= [0 0 0]',\n",
       "       'X 2  alpha 3  Beta 6  average= [87 87 87]  max= [89 89 89]  var= [1 1 1]',\n",
       "       'X 3  alpha 1  Beta 1  average= [87 87 87]  max= [90 90 90]  var= [3 3 3]',\n",
       "       'X 3  alpha 1  Beta 2  average= [88 88 88]  max= [90 90 90]  var= [1 1 1]',\n",
       "       'X 3  alpha 1  Beta 6  average= [85 84 84]  max= [86 86 86]  var= [1 1 1]',\n",
       "       'X 3  alpha 2  Beta 1  average= [87 87 87]  max= [90 90 90]  var= [5 5 5]',\n",
       "       'X 3  alpha 2  Beta 2  average= [87 87 87]  max= [88 88 88]  var= [0 0 0]',\n",
       "       'X 3  alpha 2  Beta 6  average= [88 88 88]  max= [91 91 91]  var= [9 9 9]',\n",
       "       'X 3  alpha 3  Beta 1  average= [86 85 85]  max= [88 89 88]  var= [ 7 10 10]',\n",
       "       'X 3  alpha 3  Beta 2  average= [86 86 86]  max= [87 87 87]  var= [0 0 0]',\n",
       "       'X 3  alpha 3  Beta 6  average= [88 88 88]  max= [90 90 90]  var= [2 3 3]'],\n",
       "      dtype='<U81')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " max = 32\n",
      "[[57 45  0 23 23 23 23]\n",
      " [45 36  0 18 18 18 18]\n",
      " [64 51  0 26 26 26 26]\n",
      " [52 42  0 21 21 21 21]\n",
      " [33 26  0 13 13 13 13]\n",
      " [40 32  0 16 16 16 16]\n",
      " [40 32  0 16 16 16 16]\n",
      " [40 32  0 16 16 16 16]\n",
      " [45 36  0 18 18 18 18]\n",
      " [37 30  0 15 15 15 15]\n",
      " [58 46  0 23 23 23 23]\n",
      " [36 29  0 14 14 14 14]]\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 4  alpha 1  Beta 1  average= [86 86 86]  max= [87 87 87]  var= [0 0 0]\n",
      "[[76 49  0 12 12 12 12]\n",
      " [54 35  0  9  9  9  9]\n",
      " [96 61  0 15 15 15 15]\n",
      " [65 42  0 10 10 10 10]\n",
      " [42 27  0  7  7  7  7]\n",
      " [47 30  0  7  7  7  7]\n",
      " [48 31  0  8  8  8  8]\n",
      " [47 30  0  8  8  8  8]\n",
      " [54 35  0  9  9  9  9]\n",
      " [45 29  0  7  7  7  7]\n",
      " [78 50  0 12 12 12 12]\n",
      " [44 28  0  7  7  7  7]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 4  alpha 1  Beta 2  average= [88 87 87]  max= [88 88 88]  var= [0 0 0]\n",
      "[[ 99  26   0   0   0   0   0]\n",
      " [ 75  20   0   0   0   0   0]\n",
      " [171  45   0   1   1   1   1]\n",
      " [ 82  22   0   0   0   0   0]\n",
      " [ 74  19   0   0   0   0   0]\n",
      " [ 73  19   0   0   0   0   0]\n",
      " [ 73  19   0   0   0   0   0]\n",
      " [ 74  19   0   0   0   0   0]\n",
      " [ 75  20   0   0   0   0   0]\n",
      " [ 74  19   0   0   0   0   0]\n",
      " [103  27   0   0   0   0   0]\n",
      " [ 74  19   0   0   0   0   0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 4  alpha 1  Beta 6  average= [88 88 88]  max= [90 89 89]  var= [4 5 5]\n",
      "[[ 86  69   0  34  34  34  34]\n",
      " [ 63  51   0  25  25  25  25]\n",
      " [101  80   0  40  40  40  40]\n",
      " [ 76  61   0  31  31  31  31]\n",
      " [ 37  30   0  15  15  15  15]\n",
      " [ 52  41   0  21  21  21  21]\n",
      " [ 53  43   0  21  21  21  21]\n",
      " [ 52  42   0  21  21  21  21]\n",
      " [ 63  51   0  25  25  25  25]\n",
      " [ 47  38   0  19  19  19  19]\n",
      " [ 88  70   0  35  35  35  35]\n",
      " [ 44  35   0  18  18  18  18]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 4  alpha 2  Beta 1  average= [87 87 87]  max= [88 88 88]  var= [1 1 1]\n",
      "[[111  71   0  18  18  18  18]\n",
      " [ 67  43   0  11  11  11  11]\n",
      " [150  96   0  24  24  24  24]\n",
      " [ 90  57   0  14  14  14  14]\n",
      " [ 43  28   0   7   7   7   7]\n",
      " [ 53  34   0   8   8   8   8]\n",
      " [ 55  35   0   9   9   9   9]\n",
      " [ 53  34   0   9   9   9   9]\n",
      " [ 67  43   0  11  11  11  11]\n",
      " [ 49  31   0   8   8   8   8]\n",
      " [115  73   0  18  18  18  18]\n",
      " [ 47  30   0   7   7   7   7]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 4  alpha 2  Beta 2  average= [90 90 90]  max= [91 91 91]  var= [0 0 0]\n",
      "[[124  33   0   1   1   1   1]\n",
      " [ 76  20   0   0   0   0   0]\n",
      " [267  70   0   1   1   1   1]\n",
      " [ 91  24   0   0   0   0   0]\n",
      " [ 74  19   0   0   0   0   0]\n",
      " [ 73  19   0   0   0   0   0]\n",
      " [ 73  19   0   0   0   0   0]\n",
      " [ 74  19   0   0   0   0   0]\n",
      " [ 76  20   0   0   0   0   0]\n",
      " [ 74  19   0   0   0   0   0]\n",
      " [133  35   0   1   1   1   1]\n",
      " [ 74  19   0   0   0   0   0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 4  alpha 2  Beta 6  average= [87 87 87]  max= [88 88 88]  var= [1 0 0]\n",
      "[[115  92   0  46  46  46  46]\n",
      " [ 81  65   0  32  32  32  32]\n",
      " [137 110   0  55  55  55  55]\n",
      " [101  80   0  40  40  40  40]\n",
      " [ 42  34   0  17  17  17  17]\n",
      " [ 64  51   0  26  26  26  26]\n",
      " [ 66  53   0  27  27  27  27]\n",
      " [ 64  51   0  26  26  26  26]\n",
      " [ 81  65   0  32  32  32  32]\n",
      " [ 57  45   0  23  23  23  23]\n",
      " [118  94   0  47  47  47  47]\n",
      " [ 52  42   0  21  21  21  21]]\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 4  alpha 3  Beta 1  average= [87 87 87]  max= [88 88 88]  var= [1 1 1]\n",
      "[[146  93   0  23  23  23  23]\n",
      " [ 80  51   0  13  13  13  13]\n",
      " [204 131   0  33  33  33  33]\n",
      " [114  73   0  18  18  18  18]\n",
      " [ 44  28   0   7   7   7   7]\n",
      " [ 59  38   0   9   9   9   9]\n",
      " [ 61  39   0  10  10  10  10]\n",
      " [ 59  38   0   9   9   9   9]\n",
      " [ 80  51   0  13  13  13  13]\n",
      " [ 53  34   0   8   8   8   8]\n",
      " [152  97   0  24  24  24  24]\n",
      " [ 49  32   0   8   8   8   8]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 4  alpha 3  Beta 2  average= [89 89 89]  max= [89 89 89]  var= [0 0 0]\n",
      "[[150  39   0   1   1   1   1]\n",
      " [ 77  20   0   0   0   0   0]\n",
      " [364  96   0   1   1   1   1]\n",
      " [ 99  26   0   0   0   0   0]\n",
      " [ 74  19   0   0   0   0   0]\n",
      " [ 73  19   0   0   0   0   0]\n",
      " [ 73  19   0   0   0   0   0]\n",
      " [ 74  19   0   0   0   0   0]\n",
      " [ 77  20   0   0   0   0   0]\n",
      " [ 74  19   0   0   0   0   0]\n",
      " [163  43   0   1   1   1   1]\n",
      " [ 74  19   0   0   0   0   0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 4  alpha 3  Beta 6  average= [86 86 86]  max= [90 89 89]  var= [5 6 6]\n",
      "[[73 59  0 29 29 29 29]\n",
      " [59 47  0 24 24 24 24]\n",
      " [82 66  0 33 33 33 33]\n",
      " [67 54  0 27 27 27 27]\n",
      " [43 34  0 17 17 17 17]\n",
      " [52 41  0 21 21 21 21]\n",
      " [53 42  0 21 21 21 21]\n",
      " [52 42  0 21 21 21 21]\n",
      " [59 47  0 24 24 24 24]\n",
      " [49 39  0 20 20 20 20]\n",
      " [74 59  0 30 30 30 30]\n",
      " [47 38  0 19 19 19 19]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 5  alpha 1  Beta 1  average= [87 87 87]  max= [89 89 89]  var= [7 7 7]\n",
      "[[ 98  63   0  16  16  16  16]\n",
      " [ 71  45   0  11  11  11  11]\n",
      " [123  79   0  20  20  20  20]\n",
      " [ 85  54   0  14  14  14  14]\n",
      " [ 56  36   0   9   9   9   9]\n",
      " [ 62  40   0  10  10  10  10]\n",
      " [ 63  40   0  10  10  10  10]\n",
      " [ 62  40   0  10  10  10  10]\n",
      " [ 71  45   0  11  11  11  11]\n",
      " [ 60  38   0  10  10  10  10]\n",
      " [101  65   0  16  16  16  16]\n",
      " [ 58  37   0   9   9   9   9]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 5  alpha 1  Beta 2  average= [87 86 86]  max= [89 89 89]  var= [7 8 8]\n",
      "[[130  34   0   1   1   1   1]\n",
      " [ 99  26   0   0   0   0   0]\n",
      " [219  57   0   1   1   1   1]\n",
      " [108  28   0   0   0   0   0]\n",
      " [ 98  26   0   0   0   0   0]\n",
      " [ 97  25   0   0   0   0   0]\n",
      " [ 97  25   0   0   0   0   0]\n",
      " [ 98  26   0   0   0   0   0]\n",
      " [ 99  26   0   0   0   0   0]\n",
      " [ 98  26   0   0   0   0   0]\n",
      " [135  35   0   1   1   1   1]\n",
      " [ 98  26   0   0   0   0   0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 5  alpha 1  Beta 6  average= [87 87 86]  max= [88 88 88]  var= [1 1 1]\n",
      "[[110  88   0  44  44  44  44]\n",
      " [ 81  65   0  33  33  33  33]\n",
      " [128 102   0  51  51  51  51]\n",
      " [ 98  78   0  39  39  39  39]\n",
      " [ 49  39   0  20  20  20  20]\n",
      " [ 67  53   0  27  27  27  27]\n",
      " [ 69  55   0  28  28  28  28]\n",
      " [ 67  54   0  27  27  27  27]\n",
      " [ 81  65   0  33  33  33  33]\n",
      " [ 61  49   0  24  24  24  24]\n",
      " [112  89   0  45  45  45  45]\n",
      " [ 57  46   0  23  23  23  23]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 5  alpha 2  Beta 1  average= [87 87 87]  max= [88 88 88]  var= [1 1 1]\n",
      "[[142  91   0  23  23  23  23]\n",
      " [ 87  56   0  14  14  14  14]\n",
      " [191 122   0  31  31  31  31]\n",
      " [115  74   0  18  18  18  18]\n",
      " [ 57  37   0   9   9   9   9]\n",
      " [ 69  44   0  11  11  11  11]\n",
      " [ 72  46   0  11  11  11  11]\n",
      " [ 70  45   0  11  11  11  11]\n",
      " [ 87  56   0  14  14  14  14]\n",
      " [ 64  41   0  10  10  10  10]\n",
      " [147  94   0  23  23  23  23]\n",
      " [ 62  39   0  10  10  10  10]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 5  alpha 2  Beta 2  average= [87 87 87]  max= [87 87 87]  var= [0 0 0]\n",
      "[[161  42   0   1   1   1   1]\n",
      " [101  26   0   0   0   0   0]\n",
      " [340  89   0   1   1   1   1]\n",
      " [119  31   0   0   0   0   0]\n",
      " [ 98  26   0   0   0   0   0]\n",
      " [ 97  26   0   0   0   0   0]\n",
      " [ 97  26   0   0   0   0   0]\n",
      " [ 98  26   0   0   0   0   0]\n",
      " [101  26   0   0   0   0   0]\n",
      " [ 98  26   0   0   0   0   0]\n",
      " [173  45   0   1   1   1   1]\n",
      " [ 98  26   0   0   0   0   0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 5  alpha 2  Beta 6  average= [87 86 86]  max= [89 88 88]  var= [1 2 2]\n",
      "[[146 117   0  58  58  58  58]\n",
      " [104  83   0  41  41  41  41]\n",
      " [174 139   0  69  69  69  69]\n",
      " [128 102   0  51  51  51  51]\n",
      " [ 55  44   0  22  22  22  22]\n",
      " [ 82  66   0  33  33  33  33]\n",
      " [ 85  68   0  34  34  34  34]\n",
      " [ 82  66   0  33  33  33  33]\n",
      " [104  83   0  41  41  41  41]\n",
      " [ 73  59   0  29  29  29  29]\n",
      " [149 119   0  60  60  60  60]\n",
      " [ 67  54   0  27  27  27  27]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 5  alpha 3  Beta 1  average= [87 87 87]  max= [88 88 88]  var= [0 0 0]\n",
      "[[185 119   0  30  30  30  30]\n",
      " [104  66   0  17  17  17  17]\n",
      " [259 166   0  41  41  41  41]\n",
      " [145  93   0  23  23  23  23]\n",
      " [ 58  37   0   9   9   9   9]\n",
      " [ 77  49   0  12  12  12  12]\n",
      " [ 80  51   0  13  13  13  13]\n",
      " [ 77  50   0  12  12  12  12]\n",
      " [104  66   0  17  17  17  17]\n",
      " [ 69  44   0  11  11  11  11]\n",
      " [193 123   0  31  31  31  31]\n",
      " [ 65  42   0  10  10  10  10]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 5  alpha 3  Beta 2  average= [89 89 89]  max= [89 89 89]  var= [0 0 0]\n",
      "[[193  51   0   1   1   1   1]\n",
      " [103  27   0   0   0   0   0]\n",
      " [461 121   0   2   2   2   2]\n",
      " [130  34   0   1   1   1   1]\n",
      " [ 98  26   0   0   0   0   0]\n",
      " [ 97  26   0   0   0   0   0]\n",
      " [ 98  26   0   0   0   0   0]\n",
      " [ 98  26   0   0   0   0   0]\n",
      " [103  27   0   0   0   0   0]\n",
      " [ 98  26   0   0   0   0   0]\n",
      " [210  55   0   1   1   1   1]\n",
      " [ 98  26   0   0   0   0   0]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "rslts= X 5  alpha 3  Beta 6  average= [86 86 86]  max= [89 89 89]  var= [2 3 3]\n"
     ]
    }
   ],
   "source": [
    "mx_wndws=int(np.max(cls_wndws)+1)   # حداکثر تعداد پنجره ی موجود بین کلاس ها\n",
    "print('\\n max =', mx_wndws)\n",
    "rpt_cnn_clsfctn=3                 #تعداد اجرای شبکه عصبی برای میانگین گیری هر حالت \n",
    "aug_amnt_Ttl=np.empty((0,7), int) \n",
    "rslts=np.array([])\n",
    "for X in range(4,6):                               #داده افزایی تا چند برابر کلاس اکثریت\n",
    "    mx_wndws=int(np.max(cls_wndws))   # حداکثر تعداد پنجره ی موجود بین کلاس ها\n",
    "    mx_wndws=int(X*mx_wndws)          #\n",
    "    for alpha in range(1,4):\n",
    "        rprt=np.array([])\n",
    "        for beta in range(1,4):                        #چند برابر کردن داده افزایی هر کلاس متناسب ضعیف بودن آن کلاس\n",
    "            if beta==3:\n",
    "                beta=beta*2\n",
    "            scors0=np.array([64,78,55,70,94,85,84,85,78,88,63,90])         #Class Recalls without Augmentation\n",
    "            AgScr=1+alpha*((100-scors0)/(np.max(100-scors0)))**beta        #Class Specific\n",
    "\n",
    "            f_scr=np.array([83,88,87,83,85,85,85,85])                      #UnAg,Scl.2,Mag.05,Tm.2,Gs1,frqnc2,GAN,LSTMexpgdo\n",
    "            f_scr_difrnc=f_scr-f_scr[0]\n",
    "            for z in range (len(f_scr_difrnc)):\n",
    "                if f_scr_difrnc[z]<0:\n",
    "                    f_scr_difrnc[z]=0\n",
    "            f_scr_difrnc=f_scr_difrnc**beta\n",
    "            f_scr_rtio=f_scr_difrnc/(sum(f_scr_difrnc))\n",
    "            aug_amnt=np.empty((0,len(f_scr_rtio)-1), int) \n",
    "\n",
    "            for i in range (1,cls_num+1):\n",
    "                aug_amnt=np.append(aug_amnt,[f_scr_rtio[1:]*(mx_wndws*AgScr[i-1]-cls_wndws[i-1])],axis=0)\n",
    "                #vlum_win=mx_wndws-cls_wndws[i-1]                        #میزان داده افزایی در روش های عمیق (پنجره)\n",
    "            aug_amnt=np.int16(np.round(aug_amnt))\n",
    "            aug_amnt_Ttl=np.append(aug_amnt_Ttl,aug_amnt,axis=0)\n",
    "            #print(np.int16(100*f_scr_rtio))\n",
    "            #print(aug_amnt)\n",
    "            rprt=np.empty((0,3),float)\n",
    "            print(aug_amnt)\n",
    "            for repeat in range(1,rpt_cnn_clsfctn+1):\n",
    "                xtrain=np.empty((0,smpl_rte+1), float) \n",
    "                for i in range (1,cls_num+1):                            #تعریف آرایه ی پنجره های کلاس ها\n",
    "                    xtrain=np.append(xtrain,vars()['wndws'+str(i)],axis=0)\n",
    "                    if aug_amnt[i-1,0]>0:\n",
    "                        methd=10\n",
    "                        sort=-3  #-5=Dis_sam_Cls=qlty1 #-4=var_Dis=qlty2 #-3=DisSm/DisOthr=qlty3  #-2=invrs_GDO_papr=qlty4   #-1=GDO_papr=qlty5\n",
    "                        dp_slct_dstrb=4            #1-sequencial 2-linear 3-beta 4-exponential 5-unfrm\n",
    "                        Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,0],dp_slct_dstrb,sort)\n",
    "                        Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,0],dp_slct_dstrb,sort)\n",
    "                        HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                        xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                    if aug_amnt[i-1,1]>0:\n",
    "                        methd=20\n",
    "                        sort=-3\n",
    "                        dp_slct_dstrb=2\n",
    "                        Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,1],dp_slct_dstrb,sort)\n",
    "                        Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,1],dp_slct_dstrb,sort)\n",
    "                        HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                        xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                    if aug_amnt[i-1,2]>0:\n",
    "                        methd=30\n",
    "                        sort=-3\n",
    "                        dp_slct_dstrb=4\n",
    "                        Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,2],dp_slct_dstrb,sort)\n",
    "                        Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,2],dp_slct_dstrb,sort)\n",
    "                        HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                        xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                    if aug_amnt[i-1,3]>0:\n",
    "                        methd=40\n",
    "                        sort=-1\n",
    "                        dp_slct_dstrb=4\n",
    "                        Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,3],dp_slct_dstrb,sort)\n",
    "                        Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,3],dp_slct_dstrb,sort)\n",
    "                        HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                        xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                    if aug_amnt[i-1,4]>0:\n",
    "                        methd=50\n",
    "                        sort=-3\n",
    "                        dp_slct_dstrb=4\n",
    "                        Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,4],dp_slct_dstrb,sort)\n",
    "                        Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,4],dp_slct_dstrb,sort)\n",
    "                        HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                        xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                    if aug_amnt[i-1,5]>0:\n",
    "                        methd=60\n",
    "                        sort=-1\n",
    "                        dp_slct_dstrb=4\n",
    "                        Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,5],dp_slct_dstrb,sort)\n",
    "                        Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,5],dp_slct_dstrb,sort)\n",
    "                        HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                        xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                    if aug_amnt[i-1,6]>0:\n",
    "                        methd=70\n",
    "                        sort=-1\n",
    "                        dp_slct_dstrb=2\n",
    "                        Hrzntl=srtd_dataH(methd,i,aug_amnt[i-1,6],dp_slct_dstrb,sort)\n",
    "                        Vrtcl=srtd_dataV(methd,i,aug_amnt[i-1,6],dp_slct_dstrb,sort)\n",
    "                        HrzntlVrtcl=np.concatenate((Hrzntl[:,:-1],Vrtcl),axis=1)\n",
    "                        xtrain=np.append(xtrain,HrzntlVrtcl,axis=0)\n",
    "                    #print('class ', i, 'train shape = ', np.shape(xtrain))\n",
    "\n",
    "                # Normalization train windows\n",
    "                mx_aug=np.max(xtrain[:,:-1])\n",
    "                mx=np.max(ecg[:,:-1])\n",
    "                mn_aug=np.min(xtrain[:,:-1])\n",
    "                mn=np.min(ecg[:,:-1])\n",
    "                xtrain[:,:-1]= 2*(xtrain[:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1\n",
    "\n",
    "\n",
    "                ###Test Windows:\n",
    "                wndws_test=np.empty((0,len(wndws1[0])), float)\n",
    "                i=0\n",
    "                windws=np.array([])\n",
    "                for cls in range (1,cls_num+1):                                 #ساخت پنجره های داده های آموزش اصلی\n",
    "                    vars()['wndws_tst'+str(cls)]=np.empty((0,len(wndws1[0])), float)\n",
    "                    vars()['wndws_tst'+str(cls)]=np.append(vars()['wndws_tst'+str(cls)],vars()['ecg_tst'+str(cls)],axis=0)   \n",
    "\n",
    "                # Normalization test windows\n",
    "                for i in range (1,cls_num+1):                \n",
    "                    cls=i\n",
    "                    #print('\\n cls', i, ' >> ')\n",
    "                    #print('max magnitude class', i , ' = ' ,np.max(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "                    #print('min magnitude class', i , ' = ' ,np.min(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "                    vars()['wndws_tst'+str(i)][:,:-1]= 2*(vars()['wndws_tst'+str(i)][:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1\n",
    "                    #print('after normalizing >>')\n",
    "                    #print('max magnitude class', i , ' = ' ,np.max(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "                    #print('min magnitude class', i , ' = ' ,np.min(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "                #print(\"each class and its windows =\")                    #تجمیع کلاس های تست\n",
    "                for cls in range (1,cls_num+1):                                # آرایه ی تعداد پنجره ی هر کلاس\n",
    "                    wns=len(vars()['wndws_tst'+str(cls)])\n",
    "                    wndws_test=np.append(wndws_test,vars()['wndws_tst'+str(cls)],axis=0)\n",
    "                Xtest=wndws_test[:,:-1]\n",
    "                ytest=np.int16(wndws_test[:,-1])\n",
    "\n",
    "                trainx=np.random.permutation(xtrain)\n",
    "                Xtrain=np.array(trainx[:,:-1])\n",
    "                ytrain=np.int16(trainx[:,-1])\n",
    "\n",
    "                X_train=np.array(Xtrain)\n",
    "                y_train=np.array(ytrain)\n",
    "                X_test=np.array(Xtest)\n",
    "                y_test=np.array(ytest)\n",
    "                X_valid=np.array(Xtrain)\n",
    "                y_valid=np.array(ytrain)\n",
    "                #print('X_train => ', X_train.shape)\n",
    "                #print('y_train => ', y_train.shape)\n",
    "                #print('X_test  => ', X_test.shape)\n",
    "                #print('y_test  => ', y_test.shape)\n",
    "                #print('X_valid  => ', X_valid.shape)\n",
    "                #print('y_valid  => ', y_valid.shape)\n",
    "\n",
    "                y_train_cat=to_categorical(y_train)\n",
    "                y_valid_cat=to_categorical(y_valid)\n",
    "                y_test_cat=to_categorical(y_test)\n",
    "                X_train = np.expand_dims(X_train, axis=2)\n",
    "                X_valid = np.expand_dims(X_valid, axis=2)\n",
    "                X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "                ####### NETWORK #######\n",
    "                accuracy=0\n",
    "                acc_crs=np.array([])\n",
    "                ##for i in range (10):\n",
    "                ##    if accuracy<0.2 :\n",
    "                verbose, epochs, batch_size = 0, 1000, btch\n",
    "                n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train_cat.shape[1]\n",
    "                steps_per_epoch = len(X_train)//batch_size\n",
    "                validation_steps = len(X_valid)//batch_size # if you have test data\n",
    "                model_crs = Sequential()\n",
    "                BatchNormalization()\n",
    "                model_crs.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "                #model_crs.add(MaxPooling1D(pool_size=3))\n",
    "                BatchNormalization()\n",
    "                model_crs.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "                #model_crs.add(Dropout(0.5))\n",
    "                model_crs.add(MaxPooling1D(pool_size=3))\n",
    "                BatchNormalization()\n",
    "                model_crs.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "                model_crs.add(MaxPooling1D(pool_size=3))\n",
    "                BatchNormalization()\n",
    "                model_crs.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "                model_crs.add(MaxPooling1D(pool_size=3))\n",
    "                BatchNormalization()\n",
    "                model_crs.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "                model_crs.add(MaxPooling1D(pool_size=3))\n",
    "                '''model_crs.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "                model_crs.add(MaxPooling1D(pool_size=3))\n",
    "                model_crs.add(Conv1D(filters=1024, kernel_size=3, activation='relu'))\n",
    "                model_crs.add(MaxPooling1D(pool_size=3))\n",
    "                '''\n",
    "                model_crs.add(Flatten())\n",
    "                #model_crs.add(Dropout(0.5))\n",
    "                model_crs.add(Dense(2000, activation='relu'))\n",
    "                model_crs.add(Dense(n_outputs, activation='softmax'))\n",
    "                model_crs.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                # fit network   #CategoricalCrossentropy #sparse_categorical_crossentropy #SparseCategoricalCrossentropy\n",
    "                earlystopping = callbacks.EarlyStopping(monitor =\"val_accuracy\", mode =\"max\", patience = 20, restore_best_weights = True)\n",
    "                model_crs.fit(X_train, y_train_cat, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data = (X_valid, y_valid_cat), callbacks =[earlystopping])\n",
    "                # evaluate model_crs\n",
    "                _, accuracy = model_crs.evaluate(X_valid, y_valid_cat, batch_size=batch_size, verbose=verbose)\n",
    "                predict_x=model_crs.predict(X_test)              # Function 1\n",
    "                y_pred_crs=maxindx(predict_x)                    # function from augment.py to remove 0 index predictions\n",
    "                rprt0=classification_report(y_test, y_pred_crs,output_dict=True)\n",
    "                rprt_row=np.array([])\n",
    "                rprt_row=np.append(rprt_row,rprt0['accuracy'])\n",
    "                rprt_row=np.append(rprt_row,rprt0['macro avg']['f1-score'])\n",
    "                rprt_row=np.append(rprt_row,rprt0['weighted avg']['f1-score'])\n",
    "                rprt=np.append(rprt,[rprt_row],axis=0)\n",
    "            #print('rprt=',rprt)\n",
    "            maxm=rprt[np.argmax(rprt[:,1])]\n",
    "            #print('maxm=',maxm)\n",
    "            avrg=np.mean(rprt,axis=0)\n",
    "            #print('avrg=',avrg)\n",
    "            rslts=np.append(rslts,['X '+str(X)+'  alpha '+str(alpha) +'  Beta '+str(beta)+'  average= '+str(np.int16(100*avrg))+'  max= '+str(np.int16(100*maxm))+'  var= '+str(np.int16(np.var(100*rprt,axis=0)))],axis=0)\n",
    "            print('rslts=',rslts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['X 4  alpha 1  Beta 1  average= [86 86 86]  max= [87 87 87]  var= [0 0 0]',\n",
       "       'X 4  alpha 1  Beta 2  average= [88 87 87]  max= [88 88 88]  var= [0 0 0]',\n",
       "       'X 4  alpha 1  Beta 6  average= [88 88 88]  max= [90 89 89]  var= [4 5 5]',\n",
       "       'X 4  alpha 2  Beta 1  average= [87 87 87]  max= [88 88 88]  var= [1 1 1]',\n",
       "       'X 4  alpha 2  Beta 2  average= [90 90 90]  max= [91 91 91]  var= [0 0 0]',\n",
       "       'X 4  alpha 2  Beta 6  average= [87 87 87]  max= [88 88 88]  var= [1 0 0]',\n",
       "       'X 4  alpha 3  Beta 1  average= [87 87 87]  max= [88 88 88]  var= [1 1 1]',\n",
       "       'X 4  alpha 3  Beta 2  average= [89 89 89]  max= [89 89 89]  var= [0 0 0]',\n",
       "       'X 4  alpha 3  Beta 6  average= [86 86 86]  max= [90 89 89]  var= [5 6 6]',\n",
       "       'X 5  alpha 1  Beta 1  average= [87 87 87]  max= [89 89 89]  var= [7 7 7]',\n",
       "       'X 5  alpha 1  Beta 2  average= [87 86 86]  max= [89 89 89]  var= [7 8 8]',\n",
       "       'X 5  alpha 1  Beta 6  average= [87 87 86]  max= [88 88 88]  var= [1 1 1]',\n",
       "       'X 5  alpha 2  Beta 1  average= [87 87 87]  max= [88 88 88]  var= [1 1 1]',\n",
       "       'X 5  alpha 2  Beta 2  average= [87 87 87]  max= [87 87 87]  var= [0 0 0]',\n",
       "       'X 5  alpha 2  Beta 6  average= [87 86 86]  max= [89 88 88]  var= [1 2 2]',\n",
       "       'X 5  alpha 3  Beta 1  average= [87 87 87]  max= [88 88 88]  var= [0 0 0]',\n",
       "       'X 5  alpha 3  Beta 2  average= [89 89 89]  max= [89 89 89]  var= [0 0 0]',\n",
       "       'X 5  alpha 3  Beta 6  average= [86 86 86]  max= [89 89 89]  var= [2 3 3]'],\n",
       "      dtype='<U72')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
