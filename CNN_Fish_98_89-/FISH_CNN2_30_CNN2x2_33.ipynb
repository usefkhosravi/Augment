{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import time\n",
    "plc=1\n",
    "time.sleep(3000*plc)         #run after 1 houre = 3600 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#notebook { padding-top:0px !important; } .container { width:100% !important; } .end_space { min-height:0px !important; } html, body, .container{ margin:0!important;padding:0!important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "import random\n",
    "import bisect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess import *                         #ماژول استخراج پنجره ها\n",
    "from data import *                          #ماژول محلی ورود داده ها\n",
    "from augment import *                            #ماژول های داده افزایی\n",
    "from lstm_cnn import *                           #ماژول های داده افزایی با lstm_cnn\n",
    "import augment\n",
    "import importlib\n",
    "importlib.reload(augment)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report,recall_score,precision_score\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D,Conv1D,Dropout,MaxPooling1D,MaxPooling2D,Flatten,Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "cwd = os.getcwd() #\n",
    "fullscrn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><div style=\"direction:rtl;font-family:B Nazanin\">Importing Data</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_train_shape= (175, 464)\n",
      "first_test_shape= (175, 464)\n",
      "classes_quantity= 7\n",
      "tr_lbls=\t {1, 2, 3, 4, 5, 6, 7}\n",
      "Count_labels= [26 25 28 21 22 25 28]\n",
      "max(train_feature_Altitude)= 7.0\n",
      "min(train_feature_Altitude)= -1.9506\n",
      "first_train_sample=\n",
      " [ 7.0000e+00  1.9509e+00  1.9267e+00  1.8957e+00  1.8580e+00  1.8206e+00\n",
      "  1.7903e+00  1.7676e+00  1.7313e+00  1.6952e+00  1.6589e+00  1.6230e+00\n",
      "  1.5869e+00  1.5572e+00  1.5217e+00  1.4861e+00  1.4505e+00  1.4140e+00\n",
      "  1.3777e+00  1.3415e+00  1.3054e+00  1.2699e+00  1.2348e+00  1.1989e+00\n",
      "  1.1633e+00  1.1267e+00  1.0922e+00  1.0566e+00  1.0210e+00  9.8561e-01\n",
      "  9.4955e-01  9.1484e-01  8.7873e-01  8.4270e-01  8.0675e-01  7.7089e-01\n",
      "  7.3512e-01  6.9944e-01  6.6385e-01  6.2656e-01  5.9114e-01  5.5395e-01\n",
      "  5.1871e-01  4.8163e-01  4.4643e-01  4.0963e-01  3.7273e-01  3.3589e-01\n",
      "  3.0122e-01  2.6453e-01  2.2790e-01  1.9134e-01  1.5484e-01  1.1848e-01\n",
      "  8.2080e-02  4.5819e-02  9.6418e-03 -2.6445e-02 -6.2437e-02 -9.8329e-02\n",
      " -1.3412e-01 -1.6979e-01 -2.0535e-01 -2.4079e-01 -2.7609e-01 -3.1126e-01\n",
      " -3.4627e-01 -3.8114e-01 -4.1583e-01 -4.5035e-01 -4.7830e-01 -5.0900e-01\n",
      " -5.3932e-01 -5.6422e-01 -5.8783e-01 -6.0897e-01 -6.3131e-01 -6.5184e-01\n",
      " -6.6625e-01 -6.8112e-01 -6.9434e-01 -7.0491e-01 -7.1466e-01 -7.2294e-01\n",
      " -7.2971e-01 -7.4028e-01 -7.5052e-01 -7.5760e-01 -7.7014e-01 -7.8231e-01\n",
      " -7.9051e-01 -7.9427e-01 -8.0191e-01 -8.0758e-01 -8.2325e-01 -8.3793e-01\n",
      " -8.6776e-01 -9.0660e-01 -9.4326e-01 -9.8111e-01 -1.0169e+00 -1.0525e+00\n",
      " -1.0878e+00 -1.1304e+00 -1.1779e+00 -1.2118e+00 -1.2504e+00 -1.2892e+00\n",
      " -1.3342e+00 -1.3713e+00 -1.3982e+00 -1.4284e+00 -1.4419e+00 -1.4601e+00\n",
      " -1.4696e+00 -1.4835e+00 -1.4953e+00 -1.4979e+00 -1.5047e+00 -1.5090e+00\n",
      " -1.5040e+00 -1.5032e+00 -1.4998e+00 -1.4879e+00 -1.4793e+00 -1.4688e+00\n",
      " -1.4560e+00 -1.4354e+00 -1.4187e+00 -1.4003e+00 -1.3789e+00 -1.3536e+00\n",
      " -1.3307e+00 -1.3066e+00 -1.2812e+00 -1.2548e+00 -1.2244e+00 -1.1992e+00\n",
      " -1.1702e+00 -1.1404e+00 -1.1099e+00 -1.0789e+00 -1.0473e+00 -1.0123e+00\n",
      " -9.7991e-01 -9.4665e-01 -9.1127e-01 -8.7532e-01 -8.3711e-01 -7.9581e-01\n",
      " -7.5240e-01 -7.1170e-01 -6.7151e-01 -6.3428e-01 -5.9566e-01 -5.5700e-01\n",
      " -5.1832e-01 -4.8186e-01 -4.4309e-01 -4.0649e-01 -3.6766e-01 -3.3509e-01\n",
      " -3.0467e-01 -2.8453e-01 -2.6741e-01 -2.4286e-01 -2.3729e-01 -2.5098e-01\n",
      " -2.8306e-01 -3.2307e-01 -3.2182e-01 -2.8553e-01 -2.4904e-01 -2.1155e-01\n",
      " -1.7426e-01 -1.3710e-01 -9.9367e-02 -6.1820e-02 -2.4350e-02  1.4162e-02\n",
      "  5.2106e-02  9.0096e-02  1.2864e-01  1.6719e-01  2.0626e-01  2.4533e-01\n",
      "  2.8497e-01  3.2412e-01  3.6376e-01  4.0315e-01  4.4327e-01  4.8295e-01\n",
      "  5.2294e-01  5.6293e-01  6.0414e-01  6.4468e-01  6.8529e-01  7.2611e-01\n",
      "  7.6855e-01  8.0248e-01  8.4356e-01  8.8501e-01  9.2638e-01  9.6672e-01\n",
      "  1.0077e+00  1.0486e+00  1.0890e+00  1.1289e+00  1.1686e+00  1.2090e+00\n",
      "  1.2472e+00  1.2841e+00  1.3118e+00  1.3328e+00  1.3139e+00  1.2954e+00\n",
      "  1.2772e+00  1.2644e+00  1.2489e+00  1.2320e+00  1.2223e+00  1.2131e+00\n",
      "  1.2043e+00  1.1959e+00  1.1743e+00  1.1532e+00  1.1235e+00  1.0919e+00\n",
      "  1.0607e+00  1.0232e+00  9.9311e-01  1.0067e+00  1.0250e+00  1.0547e+00\n",
      "  1.0833e+00  1.1120e+00  1.1408e+00  1.1658e+00  1.1803e+00  1.2034e+00\n",
      "  1.2296e+00  1.2645e+00  1.2885e+00  1.2955e+00  1.3164e+00  1.3309e+00\n",
      "  1.3392e+00  1.3413e+00  1.3430e+00  1.3103e+00  1.2754e+00  1.2408e+00\n",
      "  1.2038e+00  1.1644e+00  1.1235e+00  1.0826e+00  1.0390e+00  9.9699e-01\n",
      "  9.5982e-01  9.2362e-01  8.7945e-01  8.3559e-01  7.9213e-01  7.4722e-01\n",
      "  7.0248e-01  6.5793e-01  6.1252e-01  5.6941e-01  5.2672e-01  4.8445e-01\n",
      "  4.4278e-01  4.0050e-01  3.5966e-01  3.1937e-01  2.8005e-01  2.3865e-01\n",
      "  1.9738e-01  1.5746e-01  1.1658e-01  7.5781e-02  3.7458e-02 -1.7719e-03\n",
      " -4.0064e-02 -7.8342e-02 -1.1661e-01 -1.5384e-01 -1.9205e-01 -2.2916e-01\n",
      " -2.6618e-01 -3.0428e-01 -3.4116e-01 -3.7912e-01 -4.1590e-01 -4.0776e-01\n",
      " -3.8189e-01 -3.6769e-01 -3.4274e-01 -3.2486e-01 -3.0737e-01 -2.9511e-01\n",
      " -2.8212e-01 -2.6839e-01 -2.5396e-01 -2.3883e-01 -2.2922e-01 -2.3393e-01\n",
      " -2.6074e-01 -2.9248e-01 -3.3074e-01 -3.7018e-01 -4.1610e-01 -4.5877e-01\n",
      " -5.0413e-01 -5.4786e-01 -5.9159e-01 -6.3532e-01 -6.7580e-01 -7.2128e-01\n",
      " -7.6975e-01 -8.1026e-01 -8.5072e-01 -8.9116e-01 -9.3155e-01 -9.7045e-01\n",
      " -1.0122e+00 -1.0525e+00 -1.0947e+00 -1.1398e+00 -1.1764e+00 -1.2068e+00\n",
      " -1.2374e+00 -1.2689e+00 -1.2886e+00 -1.3076e+00 -1.3315e+00 -1.3587e+00\n",
      " -1.3800e+00 -1.4049e+00 -1.4231e+00 -1.4451e+00 -1.4597e+00 -1.4782e+00\n",
      " -1.4885e+00 -1.4965e+00 -1.5085e+00 -1.5115e+00 -1.5119e+00 -1.5165e+00\n",
      " -1.5075e+00 -1.5043e+00 -1.4718e+00 -1.4341e+00 -1.3953e+00 -1.3565e+00\n",
      " -1.3176e+00 -1.2794e+00 -1.2590e+00 -1.2536e+00 -1.2389e+00 -1.2399e+00\n",
      " -1.2456e+00 -1.2437e+00 -1.2500e+00 -1.2576e+00 -1.2616e+00 -1.2622e+00\n",
      " -1.2656e+00 -1.2665e+00 -1.2648e+00 -1.2527e+00 -1.2379e+00 -1.2117e+00\n",
      " -1.1845e+00 -1.1566e+00 -1.1279e+00 -1.0985e+00 -1.0643e+00 -1.0302e+00\n",
      " -9.9892e-01 -9.6366e-01 -9.3166e-01 -8.9621e-01 -8.6295e-01 -8.2759e-01\n",
      " -7.9467e-01 -7.6487e-01 -7.3128e-01 -6.9742e-01 -6.6014e-01 -6.2589e-01\n",
      " -5.9142e-01 -5.5676e-01 -5.2191e-01 -4.8973e-01 -4.5448e-01 -4.1908e-01\n",
      " -3.8354e-01 -3.4787e-01 -3.1461e-01 -2.8112e-01 -2.4739e-01 -2.1113e-01\n",
      " -1.7477e-01 -1.3916e-01 -1.0617e-01 -6.9482e-02 -3.4803e-02  3.7369e-05\n",
      "  3.5031e-02  7.0171e-02  1.0545e-01  1.4086e-01  1.7640e-01  2.1360e-01\n",
      "  2.4821e-01  2.8371e-01  3.1970e-01  3.5579e-01  3.9049e-01  4.2805e-01\n",
      "  4.6320e-01  4.9969e-01  5.3625e-01  5.7290e-01  6.0961e-01  6.4639e-01\n",
      "  6.8325e-01  7.2017e-01  7.5693e-01  7.9325e-01  8.2967e-01  8.6661e-01\n",
      "  9.0366e-01  9.4098e-01  9.7834e-01  1.0157e+00  1.0532e+00  1.0899e+00\n",
      "  1.1274e+00  1.1646e+00  1.2019e+00  1.2396e+00  1.2773e+00  1.3151e+00\n",
      "  1.3523e+00  1.3901e+00  1.4280e+00  1.4659e+00  1.5033e+00  1.5408e+00\n",
      "  1.5783e+00  1.6156e+00  1.6528e+00  1.6906e+00  1.7282e+00  1.7661e+00\n",
      "  1.8044e+00  1.8422e+00  1.8567e+00  1.8628e+00  1.9011e+00  1.9395e+00\n",
      "  1.9505e+00  1.9508e+00]\n",
      "1 26\t2 25\t3 28\t4 21\t5 22\t6 25\t7 28\t"
     ]
    }
   ],
   "source": [
    "rate=480\n",
    "cls_num=7\n",
    "btch=50\n",
    "for i in range (1,cls_num+1):\n",
    "    vars()['ecg'+str(i)],vars()['ecg_tst'+str(i)]=FISH(i)\n",
    "\n",
    "os.chdir(cwd)\n",
    "clses_lens=np.array([])\n",
    "i=0                               #جمع آوری داده ها و چاپ تعداد نمونه ی هر کلاس\n",
    "ecg=np.array(ecg1)\n",
    "print(1,len(vars()['ecg'+str(1)]), end='\\t')\n",
    "clses_lens=np.append(clses_lens,len(vars()['ecg'+str(1)]))\n",
    "for i in range (2,cls_num+1):\n",
    "    ecg=np.concatenate((ecg,vars()['ecg'+str(i)]),axis=0)\n",
    "    clses_lens=np.append(clses_lens,len(vars()['ecg'+str(i)]))\n",
    "    print(i,len(vars()['ecg'+str(i)]), end='\\t')\n",
    "\n",
    "mx_sig=max(clses_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 481)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
       "       6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 7., 7., 7., 7., 7., 7.,\n",
       "       7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n",
       "       7., 7., 7., 7., 7.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center><div style=\"direction:rtl;font-family:B Nazanin\">Base Train windows</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each class and its windows =\n",
      "1 26\t2 25\t3 28\t4 21\t5 22\t6 25\t7 28\t\n",
      " max = 28\n"
     ]
    }
   ],
   "source": [
    "smpl_rte=480                                              # در ماژول ها نیز همین مقدار ثبت شده\n",
    "i=0\n",
    "windws=np.array([])\n",
    "\n",
    "for cls in range (1,cls_num+1):                                 #ساخت پنجره های داده های آموزش اصلی\n",
    "    vars()['wndws'+str(cls)]=np.array(vars()['ecg'+str(cls)])  \n",
    "    \n",
    "print(\"each class and its windows =\")\n",
    "\n",
    "cls_wndws=np.array([])\n",
    "for cls in range (1,cls_num+1):                                # آرایه ی تعداد پنجره ی هر کلاس\n",
    "    wns=len(vars()['wndws'+str(cls)])\n",
    "    cls_wndws=np.append(cls_wndws,wns)\n",
    "    print(cls, wns, end='\\t')\n",
    "\n",
    "mx_wndws=int(np.max(cls_wndws))                        # حداکثر تعداد پنجره ی موجود بین کلاس ها\n",
    "print('\\n max =', mx_wndws)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#clses=3                                   #تعیین میزان افزایش نمونه (تولید داده)\n",
    "mx_wndws=int(mx_wndws)  #mx_wndws*0.3  # =classes-1 برای بررسی الگوریتم تعداد کمی کلاس آزمایش شد\n",
    "mx_wndws=2598           #+2\n",
    "print(mx_wndws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><div style=\"direction:rtl;font-family:B Nazanin\">Data Augmentation</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up to class  1 train shape =  (26, 481)\n",
      "Up to class  2 train shape =  (51, 481)\n",
      "Up to class  3 train shape =  (79, 481)\n",
      "Up to class  4 train shape =  (100, 481)\n",
      "Up to class  5 train shape =  (122, 481)\n",
      "Up to class  6 train shape =  (147, 481)\n",
      "Up to class  7 train shape =  (175, 481)\n"
     ]
    }
   ],
   "source": [
    "smpl_rte=len(wndws1[0])                                        # در ماژول ها نیز همین مقدار ثبت شده\n",
    "\n",
    "#add augmented data to base data\n",
    "xtrain=np.empty((0,len(wndws1[0])), float) \n",
    "for i in range (1,cls_num+1):   \n",
    "    xtrain=np.append(xtrain,vars()['wndws'+str(i)],axis=0)\n",
    "    print('Up to class ', i, 'train shape = ', np.shape(xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 26 25 28 21 22 25 28]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(np.int16(xtrain[:,-1])))    #تعداد پنجره در هر کلاس از 0 تا 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
       "       6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 7., 7., 7., 7., 7., 7.,\n",
       "       7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n",
       "       7., 7., 7., 7., 7.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_aug=np.max(xtrain[:,:-1])\n",
    "mx=np.max(ecg[:,:-1])\n",
    "mn_aug=np.min(xtrain[:,:-1])\n",
    "mn=np.min(ecg[:,:-1])\n",
    "\n",
    "#for i in range (1,cls_num+1):             #نرمالسازی داده های افزایشی\n",
    "xtrain[:,:-1]= 2*(xtrain[:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min trn = -1.0\n",
      "max trn = 1.0\n"
     ]
    }
   ],
   "source": [
    "print('min trn =', np.min(xtrain[:,:-1]))\n",
    "print('max trn =', np.max(xtrain[:,:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center><div style=\"direction:rtl;font-family:B Nazanin\">Test Windows</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wndws_test=np.empty((0,len(wndws1[0])), float)\n",
    "i=0\n",
    "windws=np.array([])\n",
    "for cls in range (1,cls_num+1):                                 #ساخت پنجره های داده های آموزش اصلی\n",
    "    vars()['wndws_tst'+str(cls)]=np.empty((0,len(wndws1[0])), float)\n",
    "    vars()['wndws_tst'+str(cls)]=np.append(vars()['wndws_tst'+str(cls)],vars()['ecg_tst'+str(cls)],axis=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " cls 1  >> \n",
      "max magnitude class 1  =  2.0470912776915458\n",
      "min magnitude class 1  =  -1.7067841463837912\n",
      "after normalizing >>\n",
      "max magnitude class 1  =  0.961349554710035\n",
      "min magnitude class 1  =  -0.8796770785564421\n",
      "\n",
      " cls 2  >> \n",
      "max magnitude class 2  =  1.9995000000000018\n",
      "min magnitude class 2  =  -1.737570959253758\n",
      "after normalizing >>\n",
      "max magnitude class 2  =  0.9380091931254746\n",
      "min magnitude class 2  =  -0.8947759659844823\n",
      "\n",
      " cls 3  >> \n",
      "max magnitude class 3  =  2.1528521925548616\n",
      "min magnitude class 3  =  -1.777414662371874\n",
      "after normalizing >>\n",
      "max magnitude class 3  =  1.0132182607872897\n",
      "min magnitude class 3  =  -0.9143166566898705\n",
      "\n",
      " cls 4  >> \n",
      "max magnitude class 4  =  11.25984586666761\n",
      "min magnitude class 4  =  -1.9420530969143601\n",
      "after normalizing >>\n",
      "max magnitude class 4  =  5.479593941637377\n",
      "min magnitude class 4  =  -0.9950608766253729\n",
      "\n",
      " cls 5  >> \n",
      "max magnitude class 5  =  2.1211000000000007\n",
      "min magnitude class 5  =  -1.7538854427257269\n",
      "after normalizing >>\n",
      "max magnitude class 5  =  0.9976459187262836\n",
      "min magnitude class 5  =  -0.9027771368244226\n",
      "\n",
      " cls 6  >> \n",
      "max magnitude class 6  =  2.0540000000000016\n",
      "min magnitude class 6  =  -1.7891619372072987\n",
      "after normalizing >>\n",
      "max magnitude class 6  =  0.9647378242541269\n",
      "min magnitude class 6  =  -0.9200779149622185\n",
      "\n",
      " cls 7  >> \n",
      "max magnitude class 7  =  2.04040190917243\n",
      "min magnitude class 7  =  -1.60279219024271\n",
      "after normalizing >>\n",
      "max magnitude class 7  =  0.9580688636342356\n",
      "min magnitude class 7  =  -0.8286759292712687\n",
      "each class and its windows =\n",
      "1 24\t2 25\t3 22\t4 29\t5 28\t6 25\t7 22\t\n",
      " max instance in classes of test windows = 29\n"
     ]
    }
   ],
   "source": [
    "#print(np.max(wndws_tst))\n",
    "for i in range (1,cls_num+1):                # Normalization test windows\n",
    "    cls=i\n",
    "    print('\\n cls', i, ' >> ')\n",
    "    print('max magnitude class', i , ' = ' ,np.max(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "    print('min magnitude class', i , ' = ' ,np.min(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "\n",
    "    vars()['wndws_tst'+str(i)][:,:-1]= 2*(vars()['wndws_tst'+str(i)][:,:-1]-mn_aug)/(mx_aug - mn_aug) - 1\n",
    "    \n",
    "    print('after normalizing >>')\n",
    "    print('max magnitude class', i , ' = ' ,np.max(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "    print('min magnitude class', i , ' = ' ,np.min(vars()['wndws_tst'+str(cls)][:,:-1]))\n",
    "    \n",
    "print(\"each class and its windows =\")                    #تجمیع کلاس های تست\n",
    "cls_wndws=np.array([])\n",
    "for cls in range (1,cls_num+1):                                # آرایه ی تعداد پنجره ی هر کلاس\n",
    "    wns=len(vars()['wndws_tst'+str(cls)])\n",
    "    cls_wndws=np.append(cls_wndws,wns)\n",
    "    print(cls, wns, end='\\t')\n",
    "    wndws_test=np.append(wndws_test,vars()['wndws_tst'+str(cls)],axis=0)\n",
    "    \n",
    "mx_wndws=int(np.max(cls_wndws))                        # حداکثر تعداد پنجره ی موجود بین کلاس ها\n",
    "print('\\n max instance in classes of test windows =', mx_wndws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min tst = -0.9950608766253729\n",
      "max tst = 5.479593941637377\n"
     ]
    }
   ],
   "source": [
    "print('min tst =', np.min(wndws_test[:,:-1]))\n",
    "print('max tst =', np.max(wndws_test[:,:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wndws_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 481)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(wndws_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=wndws_test[:,:-1]\n",
    "ytest=np.int16(wndws_test[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7,\n",
      "       7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7],\n",
      "      dtype=int16)\n"
     ]
    }
   ],
   "source": [
    "fullprint(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center><div style=\"direction:rtl;font-family:B Nazanin\">Train Windows</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nytestt=np.int32(np.array([ytest]).T)\\ntestx=np.concatenate((Xtest, ytestt), axis=1)\\ntestx=np.random.permutation(testx)\\nXtest=np.int32(testx[:,:-1])\\nytest=np.int32(testx[:,-1])'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ytraint=np.int32(np.array([ytrain]).T)\n",
    "#trainx=np.concatenate((Xtrain, ytraint), axis=1)\n",
    "trainx=np.random.permutation(xtrain)\n",
    "Xtrain=np.array(trainx[:,:-1])\n",
    "ytrain=np.int16(trainx[:,-1])\n",
    "'''\n",
    "ytestt=np.int32(np.array([ytest]).T)\n",
    "testx=np.concatenate((Xtest, ytestt), axis=1)\n",
    "testx=np.random.permutation(testx)\n",
    "Xtest=np.int32(testx[:,:-1])\n",
    "ytest=np.int32(testx[:,-1])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 481)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(wndws1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center><div style=\"direction:rtl;font-family:B Nazanin\">Validation Windows</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvalid=np.array(Xtrain)\n",
    "yvalid=np.array(ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><div style=\"direction:rtl;font-family:B Nazanin\">CNN And UnBalanced RAW Data</div></center></h1>\n",
    "<h1><center><div style=\"direction:rtl;font-family:Arial\">Cross Entropy Loss Function</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train =>  (175, 480)\n",
      "y_train =>  (175,)\n",
      "X_test  =>  (175, 480)\n",
      "y_test  =>  (175,)\n",
      "X_valid  =>  (175, 480)\n",
      "y_valid  =>  (175,)\n"
     ]
    }
   ],
   "source": [
    "X_train=np.array(Xtrain)\n",
    "y_train=np.array(ytrain)\n",
    "X_test=np.array(Xtest)\n",
    "y_test=np.array(ytest)\n",
    "X_valid=np.array(Xtrain)\n",
    "y_valid=np.array(ytrain)\n",
    "print('X_train => ', X_train.shape)\n",
    "print('y_train => ', y_train.shape)\n",
    "print('X_test  => ', X_test.shape)\n",
    "print('y_test  => ', y_test.shape)\n",
    "print('X_valid  => ', X_valid.shape)\n",
    "print('y_valid  => ', y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array(y_train+1)\n",
    "y_test=np.array(y_test+1)\n",
    "y_valid=np.array(y_valid+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat=to_categorical(y_train)\n",
    "y_valid_cat=to_categorical(y_valid)\n",
    "y_test_cat=to_categorical(y_test)\n",
    "\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_valid = np.expand_dims(X_valid, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "#y_train=np.transpose([y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 4s 346ms/step - loss: 5.1381 - accuracy: 0.2000 - val_loss: 2.1831 - val_accuracy: 0.1429\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.0789 - accuracy: 0.1086 - val_loss: 2.1434 - val_accuracy: 0.1429\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 2.4527 - accuracy: 0.1143 - val_loss: 2.1637 - val_accuracy: 0.1600\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.9958 - accuracy: 0.2400 - val_loss: 2.1446 - val_accuracy: 0.1600\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.9876 - accuracy: 0.2057 - val_loss: 2.0862 - val_accuracy: 0.1600\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.1092 - accuracy: 0.2343 - val_loss: 2.1389 - val_accuracy: 0.1200\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.8269 - accuracy: 0.2743 - val_loss: 2.0755 - val_accuracy: 0.1257\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 2.3958 - accuracy: 0.2514 - val_loss: 2.0953 - val_accuracy: 0.2457\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.7365 - accuracy: 0.3200 - val_loss: 2.1130 - val_accuracy: 0.1600\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5954 - accuracy: 0.4229 - val_loss: 2.1289 - val_accuracy: 0.1600\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.6997 - accuracy: 0.3200 - val_loss: 2.0371 - val_accuracy: 0.1257\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5315 - accuracy: 0.4057 - val_loss: 2.0391 - val_accuracy: 0.1600\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.3862 - accuracy: 0.5200 - val_loss: 2.0584 - val_accuracy: 0.1829\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0126 - accuracy: 0.6629 - val_loss: 2.0177 - val_accuracy: 0.2514\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.7478 - accuracy: 0.5200 - val_loss: 2.0276 - val_accuracy: 0.2457\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9708 - accuracy: 0.5886 - val_loss: 1.9976 - val_accuracy: 0.1943\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.3042 - accuracy: 0.5771 - val_loss: 2.0063 - val_accuracy: 0.1600\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7125 - accuracy: 0.7543 - val_loss: 1.9782 - val_accuracy: 0.3143\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.9996 - accuracy: 0.6400 - val_loss: 2.0142 - val_accuracy: 0.1600\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5328 - accuracy: 0.8114 - val_loss: 2.0124 - val_accuracy: 0.3543\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0840 - accuracy: 0.6629 - val_loss: 2.0031 - val_accuracy: 0.1600\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4939 - accuracy: 0.8286 - val_loss: 2.0323 - val_accuracy: 0.1486\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5844 - accuracy: 0.7657 - val_loss: 1.9538 - val_accuracy: 0.2457\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6104 - accuracy: 0.7543 - val_loss: 2.0073 - val_accuracy: 0.1200\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3778 - accuracy: 0.8629 - val_loss: 1.9552 - val_accuracy: 0.1771\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5037 - accuracy: 0.8000 - val_loss: 2.0133 - val_accuracy: 0.2629\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7702 - accuracy: 0.7257 - val_loss: 1.9627 - val_accuracy: 0.2629\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2151 - accuracy: 0.9200 - val_loss: 1.9879 - val_accuracy: 0.1600\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2491 - accuracy: 0.8857 - val_loss: 1.9638 - val_accuracy: 0.3200\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2286 - accuracy: 0.9086 - val_loss: 1.9279 - val_accuracy: 0.2229\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2272 - accuracy: 0.9371 - val_loss: 1.9582 - val_accuracy: 0.1200\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2624 - accuracy: 0.9029 - val_loss: 1.9560 - val_accuracy: 0.1486\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6758 - accuracy: 0.7943 - val_loss: 1.9769 - val_accuracy: 0.1200\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0786 - accuracy: 0.9771 - val_loss: 1.9328 - val_accuracy: 0.2229\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1709 - accuracy: 0.9486 - val_loss: 1.9478 - val_accuracy: 0.2857\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1882 - accuracy: 0.9486 - val_loss: 1.9306 - val_accuracy: 0.1257\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0461 - accuracy: 0.9829 - val_loss: 1.9228 - val_accuracy: 0.1371\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0248 - accuracy: 0.9886 - val_loss: 1.9105 - val_accuracy: 0.1943\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0760 - accuracy: 0.9714 - val_loss: 1.9058 - val_accuracy: 0.2229\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0382 - accuracy: 0.9829 - val_loss: 1.9216 - val_accuracy: 0.2000\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5885 - accuracy: 0.8400 - val_loss: 1.9485 - val_accuracy: 0.2514\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2599 - accuracy: 0.9029 - val_loss: 1.9855 - val_accuracy: 0.1200\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1168 - accuracy: 0.9657 - val_loss: 1.8936 - val_accuracy: 0.2457\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0591 - accuracy: 0.9714 - val_loss: 1.9033 - val_accuracy: 0.2571\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1037 - accuracy: 0.9657 - val_loss: 1.9333 - val_accuracy: 0.2514\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.9204 - val_accuracy: 0.2514\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9043 - val_accuracy: 0.2514\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9015 - val_accuracy: 0.2514\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.4290e-04 - accuracy: 1.0000 - val_loss: 1.8967 - val_accuracy: 0.2514\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.8342e-04 - accuracy: 1.0000 - val_loss: 1.9110 - val_accuracy: 0.2571\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.2871e-04 - accuracy: 1.0000 - val_loss: 1.9062 - val_accuracy: 0.2571\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.3660e-04 - accuracy: 1.0000 - val_loss: 1.9187 - val_accuracy: 0.2571\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0529e-04 - accuracy: 1.0000 - val_loss: 1.8911 - val_accuracy: 0.2571\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 8.1665e-04 - accuracy: 1.0000 - val_loss: 1.8826 - val_accuracy: 0.2571\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.3521e-04 - accuracy: 1.0000 - val_loss: 1.8954 - val_accuracy: 0.2571\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.3504e-05 - accuracy: 1.0000 - val_loss: 1.8973 - val_accuracy: 0.2571\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3.9375e-05 - accuracy: 1.0000 - val_loss: 1.8986 - val_accuracy: 0.2571\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 29ms/step - loss: 2.8816e-05 - accuracy: 1.0000 - val_loss: 1.9024 - val_accuracy: 0.2571\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.5497e-05 - accuracy: 1.0000 - val_loss: 1.9025 - val_accuracy: 0.2571\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.2313e-05 - accuracy: 1.0000 - val_loss: 1.9017 - val_accuracy: 0.2571\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.7606e-05 - accuracy: 1.0000 - val_loss: 1.9157 - val_accuracy: 0.2571\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.7599e-05 - accuracy: 1.0000 - val_loss: 1.9048 - val_accuracy: 0.2571\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.2744e-05 - accuracy: 1.0000 - val_loss: 1.8990 - val_accuracy: 0.2571\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.2868e-05 - accuracy: 1.0000 - val_loss: 1.8909 - val_accuracy: 0.2571\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 9.7461e-06 - accuracy: 1.0000 - val_loss: 1.9033 - val_accuracy: 0.2629\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 8.1761e-06 - accuracy: 1.0000 - val_loss: 1.8856 - val_accuracy: 0.2629\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 7.0760e-06 - accuracy: 1.0000 - val_loss: 1.8883 - val_accuracy: 0.2571\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 5.7430e-06 - accuracy: 1.0000 - val_loss: 1.8694 - val_accuracy: 0.2571\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 5.0373e-06 - accuracy: 1.0000 - val_loss: 1.8552 - val_accuracy: 0.2629\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.5074e-06 - accuracy: 1.0000 - val_loss: 1.8535 - val_accuracy: 0.2800\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.0124 - accuracy: 0.3543\n",
      "np.shape(X_test)= (175, 480, 1)\n",
      "Accuracy=  0.35428571701049805\n"
     ]
    }
   ],
   "source": [
    "#VGG16_1D\n",
    "\n",
    "accuracy=0\n",
    "acc_crs=np.array([])\n",
    "##for i in range (10):\n",
    "##    if accuracy<0.2 :\n",
    "\n",
    "verbose, epochs, batch_size = 1, 1000, 80\n",
    "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train_cat.shape[1]\n",
    "steps_per_epoch = len(X_train)//batch_size\n",
    "validation_steps = len(X_valid)//batch_size # if you have test data\n",
    "\n",
    "\n",
    "\n",
    "model_crs = Sequential()\n",
    "#model_crs.add(Conv1D(input_shape=x_train.shape[1:],filters=64,kernel_size=9,padding=\"same\", activation=\"relu\"))\n",
    "model_crs.add(Conv1D(filters=128, kernel_size=12, strides=1, activation='relu', input_shape=(n_timesteps,n_features))) #Replaced\n",
    "model_crs.add(BatchNormalization())\n",
    "model_crs.add(MaxPooling1D(pool_size=2,strides=3))\n",
    "\n",
    "model_crs.add(Conv1D(filters=32, kernel_size=7, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model_crs.add(BatchNormalization())\n",
    "model_crs.add(MaxPooling1D(pool_size=2,strides=2))\n",
    "\n",
    "model_crs.add(Conv1D(filters=32, kernel_size=10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model_crs.add(Conv1D(filters=128, kernel_size=5, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "model_crs.add(MaxPooling1D(pool_size=2,strides=2))\n",
    "\n",
    "model_crs.add(Conv1D(filters=256, kernel_size=15, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model_crs.add(MaxPooling1D(pool_size=2,strides=2))\n",
    "\n",
    "model_crs.add(Conv1D(filters=512, kernel_size=5, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "#model_crs.add(Conv1D(filters=128, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "\n",
    "model_crs.add(Flatten())\n",
    "model_crs.add(Dropout(0.1))\n",
    "model_crs.add(Dense(units=512,activation=\"relu\"))\n",
    "#model_crs.add(Dense(units=2048,activation=\"relu\"))\n",
    "model_crs.add(Dense(n_outputs, activation='softmax'))   #Replaced here from old Model\n",
    "\n",
    "model_crs.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# fit network   #CategoricalCrossentropy #sparse_categorical_crossentropy #SparseCategoricalCrossentropy\n",
    "\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_accuracy\", mode =\"max\", patience = 50, restore_best_weights = True)\n",
    "\n",
    "model_crs.fit(X_train, y_train_cat, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data = (X_valid, y_valid_cat), callbacks =[earlystopping])\n",
    "\n",
    "_, accuracy = model_crs.evaluate(X_valid, y_valid_cat, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print('np.shape(X_test)=',np.shape(X_test))\n",
    "\n",
    "print('Accuracy= ', accuracy)\n",
    "\n",
    "#y_pred_vgg = model_crs.predict_classes(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxindx(ar):\n",
    "    ar_cpy=np.array(ar)\n",
    "    pred=np.argmax(ar,axis=1)\n",
    "    for i in range (len(pred)):\n",
    "        if pred[i]==0:\n",
    "            ar_cpy[i,0]=-1000\n",
    "    pred=np.argmax(ar_cpy,axis=1)\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step\n",
      "array([[ 9,  0,  0,  0,  1, 14,  0],\n",
      "       [25,  0,  0,  0,  0,  0,  0],\n",
      "       [ 7,  0, 10,  0,  0,  5,  0],\n",
      "       [11,  0,  0,  0,  0, 18,  0],\n",
      "       [ 2,  0,  0,  0, 20,  6,  0],\n",
      "       [ 3,  0,  0,  0,  0, 22,  0],\n",
      "       [12,  0,  0,  0,  0, 10,  0]], dtype=int64)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.13      0.38      0.19        24\n",
      "           3       0.00      0.00      0.00        25\n",
      "           4       1.00      0.45      0.62        22\n",
      "           5       0.00      0.00      0.00        29\n",
      "           6       0.95      0.71      0.82        28\n",
      "           7       0.29      0.88      0.44        25\n",
      "           8       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.35       175\n",
      "   macro avg       0.34      0.35      0.30       175\n",
      "weighted avg       0.34      0.35      0.30       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predict_x=model_crs.predict(X_test)              # Function 1\n",
    "\n",
    "y_pred_crs=maxindx(predict_x)                    # function from augment.py to remove 0 index predictions\n",
    "\n",
    "#y_pred_crs = model_crs.predict_classes(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_crs)\n",
    "fullprint(cm)\n",
    "acc3=accuracy_score(y_test, y_pred_crs)\n",
    "\n",
    "print(classification_report(y_test, y_pred_crs))\n",
    "\n",
    "#sns.heatmap(cm, annot=True)\n",
    "\n",
    "#plt.imshow(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 2s 323ms/step - loss: 37.3251 - accuracy: 0.1200 - val_loss: 2.1748 - val_accuracy: 0.1600\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 2.1846 - accuracy: 0.2000 - val_loss: 2.1530 - val_accuracy: 0.1429\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 2.0407 - accuracy: 0.1257 - val_loss: 2.1444 - val_accuracy: 0.1486\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.9673 - accuracy: 0.2514 - val_loss: 2.1317 - val_accuracy: 0.1600\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.9411 - accuracy: 0.1943 - val_loss: 2.1254 - val_accuracy: 0.1429\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.7772 - accuracy: 0.3257 - val_loss: 2.0691 - val_accuracy: 0.1600\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 2.3912 - accuracy: 0.1600 - val_loss: 2.1412 - val_accuracy: 0.1771\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.8068 - accuracy: 0.3314 - val_loss: 2.1240 - val_accuracy: 0.1486\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.5971 - accuracy: 0.4914 - val_loss: 2.0629 - val_accuracy: 0.1257\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 3.0311 - accuracy: 0.1943 - val_loss: 2.0762 - val_accuracy: 0.2343\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.7617 - accuracy: 0.2857 - val_loss: 2.0468 - val_accuracy: 0.1600\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.6233 - accuracy: 0.3943 - val_loss: 2.0230 - val_accuracy: 0.1600\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.9471 - accuracy: 0.4171 - val_loss: 2.0982 - val_accuracy: 0.1600\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.7138 - accuracy: 0.3371 - val_loss: 2.0634 - val_accuracy: 0.2686\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.9427 - accuracy: 0.2743 - val_loss: 2.0306 - val_accuracy: 0.1657\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.4016 - accuracy: 0.4743 - val_loss: 2.0159 - val_accuracy: 0.3257\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0550 - accuracy: 0.6114 - val_loss: 2.0624 - val_accuracy: 0.2171\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.3654 - accuracy: 0.5314 - val_loss: 1.9607 - val_accuracy: 0.1486\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.6032 - accuracy: 0.5200 - val_loss: 2.0270 - val_accuracy: 0.1429\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.7236 - accuracy: 0.3771 - val_loss: 2.0185 - val_accuracy: 0.1600\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.2218 - accuracy: 0.5486 - val_loss: 2.0511 - val_accuracy: 0.2057\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.2426 - accuracy: 0.5657 - val_loss: 2.0682 - val_accuracy: 0.2286\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.0287 - accuracy: 0.6400 - val_loss: 2.0205 - val_accuracy: 0.3429\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.8378 - accuracy: 0.6800 - val_loss: 2.0532 - val_accuracy: 0.1486\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7856 - accuracy: 0.7086 - val_loss: 2.0371 - val_accuracy: 0.1486\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.4192 - accuracy: 0.5429 - val_loss: 2.0341 - val_accuracy: 0.1600\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.8641 - accuracy: 0.6571 - val_loss: 2.0022 - val_accuracy: 0.1600\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.0156 - accuracy: 0.6400 - val_loss: 2.0645 - val_accuracy: 0.2057\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7075 - accuracy: 0.7543 - val_loss: 2.0628 - val_accuracy: 0.1486\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6174 - accuracy: 0.7771 - val_loss: 2.0319 - val_accuracy: 0.1600\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.1013 - accuracy: 0.6571 - val_loss: 2.0332 - val_accuracy: 0.2457\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5641 - accuracy: 0.8343 - val_loss: 2.0206 - val_accuracy: 0.2343\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.7664 - accuracy: 0.5771 - val_loss: 2.0322 - val_accuracy: 0.1600\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.0528 - accuracy: 0.6343 - val_loss: 1.9767 - val_accuracy: 0.1657\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.3489 - accuracy: 0.8800 - val_loss: 1.9966 - val_accuracy: 0.1600\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4163 - accuracy: 0.8400 - val_loss: 1.9542 - val_accuracy: 0.1657\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3171 - accuracy: 0.8743 - val_loss: 1.9764 - val_accuracy: 0.1486\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3469 - accuracy: 0.8800 - val_loss: 1.9815 - val_accuracy: 0.1486\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5119 - accuracy: 0.7943 - val_loss: 1.9305 - val_accuracy: 0.1886\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1744 - accuracy: 0.9429 - val_loss: 2.0030 - val_accuracy: 0.1486\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.4535 - accuracy: 0.8457 - val_loss: 1.9547 - val_accuracy: 0.1657\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.2842 - accuracy: 0.8800 - val_loss: 1.9706 - val_accuracy: 0.2857\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1066 - accuracy: 0.9771 - val_loss: 1.9505 - val_accuracy: 0.1829\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.2119 - accuracy: 0.7200 - val_loss: 2.0347 - val_accuracy: 0.2629\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.4860 - accuracy: 0.8229 - val_loss: 1.9746 - val_accuracy: 0.2571\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.4994 - accuracy: 0.8286 - val_loss: 1.9625 - val_accuracy: 0.1600\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7255 - accuracy: 0.8057 - val_loss: 1.9065 - val_accuracy: 0.4629\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2363 - accuracy: 0.9314 - val_loss: 1.8980 - val_accuracy: 0.2800\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1190 - accuracy: 0.9657 - val_loss: 1.9070 - val_accuracy: 0.2743\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0404 - accuracy: 0.9829 - val_loss: 1.8839 - val_accuracy: 0.2571\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0241 - accuracy: 0.9886 - val_loss: 1.8758 - val_accuracy: 0.3371\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.8626 - val_accuracy: 0.2571\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8726 - val_accuracy: 0.2914\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9670 - val_accuracy: 0.2057\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.2885 - accuracy: 0.9257 - val_loss: 1.9904 - val_accuracy: 0.1486\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6324 - accuracy: 0.7886 - val_loss: 1.9276 - val_accuracy: 0.1429\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5137 - accuracy: 0.8229 - val_loss: 1.8884 - val_accuracy: 0.1543\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3141 - accuracy: 0.8743 - val_loss: 1.8572 - val_accuracy: 0.2114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3384 - accuracy: 0.9086 - val_loss: 1.9090 - val_accuracy: 0.2400\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0275 - accuracy: 0.9943 - val_loss: 1.8987 - val_accuracy: 0.2686\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0605 - accuracy: 0.9829 - val_loss: 1.9048 - val_accuracy: 0.2800\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.8843 - val_accuracy: 0.2686\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.8517 - val_accuracy: 0.2857\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 6.6615e-04 - accuracy: 1.0000 - val_loss: 1.8317 - val_accuracy: 0.3143\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 2.8072e-04 - accuracy: 1.0000 - val_loss: 1.8414 - val_accuracy: 0.2229\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.5067e-04 - accuracy: 1.0000 - val_loss: 1.8830 - val_accuracy: 0.2114\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.1516e-04 - accuracy: 1.0000 - val_loss: 1.8515 - val_accuracy: 0.2286\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 9.1045e-05 - accuracy: 1.0000 - val_loss: 1.9472 - val_accuracy: 0.2114\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 3.7661e-05 - accuracy: 1.0000 - val_loss: 1.9352 - val_accuracy: 0.2229\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 2.5808e-05 - accuracy: 1.0000 - val_loss: 2.0434 - val_accuracy: 0.2114\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.5772e-05 - accuracy: 1.0000 - val_loss: 2.0600 - val_accuracy: 0.2114\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.9162e-05 - accuracy: 1.0000 - val_loss: 2.2882 - val_accuracy: 0.1771\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.8732e-05 - accuracy: 1.0000 - val_loss: 2.1389 - val_accuracy: 0.2114\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 8.8170e-06 - accuracy: 1.0000 - val_loss: 2.2035 - val_accuracy: 0.2114\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 7.2578e-06 - accuracy: 1.0000 - val_loss: 2.1678 - val_accuracy: 0.2114\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 5.3016e-06 - accuracy: 1.0000 - val_loss: 2.2222 - val_accuracy: 0.2114\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.7451e-06 - accuracy: 1.0000 - val_loss: 2.4259 - val_accuracy: 0.2000\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 5.5095e-06 - accuracy: 1.0000 - val_loss: 2.2263 - val_accuracy: 0.2171\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 3.7805e-06 - accuracy: 1.0000 - val_loss: 2.4018 - val_accuracy: 0.2114\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 3.3732e-06 - accuracy: 1.0000 - val_loss: 2.2955 - val_accuracy: 0.2229\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 2.5769e-06 - accuracy: 1.0000 - val_loss: 2.3686 - val_accuracy: 0.2114\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.8637e-06 - accuracy: 1.0000 - val_loss: 2.4167 - val_accuracy: 0.2114\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.8072e-06 - accuracy: 1.0000 - val_loss: 2.4792 - val_accuracy: 0.2114\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 2.1873e-06 - accuracy: 1.0000 - val_loss: 2.3581 - val_accuracy: 0.2286\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.6389e-06 - accuracy: 1.0000 - val_loss: 2.5140 - val_accuracy: 0.2229\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 9.5094e-07 - accuracy: 1.0000 - val_loss: 2.4991 - val_accuracy: 0.2286\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.0354e-06 - accuracy: 1.0000 - val_loss: 2.5812 - val_accuracy: 0.2114\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.1430e-06 - accuracy: 1.0000 - val_loss: 2.8874 - val_accuracy: 0.2057\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 2.2295e-06 - accuracy: 1.0000 - val_loss: 2.9579 - val_accuracy: 0.2114\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.0320e-06 - accuracy: 1.0000 - val_loss: 2.6780 - val_accuracy: 0.2229\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 5.8106e-07 - accuracy: 1.0000 - val_loss: 2.7004 - val_accuracy: 0.2229\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.3392e-07 - accuracy: 1.0000 - val_loss: 2.6421 - val_accuracy: 0.2229\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 3.9509e-07 - accuracy: 1.0000 - val_loss: 2.6435 - val_accuracy: 0.2286\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 3.1948e-07 - accuracy: 1.0000 - val_loss: 2.6650 - val_accuracy: 0.2286\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 3.7398e-07 - accuracy: 1.0000 - val_loss: 2.6935 - val_accuracy: 0.2400\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 3.1744e-07 - accuracy: 1.0000 - val_loss: 3.1270 - val_accuracy: 0.2114\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 2.5701e-06 - accuracy: 1.0000 - val_loss: 2.2453 - val_accuracy: 0.3143\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.9065 - accuracy: 0.4629\n",
      "np.shape(X_test)= (175, 480, 1)\n",
      "Accuracy=  0.4628571569919586\n"
     ]
    }
   ],
   "source": [
    "#VGG16_1D\n",
    "\n",
    "accuracy=0\n",
    "acc_crs=np.array([])\n",
    "##for i in range (10):\n",
    "##    if accuracy<0.2 :\n",
    "\n",
    "verbose, epochs, batch_size = 1, 1000, 80\n",
    "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train_cat.shape[1]\n",
    "steps_per_epoch = len(X_train)//batch_size\n",
    "validation_steps = len(X_valid)//batch_size # if you have test data\n",
    "\n",
    "\n",
    "\n",
    "model_crs = Sequential()\n",
    "#model_crs.add(Conv1D(input_shape=x_train.shape[1:],filters=64,kernel_size=9,padding=\"same\", activation=\"relu\"))\n",
    "model_crs.add(Conv1D(filters=256, kernel_size=12, strides=1, activation='relu', input_shape=(n_timesteps,n_features))) #Replaced\n",
    "model_crs.add(BatchNormalization())\n",
    "model_crs.add(MaxPooling1D(pool_size=2,strides=3))\n",
    "\n",
    "model_crs.add(Conv1D(filters=64, kernel_size=7, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model_crs.add(BatchNormalization())\n",
    "model_crs.add(MaxPooling1D(pool_size=2,strides=2))\n",
    "\n",
    "model_crs.add(Conv1D(filters=64, kernel_size=10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model_crs.add(Conv1D(filters=128, kernel_size=5, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "model_crs.add(MaxPooling1D(pool_size=2,strides=2))\n",
    "\n",
    "model_crs.add(Conv1D(filters=512, kernel_size=15, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model_crs.add(MaxPooling1D(pool_size=2,strides=2))\n",
    "\n",
    "model_crs.add(Conv1D(filters=1024, kernel_size=5, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "#model_crs.add(Conv1D(filters=128, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "\n",
    "model_crs.add(Flatten())\n",
    "model_crs.add(Dropout(0.1))\n",
    "model_crs.add(Dense(units=512,activation=\"relu\"))\n",
    "#model_crs.add(Dense(units=2048,activation=\"relu\"))\n",
    "model_crs.add(Dense(n_outputs, activation='softmax'))   #Replaced here from old Model\n",
    "\n",
    "model_crs.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# fit network   #CategoricalCrossentropy #sparse_categorical_crossentropy #SparseCategoricalCrossentropy\n",
    "\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_accuracy\", mode =\"max\", patience = 50, restore_best_weights = True)\n",
    "\n",
    "model_crs.fit(X_train, y_train_cat, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data = (X_valid, y_valid_cat), callbacks =[earlystopping])\n",
    "\n",
    "_, accuracy = model_crs.evaluate(X_valid, y_valid_cat, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print('np.shape(X_test)=',np.shape(X_test))\n",
    "\n",
    "print('Accuracy= ', accuracy)\n",
    "\n",
    "#y_pred_vgg = model_crs.predict_classes(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step\n",
      "array([[11,  0,  5,  8,  0,  0,  0],\n",
      "       [ 3,  0,  1, 21,  0,  0,  0],\n",
      "       [ 1,  0, 21,  0,  0,  0,  0],\n",
      "       [ 4,  0,  2, 23,  0,  0,  0],\n",
      "       [10,  0, 12,  6,  0,  0,  0],\n",
      "       [22,  0,  2,  1,  0,  0,  0],\n",
      "       [ 3,  0,  1,  1,  0,  0, 17]], dtype=int64)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.20      0.46      0.28        24\n",
      "           3       0.00      0.00      0.00        25\n",
      "           4       0.48      0.95      0.64        22\n",
      "           5       0.38      0.79      0.52        29\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.00      0.00      0.00        25\n",
      "           8       1.00      0.77      0.87        22\n",
      "\n",
      "    accuracy                           0.41       175\n",
      "   macro avg       0.29      0.43      0.33       175\n",
      "weighted avg       0.28      0.41      0.31       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predict_x=model_crs.predict(X_test)              # Function 1\n",
    "\n",
    "y_pred_crs=maxindx(predict_x)                    # function from augment.py to remove 0 index predictions\n",
    "\n",
    "#y_pred_crs = model_crs.predict_classes(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_crs)\n",
    "fullprint(cm)\n",
    "acc3=accuracy_score(y_test, y_pred_crs)\n",
    "\n",
    "print(classification_report(y_test, y_pred_crs))\n",
    "\n",
    "#sns.heatmap(cm, annot=True)\n",
    "\n",
    "#plt.imshow(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
